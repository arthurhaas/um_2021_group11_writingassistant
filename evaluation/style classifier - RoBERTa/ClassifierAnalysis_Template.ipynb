{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtqo-KADGG67"
   },
   "source": [
    "# Building a RoBERTa-Classifier \n",
    "\n",
    "\n",
    "In this notebook we analyse our RoBERTa classifiers. The classifier consists of a fully connected layer ont top of a RoBERTa model.\n",
    "\n",
    "The implemenation is based on:\n",
    "- https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "-https://huggingface.co/transformers/model_doc/bert.html\n",
    "-https://huggingface.co/transformers/model_doc/roberta.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17616,
     "status": "ok",
     "timestamp": 1623831832921,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "xzgDn_4Dx55r",
    "outputId": "9433f097-546b-4a6c-bcee-3c634357a43c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuoFPdzvGG7C"
   },
   "source": [
    "## Loading all needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7640,
     "status": "ok",
     "timestamp": 1623831840553,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "dmNuCOFOGh1w",
    "outputId": "80a4e6d9-693c-40c4-a013-afe421f7111a"
   },
   "outputs": [],
   "source": [
    "! pip install transformers==3\n",
    "! pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEqGmlAVGG7C"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import RobertaModel, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgxcMFe9glxh"
   },
   "source": [
    "- Get GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1623831844874,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "5FipvThvGG7F",
    "outputId": "bdab95b5-2f06-41d1-ae67-6ba094a25210"
   },
   "outputs": [],
   "source": [
    "# Get Device \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Used device is {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu02Y_WfGG7K"
   },
   "source": [
    "## Building RoBERTa Classifier Model\n",
    "Here we use the classical RoBERTa model 'roberta-base'. This might be replaced by more specific pretrained models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1fiKVdnGG7L"
   },
   "source": [
    "### Bert specific processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "3628542706274fc48c70235102bf7a2e",
      "7cf8266fab2d47c08587e1a5cae9874b",
      "f646e12209af4fa68ac5bf0fc0bed041",
      "35937b2646ab405ab645f3188f1023df",
      "374d23c2cf38408f9d3d7afd6cf0e663",
      "1b39f350b83b48d5ae34558811204646",
      "9382efb1c75f415681b086d8ef40c8d7",
      "017a0c083628473b90eb2cc1c238f59f",
      "7d0f4f6c7d6e4b438401b2715f6cba8e",
      "e7d5a91924dc489686a058d1275f6a86",
      "1c6eadedcb0f491f9b75bad3010b02fe",
      "b4d6ea0364d246c69cafcb90578d5cb8",
      "735152889b6b4592896b9b68ea709008",
      "4ffd5cb7d1aa47aca6bb4dfdd7f46bf4",
      "a2bd965cdfe149059f08d8f9cda6bf75",
      "17be7962b26741e69b3e1a2573991b88"
     ]
    },
    "executionInfo": {
     "elapsed": 1875,
     "status": "ok",
     "timestamp": 1623831846738,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "5qfK5p4QGG7L",
    "outputId": "fa098e3c-bc9e-4176-b374-fa2fa23017e0"
   },
   "outputs": [],
   "source": [
    "# Special RoBERTa mdoe to be used: While slight information might be lost; capitalization in tweets is a neglectable characteristic\n",
    "PRE_TRAINED_MODEL_NAME = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrbiImoZj4C1"
   },
   "source": [
    "- Get understanding of the distribution of token sizes for maximal length used in BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1xDxi2TGG7M"
   },
   "source": [
    "### Build PyTorch Dataset and DataLoader\n",
    "\n",
    "This section builds the basic fucntionality for teh RoBERTa classifer, Dataloaders etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5iRZUrDGG7M"
   },
   "outputs": [],
   "source": [
    "# Data Structure\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, sents, labels, tokenizer, max_len):\n",
    "        self.sents = sents\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        sent = str(self.sents[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = tokenizer(sent,\n",
    "                             truncation=True,\n",
    "                             add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "                             return_token_type_ids=False,\n",
    "                             padding = 'max_length',\n",
    "                             max_length=self.max_len,\n",
    "                             return_attention_mask=True,\n",
    "                             return_tensors='pt')\n",
    "      \n",
    "        return { 'sent': sent, 'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "# Data Loader\n",
    "def create_data_loader(sentences, labels, tokenizer, max_len, batch_size):\n",
    "    ds = SentenceDataset(\n",
    "        sents=sentences, #.to_numpy()\n",
    "        labels=labels, #.to_numpy()\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-AWbwUqGG7O"
   },
   "source": [
    "### Actual Model\n",
    "\n",
    "Two types of models with the same weights! First is the 'normal' one. The second additionally gives the [CLS]-vectors for clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_DvWra9GG7O"
   },
   "outputs": [],
   "source": [
    "class StyleClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, drop = 0.3):\n",
    "        \n",
    "        super(StyleClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=drop)\n",
    "        self.out = nn.Linear(self.roberta.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)\n",
    "\n",
    "class StyleClassifier_forCluster(nn.Module):\n",
    "    def __init__(self, n_classes, drop = 0.3):\n",
    "        \n",
    "        super(StyleClassifier_forCluster, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=drop)\n",
    "        self.out = nn.Linear(self.roberta.config.hidden_size, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output), pooled_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeVa1TidGG7P"
   },
   "source": [
    "### Define Helper functions\n",
    "\n",
    "Some functionality used in evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Frpt7_9lxxiv"
   },
   "outputs": [],
   "source": [
    "# This provides just a way to illustrate our confusion matrices in a nice and labeled way\n",
    "def show_confusion_matrix(confusion_matrix, names = ['Scientific', 'Non-Scientifc'], save_path = None):\n",
    "  confusion_df = pd.DataFrame(cm, index=names,columns=names)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cbar=False, square=True,fmt='.2f')\n",
    "  plt.ylabel(r'True categories',fontsize=14)\n",
    "  plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "  plt.tick_params(labelsize=12)\n",
    "  if save_path:\n",
    "    plt.savefig(save_path)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOtgFHQQyLgS"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  # put to eval mode to disable dropout \n",
    "  model = model.eval()\n",
    "\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      labels = d[\"label\"].to(device)\n",
    "\n",
    "      outputs = model(input_ids=input_ids, attention_mask=attention_mask) #dim BATCH_SIZE x 3\n",
    "      # torch.max(outputs, dim=1) returns (vals, positions) of maxima -> positions are kept and correspond to class labels\n",
    "      _, preds = torch.max(outputs, dim=1) # dim BATCH_SIZE x 1\n",
    "\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(outputs)\n",
    "      real_values.extend(labels)\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return predictions, real_values, prediction_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqkdAEHUGG7Q"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    \n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            \n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"label\"].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGaZ6wceKQTr"
   },
   "source": [
    "### Parameter choices\n",
    "- Set hyper parameters and day of mdoel to be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGa0sP8RKA9F"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "day = datetime.date(2021, 6, 16)\n",
    "MAX_LEN = 100 # chosen acccroding to hist above\n",
    "BATCH_SIZE = 32# tunable hyper parameter\n",
    "EPOCHS = 3\n",
    "lr = 1e-5\n",
    "dropout = 0.3\n",
    "\n",
    "data_save_path = f'/models/{day}/RoBERTA_Epochs{EPOCHS}_Bs{BATCH_SIZE}_lr{lr}_drop{dropout}/model_specific_data.pkl'# save model specific data\n",
    "model_save_path = f'/models/{day}/RoBERTA_Epochs{EPOCHS}_Bs{BATCH_SIZE}_lr{lr}_drop{dropout}/RoBERTa.bin'# save model parameters, should include BERT and hyperparameters in name\n",
    "#img_save_path = f'/content/gdrive/MyDrive/StyleClassifier/models/{day}/RoBERTA_Epochs{EPOCHS}_Bs{BATCH_SIZE}_lr{lr}_drop{dropout}/cm.png' # save confusion matrix, should include BERT and hyperparameters in name\n",
    "#report_save_path = f'/content/gdrive/MyDrive/StyleClassifier/models/{day}/RoBERTA_Epochs{EPOCHS}_Bs{BATCH_SIZE}_lr{lr}_drop{dropout}/report.csv' # save classification report, should include BERT and hyperparameters in name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dACk_YZ3GG7Q"
   },
   "source": [
    "### Recreate data and LOAD model\n",
    "\n",
    "\n",
    "This way we get the exact data partioion used in training, ensuring that test data is unseen by model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1859,
     "status": "ok",
     "timestamp": 1623831848592,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "g43tgr0B_b6r",
    "outputId": "34e9fa9b-efc4-486f-b264-6e0e7df3c838"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(data_save_path, 'rb') as f:\n",
    "  data_dict = pickle.load(f)\n",
    "\n",
    "# Assign data\n",
    "data_train, labels_train = zip(*data_dict['train'])\n",
    "data_val, labels_val = zip(*data_dict['val'])\n",
    "data_test, labels_test = zip(*data_dict['test'])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_data_loader = create_data_loader(data_train, labels_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(data_val, labels_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(data_test, labels_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "print(f'Number of training sentences: \\t {len(data_train)}')\n",
    "print(f'Number of validation sentences:  {len(data_val)}')\n",
    "print(f'Number of test sentences: \\t {len(data_test)} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8g1hTd_EJAT"
   },
   "source": [
    "- LOAD MODEL FROM GIVEN PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "14794e83a98a4721ab1dd38bcba1342f",
      "d29822c2772c48e9937c807b1ba9c122",
      "366b933c5a6442128320d4f2906bc62f",
      "5234c92fb3594fd68406b5f739973eb2",
      "9b395dbe827440478200c73c42eff6e0",
      "800373db40014d88b43b8c0718eda780",
      "474547837b524a8582d65b1217abe996",
      "47debc5027424aefa38a1bfd011ef25d",
      "816a49a7def04c77b25b5dede7e11119",
      "d63dc278554b488ea43130ea12fe51bd",
      "0c97770364ae40edbf95ccf03df9ba85",
      "8bff27a639564414beb40875a4a284bf",
      "efa620552f5441769b01d6c84852d37c",
      "402c74d6b2fd478e925688c54247cb4d",
      "3b3191b3040040c693253231d043ea58",
      "5529a2c491c84c6cb38953f644435389"
     ]
    },
    "executionInfo": {
     "elapsed": 33005,
     "status": "ok",
     "timestamp": 1623831881594,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "HB0rZZCzGG7O",
    "outputId": "5e67452a-13b2-4efc-f943-1c0aad45aaf5"
   },
   "outputs": [],
   "source": [
    "# LOAD model\n",
    "model = StyleClassifier(2, drop = dropout).to(device)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model = model.to(device)\n",
    "\n",
    "model_cluster = StyleClassifier_forCluster(2, drop = dropout).to(device)\n",
    "model_cluster.load_state_dict(torch.load(model_save_path))\n",
    "model_cluster = model_cluster.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voCzvv0QP9gO"
   },
   "source": [
    "## Standard Model Evaluation\n",
    "\n",
    "Compare values to notebook of trainign teh classifier to ensure its the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112006,
     "status": "ok",
     "timestamp": 1623831993585,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "dfCApAE_ShY0",
    "outputId": "8ac3b03e-53ed-4e94-e95b-c1f46ae70fb1"
   },
   "outputs": [],
   "source": [
    "# Test Accuracy\n",
    "test_acc, _ = eval_model(model, test_data_loader, nn.CrossEntropyLoss().to(device) , device, len(data_test))\n",
    "print(f'Test Accuracy: {test_acc.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hYSixO-LAB3"
   },
   "source": [
    "- Calculate Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 109556,
     "status": "ok",
     "timestamp": 1623832103136,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "FB0oBOsuyH4d",
    "outputId": "f6b0b956-ef9d-4c84-bf4e-db3b1d4beaa7"
   },
   "outputs": [],
   "source": [
    "# Calculation of relevant scores\n",
    "labels_pred, labels_test,_ = get_predictions(model, test_data_loader)\n",
    "report = classification_report(labels_test, labels_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1623832103138,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "IxkHG20G2GWv",
    "outputId": "d364eecd-9c6a-4c0b-e214-2b35a7bd995f"
   },
   "outputs": [],
   "source": [
    "report_df\n",
    "cm = confusion_matrix(labels_test, labels_pred, normalize = 'true')\n",
    "show_confusion_matrix(cm, names = ['Reports', 'Arxiv'], save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhOMrxIvvDyI"
   },
   "source": [
    "# Analysing the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMtFTQ1o8_Rg"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NST_9bwZZafF"
   },
   "outputs": [],
   "source": [
    "# this path some csv's will be stored that can be used for further manual inspection of data\n",
    "analysis_path = f'/models/{day}/analysis/'\n",
    "\n",
    "! mkdir {analysis_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFCTfNuDDMq8"
   },
   "source": [
    "## Setup Data for Analysis\n",
    "**Working with and setting up test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 110219,
     "status": "ok",
     "timestamp": 1623832213755,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "BNdON0bpDaai",
    "outputId": "4f1ad3b3-4ad8-4ba1-a60f-2d029c7886c1"
   },
   "outputs": [],
   "source": [
    "# Get Predictions and transfer to list\n",
    "labels_pred, labels_test, probs = get_predictions(model, test_data_loader)\n",
    "\n",
    "# Create DF for easier handling!\n",
    "data = pd.DataFrame(columns = ['sent', 'true_label', 'pred_label'])\n",
    "data['sent'] = data_test\n",
    "data['true_label'] = [label.item() for label in labels_test]\n",
    "data['pred_label'] = [label.item() for label in labels_pred]\n",
    "\n",
    "\n",
    "#\n",
    "probs = F.softmax(probs)\n",
    "data['prob0'] = [prob[0].item() for prob in probs]\n",
    "data['prob1'] = [prob[1].item() for prob in probs]\n",
    "data['prob_max'] = [max(prob[0].item(),prob[1].item()) for prob in probs]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLCg62v03ZFx"
   },
   "source": [
    "## Sentences in dependece of their prediction probability\n",
    "In the next cells, the sentences which\n",
    "  - the classifier is unsure about\n",
    "  - the classifier wrongly predicted with high probability\n",
    "  - the classifier correctly predicted with high probability\n",
    "\n",
    "will be analyzed. To that end, some sentences are exported to a csv-file allowing better manual annotation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1623832213760,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "YrQ69c4x1f9R",
    "outputId": "8821d036-f1d7-48a9-9dea-b21e33eb2f81"
   },
   "outputs": [],
   "source": [
    "# Sentences the classifier is unsure about\n",
    "cond = (0.45<data['prob0'])*(data['prob0']<0.55)\n",
    "data_unsure = data.loc[cond]\n",
    "data_unsure.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1623832213772,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "nmQQqWJU4RLT",
    "outputId": "ccf56059-bce1-4840-9f7a-3274cb5a140e"
   },
   "outputs": [],
   "source": [
    "# Sentences the classifier is wrong about, buth with high confidence\n",
    "# Arxiv mistaken as Medium\n",
    "cond = (data['pred_label'] == 0)*(data['true_label']==1)*(data['prob_max']>0.9)\n",
    "data_sure = data.loc[cond]\n",
    "\n",
    "data_sure.to_csv( analysis_path+'CSArxiv_as_Medium_90.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1623832213773,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "UKDAFdRaaO3m",
    "outputId": "1afcf8f3-e4d4-4a1e-fb43-6e0c343d89ca"
   },
   "outputs": [],
   "source": [
    "# Sentences the classifier is wrong about, buth with high confidence\n",
    "# Medium mistaken as Arxiv\n",
    "cond = (data['pred_label'] == 1)*(data['true_label']==0)*(data['prob_max']>0.9)\n",
    "data_sure = data.loc[cond]\n",
    "\n",
    "data_sure.to_csv( analysis_path+'Medium_as_CSArxiv_90.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1866,
     "status": "ok",
     "timestamp": 1623832215577,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "SmVlkEfrGZB7",
    "outputId": "ede7f147-af35-4b2e-9c87-ad440fd66c43"
   },
   "outputs": [],
   "source": [
    "# Sentences the classifier is correct about, buth with high confidence // Medium\n",
    "cond = (data['pred_label'] ==0)*(data['true_label'] == 0)*(data['prob_max']>0.9)\n",
    "data_sure_medium = data.loc[cond]\n",
    "data_sure_medium['len'] = [len(tokenizer.tokenize(sent)) for sent in data_sure_medium['sent']]\n",
    "data_sure_medium.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1623832216630,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "i6c0OtZ-GJlp",
    "outputId": "101f40e2-418d-4aef-b45e-01042ef2cb4d"
   },
   "outputs": [],
   "source": [
    "# Sentences the classifier is correct about, buth with high confidence // Arxiv\n",
    "cond = (data['pred_label'] ==1)*(data['true_label'] == 1)*(data['prob_max']>0.9)\n",
    "data_sure_arxiv = data.loc[cond]\n",
    "data_sure_arxiv['len'] = [len(tokenizer.tokenize(sent)) for sent in data_sure_arxiv['sent']]\n",
    "data_sure_arxiv.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5L8a7Ie4NX9"
   },
   "source": [
    "## Rewriting sentences and ccking their new classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EokUFsKmJv9G"
   },
   "outputs": [],
   "source": [
    "list_of_rewritten_sents = [\n",
    "                           ('its vertices are enclosed by the dashed contour.', 'the vertices of this are surrounded by a shaded region.'),\n",
    "                           ('however, it had never been empirically evaluated before this work.', 'no one has looked at this before in an empirical way.'),\n",
    "                           ('let us now give a brief description of the concatenated coding scheme.', 'i will now decsribe the the concatenated coding scheme.'),\n",
    "                           ('let us now give a brief description of the concatenated coding scheme.', 'This now decsribes the the concatenated coding scheme.'),\n",
    "                           ('given the small difference in performance between the algebraic lattices, it is difficult to propose an optimal candidate.', 'it is very difficult to find an optimum candidate, because the differences are so tiny.'),\n",
    "                           ('to lower bound the marginal joint replenishment cost we perform a similar analysis to the one in eq.', 'i try to lower bound the cost in the same way as before.'),\n",
    "                           ('we perform multiple restarts of gradient ascend with random initializations for the nodes ( e ), ( f ), ( g ).', 'the start the optimization from different starting points for the nodes ( e ), ( f ), ( g ).'),\n",
    "                           ('it is then possible to get an ordered ( from left to right ) overview of the articles on that topic.', 'you can get the overview of the articles on that topic from left to right.'),\n",
    "                           ('it is then possible to get an ordered ( from left to right ) overview of the articles on that topic.', 'This way one can get the overview of the articles on that topic from left to right.'),\n",
    "                           ('third, the bandwidths of the network connecting the nodes are limited.', 'also, there is some limitation of the bandwidths of the network.'),\n",
    "                           ('thus, we obtain the following algorithm for computing the well - founded semantics.', 'We have built this algorithm for finding well - founded semantics.'),\n",
    "                           ('is result implies that the mean packet delay and delay jitter can go to infinity even if the system is not saturated.', 'this shows cleary that the mean delay and delay jitter can gow super large also when the system is not saturated.'),\n",
    "                           ('we perform the spectral analysis needed to prove our main result.', 'We do spectral analysis to show that our main result is true.'),\n",
    "                           ('our focus on these two methods is due to their widespread adoption by the signal processing and statistics communities.', 'we look at these two methods, because they are often used in signal processing and statistics.'),\n",
    "                           ('furthermore, the combination of friction effects and muscle-pose ambiguity leads to a strong hysteresis effect.', 'also, firction effects and and muscle-pose ambiguity together can result in to strong hysteresis effect.'),\n",
    "                           ('this will cost large computations to obtain the accurate implicit surface.', 'getting an accurate implicit surface will take long computations.'),\n",
    "                           ('comparison between the results show that the performance of egc is very close to the performance of oc receiver.', 'looking at the results we cane see that the performance of egc is almost the same as the performance of oc receiver.'),\n",
    "                           ('the fast convergence of the derived formula is due to the identified mock-gaussian behavior.', 'our formula converges very fast because of the identified mock-gaussian behavior.'),\n",
    "                           ('we therefore consider scores resulting from algorithms based on editorial changes to be less informative for this comparison.', 'because of this we think that scores from algorithms based on editorial changes are not really good for this comparison.'),\n",
    "                           ('our work raises a number of questions which aim to further strengthen our understanding of the long term influence.', 'we look at some questions which are supposed to help understnd the long term effects.'),\n",
    "                           ('of course, the feedback can be substantially reduced by exploiting channel correlations.', 'obviously, you need less feedback if taking into account that there is correlations between the channels.'),\n",
    "                           ('the proposed optimum solution algorithm is numerically simulated to find the optimum departure region.', 'we simulate the optimum solution algorithm to find the best of the depature regions.'),\n",
    "                           ('the proposed algorithm is implemented to estimate the wind power output considering practical wind data.', 'our algorithm is built to predict the of wind power using wind data.')\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1623832216637,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "twmdUSVGQ4xg",
    "outputId": "0f5e65f7-166f-405f-b671-5b6ec0c138a4"
   },
   "outputs": [],
   "source": [
    "originals = [sent for (sent,_) in list_of_rewritten_sents]\n",
    "rewritten= [sent for (_,sent) in list_of_rewritten_sents]\n",
    "print(rewritten)\n",
    "rewritten_data_loader = create_data_loader(rewritten, [1 for _ in rewritten], tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "labels_rewritten,_,_ = get_predictions(model, rewritten_data_loader)\n",
    "print(labels_rewritten)\n",
    "print(f'Out of {len(labels_rewritten)} rewritten sentences, {len(labels_rewritten)-sum(labels_rewritten)} were now classified differnetly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9cJaW6jyWeR"
   },
   "source": [
    "## Quantitive differences between the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 3560,
     "status": "ok",
     "timestamp": 1623832220594,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "Si96KZlDx2uR",
    "outputId": "47665637-4865-4c98-bc8f-e4f9a5cdce25"
   },
   "outputs": [],
   "source": [
    "# Avg length\n",
    "data['token_length'] = [len(tokenizer.tokenize(sent)) for sent in data['sent']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 580,
     "status": "ok",
     "timestamp": 1623832221167,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "AthxZXbyywOZ",
    "outputId": "42815a22-d5ea-4410-b00a-dc3824cf45b7"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (18,8))\n",
    "ax.hist([data['token_length'][data['true_label']==0], data['token_length'][data['true_label']==1]], label = ['Medium', 'Arxiv'], bins = 100, density=True)\n",
    "ax.legend()\n",
    "ax.set_title('Length of Tokens', fontsize = 16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCEOi4yL4gep"
   },
   "source": [
    "## Looking for Unscientific Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saqGjy_EKVd7"
   },
   "outputs": [],
   "source": [
    "def keyword_odds(dataframe, keywords):\n",
    "\n",
    "  # Separate sentences\n",
    "  all_test_sentences_sci = [sent.lower().split() for i,sent in enumerate(dataframe['sent'][data['true_label'] == 1])]\n",
    "  all_test_sentences_nonsci = [sent.lower().split() for i,sent in enumerate(dataframe['sent'][data['true_label'] == 0])]\n",
    "\n",
    "  #Calculate occurences\n",
    "  keywords_sci = sum([1 for sent in all_test_sentences_sci if any([word in sent for word in keywords])])\n",
    "  keywords_sci /= len(all_test_sentences_sci)\n",
    "  keywords_nonsci = sum([1 for sent in all_test_sentences_nonsci if any([word in sent for word in keywords])])\n",
    "  keywords_nonsci /= len(all_test_sentences_nonsci)\n",
    "\n",
    "  print(f'Proportion of sentences with keywords in Arxiv: {keywords_sci}')\n",
    "  print(f'Proportion of sentences with keywords in Medium: {keywords_nonsci}')\n",
    "\n",
    "  return keywords_sci/keywords_nonsci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1623832221170,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "3fFl7w7S4g6Q",
    "outputId": "1c22ed3b-7a05-49c5-fce2-b3b7d884e9e4"
   },
   "outputs": [],
   "source": [
    "# keywords = ['I','you', 'we', 'should', 'obviously', 'us', 'our'] #['et']\n",
    "keywords = ['you']\n",
    "keyword_odds(dataframe = data, keywords=keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNA8blmXvXo6"
   },
   "source": [
    "Preprocessing helps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUSi6CJm8Ewh"
   },
   "source": [
    "## Vocabulary differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf-xEkQoL2U3"
   },
   "outputs": [],
   "source": [
    "def compare_vocabs(corpus1, corpus2):\n",
    "\n",
    "  all_words_corpus1 = [word for sent in corpus1 for word in sent.split()]\n",
    "  all_words_corpus1 = set(all_words_corpus1)\n",
    "  print(f'# All words Corpus1: {len(all_words_corpus1)}')\n",
    "\n",
    "  all_words_corpus2 = [word for sent in corpus2 for word in sent.split()]\n",
    "  all_words_corpus2 = set(all_words_corpus2)\n",
    "  print(f'# All words Corpus2: {len(all_words_corpus2)}')\n",
    "\n",
    "\n",
    "  union = all_words_corpus1.union(all_words_corpus2)\n",
    "  intersec = all_words_corpus1.intersection(all_words_corpus2)\n",
    "\n",
    "\n",
    "  print(f'# All words: {len(union)}')\n",
    "  print(f'# shared words: {len(intersec)}')\n",
    "\n",
    "  #return union, intersec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1623832221546,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "hDsjtwxcMl1D",
    "outputId": "83db4c30-11e9-4a21-f754-a13cadb0e03f"
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "sci_data = list(data['sent'][data['true_label']==1])\n",
    "nonsci_data = list(data['sent'][data['true_label']==0])\n",
    "# Evaluate\n",
    "print('Arxiv Medium')\n",
    "compare_vocabs(corpus1 = sci_data, corpus2 = nonsci_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipQ-aV9V_Ou8"
   },
   "source": [
    "This does not take into account frequencies. Some sared words might even have noticable frequency differences. This still has punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apdprPQMUmU0"
   },
   "source": [
    "## Clustering with t-SNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0uoxjHDOGAT"
   },
   "outputs": [],
   "source": [
    "def get_cluster_vectors(data_loader, classifier):\n",
    "  # get vectors of CLS token of last layer of actual roberta model\n",
    "  classifier = classifier.eval()\n",
    "\n",
    "  CLS_vectors = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      labels = d[\"label\"].to(device)\n",
    "\n",
    "      outputs, cls_out = classifier(input_ids=input_ids, attention_mask=attention_mask) #dim BATCH_SIZE x 3\n",
    "      # torch.max(outputs, dim=1) returns (vals, positions) of maxima -> positions are kept and correspond to class labels\n",
    "      CLS_vectors.extend(cls_out)\n",
    "      #prediction_probs.extend(outputs)\n",
    "\n",
    "\n",
    "  CLS_vectors = torch.stack(CLS_vectors).cpu().numpy()\n",
    "  return CLS_vectors\n",
    "\n",
    "\n",
    "def plot_clusters(vectors, labels, names = {1: 'Sci:', 0: 'NonSci'}, title = 't-SNE of CLS-vectors'):\n",
    "\n",
    "  #Plotting\n",
    "  dim = vectors.shape[1]\n",
    "  labels_unique = list(set(labels))\n",
    "  n_classes = len(labels_unique)\n",
    "  assert n_classes == len(names)\n",
    "\n",
    "  fig, ax = plt.subplots(1,1, figsize = (16, 5))\n",
    "  for i, label in enumerate(labels_unique):\n",
    "    x = vectors[labels == label,0]\n",
    "    y = vectors[labels == label,1]\n",
    "    ax.scatter(x,y, label = names[i] ,alpha=.8, edgecolors='none')\n",
    "\n",
    "\n",
    "  ax.set_title(title, fontsize = 12)\n",
    "  ax.legend()\n",
    "  plt.show()\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "def illustrate_cluster(dataframe, classifier, n_components = 2, names = {1: 'Sci:', 0: 'NonSci'}, title = 't-SNE of CLS-vectors'):\n",
    "\n",
    "  # put data into correct form \n",
    "  data_loader = create_data_loader(dataframe['sent'], dataframe['true_label'], tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "  # get CLS emebddings\n",
    "  print('Calculating CLS embeddings!')\n",
    "  CLS_vectors = get_cluster_vectors(data_loader = data_loader, classifier = classifier)\n",
    "\n",
    "  # Data dimesnionality reduction\n",
    "  print('Reducing data dimesionality for illustration. This might take a while!')\n",
    "  tsne = TSNE(n_components = n_components , init='pca', random_state=42)\n",
    "  CLS_vectors_fitted = tsne.fit_transform(CLS_vectors)\n",
    "\n",
    "  plot_clusters(vectors = CLS_vectors_fitted, labels = dataframe['true_label'], names = names, title = title)\n",
    "\n",
    "  return CLS_vectors_fitted\n",
    "\n",
    "\n",
    "def dislpay_sents_cluster(xmin, xmax, ymin, ymax, CLS_vecs, all_sents, labels, n_sents = 10):\n",
    "  idxs = list(range(CLS_vecs.shape[0]))\n",
    "  filtered_idxs = []\n",
    "  for idx in idxs:\n",
    "    x = CLS_vecs[idx,0]\n",
    "    y = CLS_vecs[idx,1]\n",
    "    if xmin<= x and x <= xmax:\n",
    "      if ymin <= y and y<=ymax:\n",
    "        filtered_idxs.append(idx)\n",
    "\n",
    "  chosen_idxs = random.sample(filtered_idxs, n_sents)\n",
    "  for idx in chosen_idxs:\n",
    "    print(all_sents[idx], '\\t |', labels[idx].item() , '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 1399959,
     "status": "ok",
     "timestamp": 1623833621494,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "rkXMtyCVSRns",
    "outputId": "9f6decf8-286b-4771-9c86-bfec1cd8807b"
   },
   "outputs": [],
   "source": [
    "cls_vecs = illustrate_cluster(dataframe = data, classifier = model_cluster, n_components = 2, names = {1: 'Sci:', 0: 'Medium'}, title = 't-SNE of CLS-vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mF5-K7Xze--O"
   },
   "source": [
    "1) Cluster on Bottom: possesive 's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1623833881184,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "JivsWZxeVtVo",
    "outputId": "213917b1-7fa9-4cd4-a237-39507a6320d8"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = -30, xmax=-20, ymin = -40, ymax=-32, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2DyWPiSLwfz"
   },
   "source": [
    "2) Small Cluster on top. -> Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1623834035089,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "lR9oAoWnLwf0",
    "outputId": "e640301a-67cf-4d6c-f20a-e162649daad5"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = -40, xmax=-20, ymin = 38, ymax=50, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLuhJAumMUBQ"
   },
   "source": [
    "3) Small Cluster left ->farwell clauses/gratitude clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1623834298872,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "O6fxmRDCMUBQ",
    "outputId": "28e1272a-1528-484e-9dbc-49c45c02da30"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = -60, xmax=-50, ymin = -5, ymax=15, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlFqaT1uM_0T"
   },
   "source": [
    "4) I sentences, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1623834304684,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "APjDYTA7M_0U",
    "outputId": "8a432dec-e8c0-48c2-8445-d53a8246f402"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = 25, xmax= 30, ymin = -10, ymax=0, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w781b0gSNjfw"
   },
   "source": [
    "5) Special punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1623834364154,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "dvnRdZ7uNjfx",
    "outputId": "499fe945-916f-49eb-81ee-8062968f327d"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = 30, xmax=50, ymin = -30, ymax=-20, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72HTwobpOl8v"
   },
   "source": [
    "6) Extremely short, casual sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1623834454001,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "M0Oju64ZOl87",
    "outputId": "606ba088-9273-4a7c-af2d-330df80eec36"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = 50, xmax=60, ymin = -22, ymax=-18, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SILPpjTAP0NX"
   },
   "source": [
    "7) Broken by tokenization/ prerpocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1623834630792,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "2NOpZHGHP0NY",
    "outputId": "098bf396-2a88-4bfa-99fd-d38c274e663e"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = 30, xmax=35, ymin = -25, ymax=-20, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBKREPIQP-rw"
   },
   "source": [
    "8) Main Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1623834682961,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "D-6Cp-J5P-rw",
    "outputId": "3dc5f244-cb59-4987-f322-89507dc46dbb"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = 20, xmax=40, ymin = 20, ymax=40, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFgnRBtwF0br"
   },
   "source": [
    "9) Main Mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1623834735617,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "yP7l9yaWF0bt",
    "outputId": "e2c7fe1c-a90e-44f4-d906-a5fc0044224f"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = -20, xmax=20, ymin = -20, ymax=20, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B6iKvLAGO4_"
   },
   "source": [
    "10) Main Sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1623834853215,
     "user": {
      "displayName": "Carsten Gieshoff",
      "photoUrl": "",
      "userId": "15205643335020562625"
     },
     "user_tz": -120
    },
    "id": "90xQ5L5zGO5A",
    "outputId": "a2d1e1fe-5bd6-4ef9-8772-d046cba9db0d"
   },
   "outputs": [],
   "source": [
    "#Sci cluster\n",
    "dislpay_sents_cluster(xmin = -40, xmax=-20, ymin = -20, ymax=40, CLS_vecs=cls_vecs, all_sents=data['sent'], labels=data['true_label'], n_sents = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks23olEnGbC0"
   },
   "source": [
    "**Take away from clusters**\n",
    "  - still strong content dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo7oXwUSlOx6"
   },
   "source": [
    "## Manual Testing\n",
    "\n",
    "In this section we do manual classification in order. The comaprison of model performance, aswell as the charcteristca the annotator uses in his choices will give importnant information about both the model and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSD1uw1mlO8B"
   },
   "outputs": [],
   "source": [
    "def test_manually(data, labels, tries = 100, rand_state = 42):\n",
    "  testing_myself = 0\n",
    "\n",
    "  data_ = [d for d in data]\n",
    "  try:\n",
    "    labels_ = [l.item() for l in list(labels)]\n",
    "  except:\n",
    "    labels_ = [l for l in list(labels)]\n",
    "\n",
    "  query = random.Random(rand_state).sample(list(zip(data_,labels_)), tries)\n",
    "  \n",
    "  for i, (sent, label) in enumerate(query):\n",
    "    print( f'{i}/{tries}' , sent, f'\\t accuracy: { (testing_myself)/(i+1)}', '\\n')\n",
    "    a = input()\n",
    "    a = int(a)\n",
    "    if a == label:\n",
    "      testing_myself +=1\n",
    "\n",
    "\n",
    "  print(f'Accuracy: {testing_myself/tries:.2f}')\n",
    "  return testing_myself/tries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bof4tgLMlTLc"
   },
   "outputs": [],
   "source": [
    "my_acc = test_manually(data_test, labels_test, 100, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Con9V5Gk4JyH"
   },
   "source": [
    "Accuracy on 100 sentences: 75%\n",
    "Main decison making criteria:\n",
    "  - style\n",
    "  - complexity of vocabulary / content\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3_36G8A89Jz"
   },
   "source": [
    "## Checking paraphrases\n",
    "\n",
    "In this section we laod the paraphrases created by our M1 model (T5-phase2) and see whether paraphrasing has thrown off the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-F4TZTJ89QL"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/gdrive/MyDrive/NLP_EvaluationMetrics/T5_paraphrases/'\n",
    "filename_dataframe = 'data_paraphrased_F1_top75k.pkl'\n",
    "paraphrase_data =  pd.read_pickle(data_path + filename_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CJIGvI8_JNx"
   },
   "outputs": [],
   "source": [
    "originals = list(paraphrase_data['original'])\n",
    "label_originals = [1 for _ in originals]\n",
    "paraphrases = list(paraphrase_data['paraphrase'])\n",
    "label_paraphrases = [0 for _ in paraphrases]\n",
    "\n",
    "paraphrase_data_for_cluster = pd.DataFrame(columns = ['sent', 'true_label'])\n",
    "paraphrase_data_for_cluster['sent'] = originals+paraphrases\n",
    "paraphrase_data_for_cluster['true_label'] = label_originals+label_paraphrases\n",
    "paraphrase_data_for_cluster.head()\n",
    "paraphrase_loader = create_data_loader(paraphrase_data_for_cluster['sent'], paraphrase_data_for_cluster['true_label'], tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NR2nyOqX4vGs"
   },
   "outputs": [],
   "source": [
    "# Calculation of relevant scores\n",
    "labels_para_pred, labels_para_test,_ = get_predictions(model, paraphrase_loader)\n",
    "report_para = classification_report(labels_para_test, labels_para_pred, output_dict=True)\n",
    "report_para_df = pd.DataFrame(report_para).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBmsyBC17GCt"
   },
   "outputs": [],
   "source": [
    "report_para_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXeEe4Yh5I4l"
   },
   "outputs": [],
   "source": [
    "cm_para = confusion_matrix(labels_para_test, labels_para_pred, normalize = 'true')\n",
    "#show_confusion_matrix(cm_para, names = ['Paraphrase', 'Orig. Arxiv'], save_path=None)\n",
    "cm_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V98rbti39u2k"
   },
   "source": [
    "## Reports\n",
    "\n",
    "In this section we load our reports to see whether the classifier is sitbale to use: ideally it should consider most of these to be non-scientific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Dsb7EmG9yLs"
   },
   "outputs": [],
   "source": [
    "data_path_reports = '/content/gdrive/MyDrive/StyleClassifier/datasets/almost_scientific_reports/final_processed/clean_report.txt'\n",
    "\n",
    "with open(data_path_reports, 'r') as f:\n",
    "  data_reports = f.readlines()\n",
    "\n",
    "data_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLrQyvPhAQst"
   },
   "outputs": [],
   "source": [
    "data_reports = [sent.lower().replace('\\n','') for sent in data_reports]\n",
    "data_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7Z23_FEApd4"
   },
   "outputs": [],
   "source": [
    "labels_reports = [0 for _ in data_reports]\n",
    "report_loader = create_data_loader(data_reports, labels_reports, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o__U4yLpAwA_"
   },
   "outputs": [],
   "source": [
    "labels_reports_pred, labels_reports_test,_ = get_predictions(model, report_loader)\n",
    "report_reports = classification_report(labels_reports_test, labels_reports_pred, output_dict=True)\n",
    "report_reports_df = pd.DataFrame(report_reports).transpose()\n",
    "report_reports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKGfBUrlag4e"
   },
   "outputs": [],
   "source": [
    "cm_reports = confusion_matrix(labels_reports_test, labels_reports_pred, normalize = 'true')\n",
    "#show_confusion_matrix(cm_para, names = ['Paraphrase', 'Orig. Arxiv'], save_path=None)\n",
    "cm_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZaUILrlflwv"
   },
   "source": [
    "# Results/Takeaways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd4xgmu8t7dX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJnG2fahMRLq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ClassifierAnalysis_Template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "017a0c083628473b90eb2cc1c238f59f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c97770364ae40edbf95ccf03df9ba85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_402c74d6b2fd478e925688c54247cb4d",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_efa620552f5441769b01d6c84852d37c",
      "value": 501200538
     }
    },
    "14794e83a98a4721ab1dd38bcba1342f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_366b933c5a6442128320d4f2906bc62f",
       "IPY_MODEL_5234c92fb3594fd68406b5f739973eb2"
      ],
      "layout": "IPY_MODEL_d29822c2772c48e9937c807b1ba9c122"
     }
    },
    "17be7962b26741e69b3e1a2573991b88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b39f350b83b48d5ae34558811204646": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c6eadedcb0f491f9b75bad3010b02fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ffd5cb7d1aa47aca6bb4dfdd7f46bf4",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_735152889b6b4592896b9b68ea709008",
      "value": 456318
     }
    },
    "35937b2646ab405ab645f3188f1023df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_017a0c083628473b90eb2cc1c238f59f",
      "placeholder": "​",
      "style": "IPY_MODEL_9382efb1c75f415681b086d8ef40c8d7",
      "value": " 899k/899k [00:01&lt;00:00, 633kB/s]"
     }
    },
    "3628542706274fc48c70235102bf7a2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f646e12209af4fa68ac5bf0fc0bed041",
       "IPY_MODEL_35937b2646ab405ab645f3188f1023df"
      ],
      "layout": "IPY_MODEL_7cf8266fab2d47c08587e1a5cae9874b"
     }
    },
    "366b933c5a6442128320d4f2906bc62f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_800373db40014d88b43b8c0718eda780",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b395dbe827440478200c73c42eff6e0",
      "value": 481
     }
    },
    "374d23c2cf38408f9d3d7afd6cf0e663": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3b3191b3040040c693253231d043ea58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "402c74d6b2fd478e925688c54247cb4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "474547837b524a8582d65b1217abe996": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47debc5027424aefa38a1bfd011ef25d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ffd5cb7d1aa47aca6bb4dfdd7f46bf4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5234c92fb3594fd68406b5f739973eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47debc5027424aefa38a1bfd011ef25d",
      "placeholder": "​",
      "style": "IPY_MODEL_474547837b524a8582d65b1217abe996",
      "value": " 481/481 [03:22&lt;00:00, 2.38B/s]"
     }
    },
    "5529a2c491c84c6cb38953f644435389": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "735152889b6b4592896b9b68ea709008": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7cf8266fab2d47c08587e1a5cae9874b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d0f4f6c7d6e4b438401b2715f6cba8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c6eadedcb0f491f9b75bad3010b02fe",
       "IPY_MODEL_b4d6ea0364d246c69cafcb90578d5cb8"
      ],
      "layout": "IPY_MODEL_e7d5a91924dc489686a058d1275f6a86"
     }
    },
    "800373db40014d88b43b8c0718eda780": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "816a49a7def04c77b25b5dede7e11119": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0c97770364ae40edbf95ccf03df9ba85",
       "IPY_MODEL_8bff27a639564414beb40875a4a284bf"
      ],
      "layout": "IPY_MODEL_d63dc278554b488ea43130ea12fe51bd"
     }
    },
    "8bff27a639564414beb40875a4a284bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5529a2c491c84c6cb38953f644435389",
      "placeholder": "​",
      "style": "IPY_MODEL_3b3191b3040040c693253231d043ea58",
      "value": " 501M/501M [00:10&lt;00:00, 48.8MB/s]"
     }
    },
    "9382efb1c75f415681b086d8ef40c8d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b395dbe827440478200c73c42eff6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a2bd965cdfe149059f08d8f9cda6bf75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4d6ea0364d246c69cafcb90578d5cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17be7962b26741e69b3e1a2573991b88",
      "placeholder": "​",
      "style": "IPY_MODEL_a2bd965cdfe149059f08d8f9cda6bf75",
      "value": " 456k/456k [00:00&lt;00:00, 1.22MB/s]"
     }
    },
    "d29822c2772c48e9937c807b1ba9c122": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d63dc278554b488ea43130ea12fe51bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7d5a91924dc489686a058d1275f6a86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efa620552f5441769b01d6c84852d37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f646e12209af4fa68ac5bf0fc0bed041": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b39f350b83b48d5ae34558811204646",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_374d23c2cf38408f9d3d7afd6cf0e663",
      "value": 898823
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
