,original,paraphrase
0,"therefore, for languages like chinese and japanese, which are written without spaces between words, tokenization boils down to string matching.",thus tokenization boils down to string matching in languages like chinese or japanese which have no spaces between words.
1,"similar to these subtopics, feature representation is put as another important section deserving detailed descriptions, since feature representation, as an indispensable basis, is highly correlated with each of the three subtopics.","as the feature representation is of course a fundamental component in any of these three subtopics, it is placed as another crucial piece that deserves detailed descriptions."
2,these clusters are ranked by collection selection to determine which clusters to search.,these clusters are ranked by collection selection based on how to distinguish which clusters to search.
3,"however, the behavior network is realized by running some random process over the potential network which samples vertices and edges from it to produce the behavioral network and in some cases adds additional edges.","an additional step in generating the behavioral network is to run some random procedure over the potential network and sample vertices and edges from it, so that a behavioral network can indeed be constructed."
4,"how well the code is performing, the percentage of potential instruction execution and memory bandwidth used by the kernel is output.",this output includes information about the code s performance and how much of the potential instruction execution area and the memory bandwidth the kernel has taken up.
5,"a targeted attack is the same as random removal, because the degree distribution is a delta function.",the specific attack is no different from random removal as the degree distribution is a delta function.
6,"in the ideal data case, we can see that the sequential methods outperform all the other algorithms in terms of runtime.",we observe that the sequential methods outperform the other algorithms in terms of runtime in the ideal data case.
7,this problem is well known as the domain shift problem in research community.,"in the research community, this problem is known as the domain switching problem."
8,"the unitbox demonstrates not only more accurate box prediction, but also faster training convergence.","the unitbox not only delivers a better prediction of the box, but also reaches faster training convergence."
9,"in modeling collaborative activities, it is essential that the system captures the agents intentions conveyed by their utterances.","our research suggests that the system captures the intention, conveyed through the words of agents, that is crucial to modeling collaborative action."
10,"we tune all the methods via cross validation, and report the average performance.","we tune all our methods using cross-validation, and report the sum-rates."
11,"the classic re problems, communication, incomplete requirements, inconsistent requirements and not enough time seem to dominate.","these are the classic relaying problems, communication failures, incomplete specification, inconsistent specification, and not enough time."
12,this graph can be also viewed as a data-flow diagram.,this diagram can also be regarded as a data flow diagram.
13,messages to its neighbors (agents it shares a constraint with).,messages to their neighbors (agents it shares a constraint with).
14,"for some schemas, checking compatibility between incoming and outgoing edges can be far from being obvious, as happens for the following one.","when checking the compatibility between incoming and outgoing edges in some schemas, checking the consistency is far from obvious as in the following example."
15,"if items have broad intrinsic value, then voting would show persistence over time and similar outcomes for independent subgroups.","if items are intrinsically broad, then voting would show continuous behavior over time and similar outcomes for independent subsets."
16,"it goes without saying, of course, that the views represented are my own, and that any factual errors are entirely my fault.","it goes without saying that the views expressed are my own, and any factual errors are entirely the fault of me."
17,"we added more detailed descriptions, explanations and illustrations in various parts of the paper to make the work easier to understand.","to make the work easier to follow, we have expanded the descriptions, justifications, and illustrations in various parts of the paper."
18,we can convert it from a write-friendly structure into an optimized and compressed read-only structure.,we can be able to transform it from an uncompressed read-only structure to an optimized read-only structure with compression.
19,a chunk is registered by passing the control of the chunk object to the chunks and tasks library.,a chunk is registered by passing control over the chunk object onto the chunks and tasks library.
20,"suppose we want to ask the following meta-query: for each view name, give the cartesian product of its definitions.",we assume we need to answer the following meta-query: for each view name give the cartesian product of its definitions.
21,"in this section, levering the insights derived from our empirical study, we develop a predictive model that is able to identify the most promising enablers with respect to target papers.","in this section, we develop a prediction model that can predict which enablers are more promising in the context of target papers by exploiting insights gained from our empirical investigation."
22,"it can handle moderate-size datasets, but can not scale to large-scale datasets.","the model can handle moderate datasets, but has no ability to scale to large datasets."
23,the proxies were installed just as they exist on the production memento machines.,the proxy s servers were installed exactly as they would be seen on the production memento machines.
24,"before we proceed with the argument, some comments are in order.",we make some observation before proceeding to the proof of the proposition.
25,more than two decades have passed and the question still remains open.,we must remember that this question has remained open for more than two decades.
26,"then, a possible adaptation could be a variable pitch, smaller at the ends and higher in the middle.","thus, variable pitch, skewed toward the endpoints and higher towards the middle would be a possible adaptation."
27,"multicast, or transmit different portions of its packets to different destinations, viz.","multicasting or distributing, or by sending different portions of its packets to different receivers, viz."
28,we will start with some rudimentary examples and gradually build up a toolkit for general networks.,"we begin with some rudimentary examples, and develop this toolkit gradually for general network systems."
29,polymorphic predicates are very useful because they can be used for different types.,polymorphic predicates are useful because they can be applied to different types of occurrences.
30,"the word detection stage generates bounding boxes around words in an image, while the word recognition stage takes the content of these bounding boxes and recognises the text within.","the word detection stage creates bounding boxes over words, while the word recognition stage retrieves the content of the bounding boxes and recognises the text inside them."
31,matrix completion is a reliable estimator to predict unobserved entries.,matrix completion is a reliable estimator that can predict the outcome of unobserved events.
32,but in a relatively unstable network because link quality is continuously changing initial phase is repeated and serious overhead occur.,"however, severe overhead happens in a relatively unstable network because the link quality is continuous, a temporary process in the initial state is repeated, and the link quality changes with time."
33,the benefits from having this much larger space to explore may not be worth the trade-off of the time it takes to find it.,"if this much wider area were available, the benefits of having this much larger area to explore might be worth less than the time spent finding it."
34,"a similarity measure can be calculated by dividing the total length of the common sub-strings by the minimum, maximum or average lengths of the two original strings.","a similarity measure can be computed by dividing the average lengths of the common sub-strings by the minimal, maximal or average lengths of the two original strings."
35,we can do it more sophisticatedly and further reduce the diameter of the graph.,we can do this more precisely by further reducing the diameter of the graph.
36,we can compute statistics about the relevance of features by looking at which features are good predictors of the class labels.,we investigate which features can be used to compute the criterion of relevance statistics for class labels.
37,"the output of the algorithm, that is the isolating boxes of the real roots can be seen in fig.",we can see in fig.
38,"despite the importance of software quality, its management is still an immature discipline in software engineering research and practice.","yet, software quality management remains an immature discipline in software engineering research and practice, despite its importance for software quality."
39,bits are unpacked from the signature and added into the accumulators.,bits are pulled from the signature and appended to the accumulators.
40,"in the recent years, our society has experienced the rise of new ways to communicate and relate among each other through digital devices.","in the past few years, the adoption of digital devices has provided our society with many new opportunities to communicate and relate to each other."
41,"for each batch, categorical-cross-entropy loss is generated for each sequence by comparing the predictions with the ground-truth.","each sequence is concatenated by the prediction with ground-truth, generated as the categorical-cross-entropy-loss of each batch."
42,"adds a new (overloaded) method that converts the input to a token iterator (details omitted for brevity), transitions according to that iterator, and then returns whether the string is accepted.","adds a new (overloaded) method that sets the input for a token iterator (details omitted for brevity), transitions according to that iterator and returns whether the string is accepted."
43,a pure node is a node not holding the message or any of its replicas.,a pure node is a node that holds neither the message nor any of its replicas.
44,"we plan to explore differences along other human factors which can be collected from self-reported user metadata like age group, gender, profession, etc.","we plan to explore difference in other human factors that can be collected from self-reported profile information of users like age, gender, professional experience, etc."
45,tags can influence each other over a long distance via transition probabilities.,tags can be influenced by each other over a wide geographic area through transition probabilities.
46,"hence, quality models need more structure and detail to integrate them closely in the development process.",this provides a high degree of structure and detail for quality models to integrate more closely within the quality development process.
47,the acronyms csi-tr in the legend corresponds to the case where the csi is available at both transmitters and at the receiver as well.,"in the legends, the csi-tr is defined as a case in which the csi is available at both the transmitter and the receiver."
48,a large amount of research has focused on how possibility distributions can be used to assign a meaning to rules.,a large body of research has focused on how probability distributions can be used to assign meanings to rules.
49,a student does not understand a lecture and scores poorly in the exam.,it occurs when a student fails to understand the lecture and scores poorly on an exam.
50,"in the real world, one single object may have different representations in different domains.","for example, in real world systems one single object may have various representations across multiple domains."
51,we pick an agent at random (this is the target agent) as well as one of its four neighbors,we assume that a given agent (the target agent) and one of its four neighbors are chosen at random.
52,the only thing that distinguishes between them is the identity of the nodes.,the only difference that distinguishes them is the identity of the nodes involved.
53,"consequently, formulating and maximizing expected profits which is a function of all these static and dynamic quantities is significantly harder.",this considerably makes it a difficult task to formulate and maximize expected rewards from all these static and dynamic quantities.
54,"then, the total cost is calculated among all the bins and the cycle is permanently assigned to the bin which results in the lowest total cost.","then, we compute the total cost among all the bins and permanently assign the cycle to the bin that gives the lowest total cost."
55,these antennas are used to create artificial channel fluctuations to restore the transmission opportunities.,these antennas are used to introduce artificial channel fluctuations to restore transmission opportunities.
56,these two similarities are then averaged for the final template level score.,these two similarity measures are then averaged to give a final template level score.
57,these blocks can be detected by looking at the standard deviation or maximum absolute deviation of pixels intensities.,such blockages can be detected by looking at the standard deviation or maximum absolute deviation of the intensities of pixels.
58,all log entries resolving to the same town or city were assigned the same latitude and longitude.,we assigned the same latitude and longitude to all log entries resolving to the same town or city.
59,a comparative scale is an ordinal or rank order scale that can also be referred to as a non-metric scale.,this is a metric scale for ordinals or rank orders which could also be seen as a non-metric scale.
60,"over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence.",phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence for the last ten years.
61,inference under uncertainty is a common problem in the real world.,a common problem in the real world is inference under uncertainty.
62,"while theoretically explaining the effect of dropout is difficult for complex models, we can still gain an insight by looking at an approximate surrogate.",although it is difficult in complex models to theoretically explain the dropout effect we can still get insights by looking at an approximate surrogate.
63,we experimented further with to see how changing the sketch and harness affects the output.,we continued to experiment with to see how changing the sketch and harness influences the output.
64,"if the assumption was correct, it is similar to the feedback strategy.",this is similar to the feedback strategy assuming the assumption is correct.
65,"in addition to these initiatives, there are search engines like pipl that try to collect as much personal information as possible from social networks about a particular person.","in addition to these initiatives, there also exists a search engine like pipl that tries to gather the most relevant personal information from social networks about a specific person."
66,we will talk about polynomial time algorithms in the theory meaning that they are represented by the corresponding function symbols.,we refer to polynomial-time algorithms with the theory meaning that they are represented by the corresponding function symbols.
67,data-driven approaches can yield comparable (and sometimes even more accurate) results than the rule-based approach.,the data-driven approaches can produce comparable (and sometimes even more accurate) results than the rule-based approaches.
68,"it yields an expectation-maximization algorithm for fitting the parameters which is highly efficient: each iteration takes linear time as a function of the number of users, items, and observed links.","it yields an expectation-maximization parameter fitting algorithm that is very efficient: the sum of all iterations takes linear time, as a function of the number of users, items, and observed links."
69,"additionally, applying continuous quality assessments using a quality model may improve the quality awareness of practitioners as they learn from the quality knowledge contained in the quality model.",it can also be argued that applying the quality model to continuous quality assessments can improve quality awareness of practitioners as practitioners learn about quality knowledge in the quality model.
70,"thus, we print with white, cyan, magenta and yellow materials.","we print with white, cyan, magenta and yellow materials, respectively."
71,there is a difference between the random baseline and the clustering solution.,there is a difference between the random baseline and our clustering solution.
72,so a component that is an odd sink is not useful for synthesizing compositions.,therefore a component that is an odd sink is not relevant for compositional synthesizing.
73,the first role is similar to any data processing pipeline; the unique aspect is the communication.,the first role is similar to any data pipeline; the unique feature is the communication.
74,"second, we use hand-crafted rules to extract simple sentences using the dependency structure.","second, we use a rule-based system to extract simple sentences and exploit the dependency structure."
75,the second paper improves upon the first by employing an earlier pass of non-discriminated embedding learning to obtain vectors used to represent the contexts.,"the second paper, develops upon the first paper in providing a refinement of the previous step by using a non-discriminative embedding learning to learn the vectors which represent context."
76,"if the input permutation is odd, the permutation in one bin should be odd.","such a permutation means that if one of its bins is odd, then its input permutation has to be odd."
77,"secondly, agents can contribute effectively towards self-management, hence reduces management responsibilities on an administrator.","second, the agents can contribute effectively towards the self-management, hence reducing the burden of control on the manager."
78,"with such a large dataset of what is being said online ready to be processed by a computer program, the possibilities are infinite.",the possibilities are infinite when the available online discourse is such a large dataset ready to be processed by a computer program.
79,so we see that forecaster is losing utility because of her local predictive commitments.,this shows that the prediction process loses utility due to its local adversity.
80,"originally, integrity constraints were introduces to prevent incorrect updates and to check the database for integrity.","in the original work, integrity constraints were introduced to prevent inadvertent updates and to check for integrity of database entries."
81,one way to tackle this problem is to replace the inner table with a set of pointers.,a one-step solution to this problem is to replace an inner table with a pointer set.
82,"elektra uses the pee, such as configuration files, to initialize contextual values.",the initialisation of contextual values is done by elektra using pes such as configuration files.
83,"in this respect, the use of binary decision diagram (bdd) is very effective by compressing search space through generating a unique and succinct representation of a boolean formula.","the application of boolean decision diagram (bdd) to this problem has significant potential benefits, as it can compress the search space by generating unique and succinct representations of the boolean formulas."
84,the network becomes more sparse and some minor characters might become completely disconnected from the main narrative.,this process could reduce the network to becoming sparse and some minor characters could become completely disconnected from the main narrative.
85,"for example, during detection, the distribution should capture the statistics of the errors made by using the face detection bounding box to provide a shape estimation.","for example, a bounded face detection bounding box should capture the statistics of the error of the boolean curve during detection."
86,"in particular, image processing provides several problem instances where there is a need to relate different regions of the image.","for instance, there are several instances of a problem in image processing, where different regions of the image are needed to be connected."
87,"now for the inductive step, suppose we add an extra-gadget.",now suppose we add a gadget to the induction step.
88,"the focus is mostly on utilizing within-document features, such as term frequencies.","we focus mostly on the use of within-document features, such as term frequencies."
89,"more generally, most of the values in the table can be computed using the results from the paper.","more generally, most of the table values are computed using the paper results."
90,"politically, this is a questionable proposition, as it may sound as an admission of weakness.",this is a questionable proposition from a political point of view as it may seem as if our policy follows a weakness.
91,"like all the very, very best theoreticians, alan has a terrific intuition about what is in the tapestry of coherent beauty that binds together the structure of computation.","alan has the olfactory intuition, as do all great theorists, about the threads of coherent beauty that bond the computational fabric."
92,the first model is a rather raw but revealing way of extracting an unweighted structure from the weighted graph by filtering out edges with low enough weights.,the first model is rather crude but illustrates how the unweighted structure of a weighted graph can be extracted from a weighted graph by filtering out edges with small enough weights.
93,wireless link quality settings are the same to the previous section.,the quality setup for wireless links is similar to the previous section.
94,"workflow software provides very elegant technical solutions to the challenges of communication between diverse software tools, capturing provenance in graphically driven interfaces, and handling issues from versioning dependencies to data access.","workflow software gives very elegant technical solutions to challenges, which are managing communication between disparate software tools, capturing provenance through graphical user interfaces, and dealing with issues ranging from versioning dependencies to data access."
95,many methods designed for time series forecasting perform well (depending on the complexity of the problem) on a rather short-term horizon but are rather poor on a longer-term one.,many methods for time series forecasting perform very well (depending on the complexity of the problem) at rather short time scales but perform poorly at too long time scales.
96,"the internal tree nodes are represented as real-valued vectors, of the same dimensionality as word and document vectors.",the internal tree nodes are represented by real-valued vectors having a similar dimensionality to the word and document vectors.
97,"remarkably, they were able to train this multi-stage network with relative success.","remarkably, this multi-stage network was trained with relative success."
98,we divide the square region into different non-overlapping subregions based on the different border and corner effects that occur in that region.,"according to the different border and corner effects that exist in a region, we partition the region into multiple, non-overlapping subregions."
99,"additionally, all of these models rely on variational inference to learn the models.","additionally, all of these models use the variational inference approach to learn models."
100,"thus, modern industrial recommender must be flexible enough to address different tasks (recommend a sequence, extend a list, personalize a list, etc.","the modern industrial recommender should thus be flexible enough to cope with a variety of tasks (recommend sequences, expand a list, personalize lists etc."
101,"partition density was introduced specifically for the case of link communities, where links instead of nodes are partitioned into groups.","the sparse-parity inequality was introduced for the specific case of link communities, in which the links are partitioned into groups instead of nodes."
102,visibility is the probability a user finds the resolve during a visit to the site.,visibility is the probability a user discovers a resolve on the site while browsing.
103,they are also likely to be videos that were uploaded by the course staff for testing purposes.,this could also be a video created by the course staff for testing purposes.
104,"indeed, these peaks are in most cases identified as outliers.","indeed, most of the peaks are identified as outliers."
105,"since we are assuming that all the users have the same distance from the access point, they all have the same channel gains.","since we assume that all the users have the same distance from the access point, their channel gains are not comparable."
106,"this distance is easily accurate enough to tell when a person goes home, what areas a person drives through, and can identify many destinations of a driver.","distance is easily and confidently accurate enough to tell when a person goes to sleep, what areas a person drives through, and to identify the destinations of a driver."
107,a group is a community of agents who show some common properties or behave similarly in certain aspects.,"group is the community of agents, which have certain common property or have behavior similar to one another in some of its aspects."
108,"so, the additivity of these quantities can be related to the additivity of distinguishability for unitary operations.","hence, the additionity of these quantities may be related to the additivity of distinguishability of unitary operations."
109,"even though cricket is the second most popular game in the world after soccer, compared to other professional sports it has been relatively understudied by academics, although there is no dearth of match statistics.","while cricket is the second most popular sport in the world after soccer, compared to the other professional sports, it has been relatively understudied by academics, although there is no shortage of match statistics."
110,systems such as ebay or amazon implement reputation mechanisms which are partly credited for the businesses success.,system like ebay or amazon implement reputation mechanisms which partially explains the success of the seller s business.
111,"this is common in service oriented processes, like the first-come-first-serve execution of orders in a restaurant or getting help from directory assistance and consumer support.",such cases come naturally in service-oriented processes such as the first-come-first-serve order ordering in a restaurant or the request for help from directory help or consumer support.
112,"of course, the previous paragraph is just an intuitive handwave, not a proof.","naturally, the intuition in the previous section is simply for intuition, not a proof."
113,these end up in the places at the end of those arcs.,they are stranded on the ends of such arcs.
114,"even with a strictly positive transition matrix, this condition does impose additional restrictions.",this condition presents additional constraints even if the transition matrix is strictly positive.
115,"various aspects of building production pig workflows using oink, such as scheduling, resource management, error handling, notifications, etc.","all aspects of building production pig workflows with oink, such as scheduling, resource management, error handling, reporting, etc."
116,"because word usage frequency is so variable, great care must be taken with any analysis.",recurrences are so variable that great care must be taken with any analysis concerning word usage frequency.
117,"one of the efficient approaches in this dynamic market is to develop demand side management, which allows the service providers and network nodes to interact like in smart grid, to guarantee energy-efficiency and reliability.","development of demand side management based on a centralized control which enables the service providers and network nodes to interact, as in the smart grid, to guarantee energy efficient and reliable operations is one of the most efficient approaches in such dynamic market."
118,evaluation is closely related to manipulation as the following result illustrates.,the above result illustrates that evaluation is closely related to manipulation.
119,fortunately it is possible to break down the variety of activities available to users into a number of primitive actions.,"fortunately, the rich variety of activities available to the user can be broken down into a set of primitive actions."
120,the extracted tuple is associated with a marginal probability that it is true.,the extracted tuple has marginal probability that it is true.
121,it is important to realize that outcome stability is dependent on input matrix particulars.,we note that the stability of the results depends on the details of the input matrix.
122,"they take different standpoints for looking at specifications and verifications, and offer complementary advantages.",the two different perspectives on specification and verification look at implementations from different viewpoints and offer complementary advantages.
123,examples demonstrating the use of the software are also available from the authors.,the authors also provide examples to illustrate the usage of the software.
124,it is a simple greedy search strategy that updates one label at a time.,it is a simple greedy search strategy where one label is updated at a time.
125,"since there is nothing to suggest that a logarithmic scale is relevant, the logarithmic odds ratio gives rather poor result as expected and we omitted it.","the logarithmic variance relation is rather poor, as expected, and therefore we omit it because nothing suggests logarithmic scaling importance."
126,the box is called magic because neither agent can make out its depth.,the box is called magic because neither agent can explore its depth.
127,the criteria used here to set the filters parameters will be discussed later.,we later discuss the criteria used to tune the filters parameters.
128,a predator is an animal that hunts and kills other animals (its preys) for food.,prey is an animal that hunts for food by hunting and killing other animals (its prey).
129,"rowland also implemented this method in a mathematica package called binomialcoefficients, available from his website.","rowland also implemented it in a mathematica package called binomialcoefficients, available from his website."
130,this approach attempts to balance reuse and innovation in an integrated architecture.,this approach aims to create an integrated architecture that achieves a balance between reuse and innovation.
131,it has the effect of dividing the evidence from a training instance across all possible categories for the words.,it has the effect of ranking the proof against a training instance across every possible category of words.
132,"nonetheless, if we have negative literals or prolog built-ins, this is no longer true.","nevertheless, if negative literals and prolog built-ins are available, this no longer holds."
133,the channel state information (csi) is supposed to be known to the receiver but not to the transmitter.,we presume that the receiver but not the transmitter has information about the channel state information (csi).
134,"certainly, inaccuracy by itself would not take place if we were aware of it.","indeed, even if we knew about inaccuracy, it would have never taken place in the presence of it by itself."
135,"belief can run on any android system and it is available on googleplay, to date, the biggest commercial website for android applications.","belief is a free and open-source app available on googleplay, the largest commercial android application marketplace to date, and runs on any android-based system."
136,"hence, hyper-pooling postulates that we can get a more stable set of centers by applying a clustering algorithm (such as k-means) on the set of components relating to the highest eigenvalues.","hence hyperpooling postulates that a clustering algorithm (like k-means) can give us a smaller number of centers, by clustering the aforementioned elements containing the most significant eigenvalues, and that this method can generate more stable sets of centers."
137,an approach that relies on an estimation of the parameters using maximum likelihood can be used.,there is an approach that makes use of parameter estimation using maximum likelihood.
138,this is the first paper that considers a machine learning setting where the input consists of default rules.,this is the first paper to consider machine learning settings where the input consists of pre-defined rules.
139,"training increasingly accurate image classifiers does not lead to better captions, after a point.","we should note that, after a certain point, learning increasingly accurate image classifiers does not necessarily lead to better captions."
140,"we can encode the quotient by giving, for each neighbor, an ordered pair of integers.",it is not at all simple and we can encode the quotient by giving an ordered set of integers per neighbor.
141,one of the main difficulties in building a model is choosing the right algorithms to apply to the training dataset.,the choice of an algorithm for applying the model to the training dataset is one of the main challenges in model generation.
142,at the ends of paths there are simply too few features to make this distinction.,there are simply too few features to make this distinction at the ends of paths.
143,"as we are mainly interested in user navigational behavior, we have extensively filtered the logs.","the logs have been extensively filtered out, as we focus on the navigation behavior of users."
144,the removal of a small number of nodes or edges of the network can lead to a breakdown of functional processing.,the removal of a small number of nodes or edges of the network may lead to functional processing breakdown.
145,"such scenarios are challenging because information is spread across the agents and possibly multiple layers, and networks, by themselves, are not the decision makers.",these scenarios are challenging because the information spreads across the agents and potentially multiple layers and the networks are not decision makers in themselves.
146,this can be viewed as statistically multiplexing the packet streams from different user groups.,"then, the packet streams from various user groups can be interpreted as statistically multiplexed."
147,"another way to evaluate the quality of the word embeddings is to use the word vectors to compute document representation, which can be evaluated with document classification tasks.","another approach to evaluate word embedding quality is to exploit word vectors to compute document representation, which can then be evaluated against document classification tasks."
148,it offers a sound and fully automatic technique for test case generation with a good code coverage.,"it is a sound, fully automatic, test-case generation technique that guarantees good code coverage."
149,here is an example of a more exotic version of the latter result (which probably is of no interest in itself but just serves as an illustration of the technique).,"we show an exotic version of the latter result (which, perhaps, is not interesting in itself, but is there to illustrate the technique)."
150,"evaluating causal relations in neural systems: granger causality, directed transfer function and statistical assessment of significance.","neural systems with causal relationships: granger causality, directed transfer function and statistical significance assessment."
151,"below this value, the bit energy increases as the sum spectral efficiency decreases.","as the sum spectral efficiency decreases, the bit-energy grows below this threshold."
152,"lastly, a probability is calculated which represents the probability that the newly discovered user attributes actually belong to the searched user.","finally, a probability is calculated that represents the probability that the newly discovered user attributes belong to the searched user."
153,"how much transmit power sensors have to use for successful transmission? and, how the wireless channels affect the performance","how does the number of transmission powers needed for successful transmission depend on the number of wireless channels? and, how do the bandwidth constraints affect the performance of wireless channels?"
154,the following procedure shows how to transform multiclass examples into binary examples for each non-leaf node in the tree.,how to transform a collection of multiclass examples into binary examples for every non-leaf node in a tree is described in the following procedure.
155,"typically, deepdiveis used to learn the weights from data.",deepdiveis typically used to learn weights in the data.
156,"for example, employing a model of soft clustering will make the clustering process more flexible but also make the learning process more computationally demanding.","thus, soft clustering model implementation would, in general, make the clustering process more flexible but also make learning more computationally demanding."
157,"since search plays a larger role with age, older nodes are less biased in their connections.","the older nodes will be more biased in their connections, since the search plays a more important role as they age."
158,a popular policy search method is to update policy functions via gradient ascent.,gradient ascent-based policy updating is a popular policy search method for updating policy functions.
159,"indeed, rather than reinventing the wheel and designing a new sublanguage for syntactical manipulation of stored queries, it allows us to use the standard xml transformation language xslt for this purpose.","indeed, it means that we can use the standard xml query transformation language, xslt, as a central tool rather than reinventing the wheel and designing a new sublanguage for syntactical manipulation of stored queries."
160,"once all items are assigned to their groups, a grouping solution is generated.","once all items have been assigned to their clusters, a clustering solution is generated."
161,"this makes the semi-supervised learning paradigm, which is able to utilize both labeled and unlabeled data, attractive in many sentiment analysis and text classification tasks.","this makes semi-supervised learning paradigm an attractive paradigm for a number of sentiment analysis and text classification tasks, as it could take advantage of both labeled and unlabeled data."
162,any action that would take the system outside of the environment moves the system to the nearest boundary.,any action that leads the system outside of its environment moves it towards a close-by boundary.
163,sentence planning::: many names have been used for this process; here i use one suggested by rambow and korelsky.,"sentence planning:::::::,:::: many names exist that represent this process; i use one proposed by rambow and korelsky."
164,computers are physical systems and information has to be stored and transmitted using physical devices.,computing systems are physical systems and information should be stored and transmitted using physical devices.
165,"do they become quaternions, colored graphs, or sick-humored gremlins?","can they become qkds, colored graphs, or sickly gremlins?"
166,it integrates four different emoji resources from the web to extract emoji senses and align those senses with babelnet.,it employs four methods of extracting emoji senses from online collections and aligning these senses with those supported by babelnet.
167,clustering is another useful technique to identify the different patterns in the data sets.,another useful technique for distinguishing the different patterns of a data set is clustering.
168,"however, it is also possible that, looking back into the past, an individual was created by copying from another subpopulation.","however, it is possible that, looking back at the past, one had a copy of individuals that came from different subpopulations."
169,"the complete tool, including its various views and algorithms will be available for the users to explore.","we will invite the users to explore the fully conceived tool and its multiple views, algorithms, and methods."
170,"in addition to data analysis, users sometimes need to simulate event samples of the order of a few tens of thousands of events.","when using hdma, some users require the simulation of event samples of order of tens of thousands of events per year, which is outside the scope of data analysis."
171,i noted at the outset that cultural expectations responsible for a lack of code sharing practices in many fields are a far more extensive primary barrier to reproducibility than the technical barriers discussed here.,"i noted in the outset that there are much more widespread primary barriers to reproducibility than the technical barriers considered here, which are cultural expectations that are responsible for the lack of code sharing practices in many fields."
172,"ideally, the empirical datasets would each come with a complete ground truth, just like the synthetic datasets.","it is ideally fair to assume that empirical datasets are all complete ground truth, just as synthetic datasets are."
173,"the performance of ul transmission for the edge users is much more complex, as seen below.","the performance of ul transmission for the edge users is much more complex, as we see in fig."
174,"to do so, we use a non-asymptotic mean field approach over function space.","then, over function spaces, we employ a non-asymptotic mean field approach."
175,"however, the integrity of state estimation is under mounting threat as we gradually transform the current electricity infrastructures to future smart power grids.","however, as we transition from the existing electricity infrastructures to the future smart power grid, the integrity of the state estimation becomes ever more vulnerable."
176,handling capacity is a key ingredient that needs to be prescribed upfront.,the key ingredient for predicting the capacity need to be handling capacity is the tolerability.
177,the aim is to provide some invariance to where exactly the activation is positioned within the input window.,the goal is to provide a small amount of invariance on how precisely the activation lies within the input window.
178,"the green circles denote the source and media, while the blue circles denote processing methods applied on the source and media.","the green circles denote the sources and media outlets, while the blue circles denote the processing methods applied to the sources and media outlets."
179,"it offers several novelties compared to existing sets, including template based, rather than image based, recognition and a mix of both images and videos.","the new generation of psmrs offers several unique attributes over existing datasets, including template-based vt instead of image-based vt, recognition, and mixing of both image and video features."
180,the fourth ones are the percentages of the gap between the second and third columns.,the fourth one is the percentage of the gap between the second and third columns.
181,"the ellipsis is part of the syntax for writing macros, which can be thought of as a meta-language for scheme.","the syntax of writing macros can be thought of as a meta-language for schemes, since they are implemented by the ellipsis part."
182,"roughly speaking, a schema or dataguide is a kind of structural summary of semi-structured data.",", roughly speaking, a schema or a dataguide is a sort of structural summary of a semi-structured dataset."
183,"turn each of the lists from a list of tuples to a list of integers, using the separators, as described above.","the list represents the same as above, in which we can turn each entry of a list from a tuple to a row of integers, as represented by a separator."
184,"winning strategy, then no game position will be repeated until capture takes place.","strategy winning, then no game position is repeated until capture is achieved."
185,the choices we have made are for ease of presentation and to make the connection with as simple as possible.,our choices are based on a simple presentation problem and to make a connection as simple as possible.
186,"it also happens to require less information than ds and xs, the other top performers.","as it happens, fds and xs, the other three top performers, require less information."
187,"so it is important, even in practice, to get a better understanding of motorcycle graph computation.","thus, getting a more complete view on motorcycle graph computation is important, even in practice."
188,a valuation is a function that provides possible elements of a field for variables.,a valuation is a function that provides a set of potentially possible strings for variables.
189,"while cross-validation has many advantages for certain tasks, an often mentioned disadvantage is that it is computationally expensive.","while cross-validation can provide a wide range of advantages for certain tasks, a much-mentioned disadvantage is its computational cost."
190,"as part of our future works, we will continue to investigate this problem, trying to understand what properties the other solutions have and how we can extend our algorithm to find them all.","this problem will be investigated in future work, and we will try to understand what properties other solutions possess and how to extend our algorithm to find all of them."
191,both algorithms have been compiled with the same options and run on the same machine under the same conditions.,we compile both algorithms with the same options and run on the same machine under similar conditions.
192,"therefore, expressions using set difference evaluate to empty or nonempty on both graphs simultaneously.","therefore, expressions using set difference evaluate to empty or nonempty on both graphs concurrently."
193,"tags are usually not informative about capitalization, but probability distributions of tags around capitalized words are different from those not capitalized.","capitalization information is generally not interesting, but the probability distribution of tags for capitalized words differs significantly from those for uncapitalized words."
194,the first example is about movie ranking on a subset of netflix data.,we focus on the movie ranking in a subset of netflix data in the first example.
195,we computed the average intensity of eye regions and asked the user to adjust lighting conditions if the average intensity was below a threshold.,"we computed the mean intensity for the retinal regions of the eyes, and asked the user to adjust the lighting conditions, if the average intensity is below a threshold."
196,these mechanisms will then be applied to computer networks to see if they can lead to faster recovery after failure.,we then apply these mechanisms to computer networks and see if they lead to faster recovery from failures.
197,"how does the volume of incoming email, information or email load, affect user behavior?","how do email arrivals, the information the email provides, and email load affect user behavior?"
198,let us now look at a sample domain to see how it can be represented in our framework.,we now turn to a sample domain to see how it can be represented by our framework.
199,it is important as it allows us to restrict the scope of searches for constrained explanations.,this is of interest as it allows us to restrict the scope of the searches to finite explanations.
200,the coverage is a common summary that represents the number of features overlapping each position in the reference sequence.,coverage is a generalized summation which describes the number of features overlapping each position in a reference sequence.
201,these methods require a few manual engineered components such as the content to be classified and the template.,the only major feature that makes these methods different is that a few manually engineered steps such as the content being categorized and the template must be prepared for the purpose of determining these.
202,"the action predicate specifies the precondition, effect, and cost of each of the actions.","each action predicate is defined by a context that predicates action predicate functions, the set of effects and the cost of each action."
203,"specifically, fault-detection is accomplished by polling a process and waiting for a response or a timeout.","specifically, fault-detection is performed by polling the process and waiting for a response or a timeout."
204,"recommendations play an important role in supporting software development, especially in larger teams: locating experts for a given problem is one of the main challenges when working in a large team.","recommendation plays a central role in supporting software development, especially in large teams: finding experts to tackle a given problem is one of the major challenges in managing a large team."
205,an important feature of is that it can also estimate the number of nodes of each type while nsum can not.,"the uniqueness of is that it is capable of estimating the number of nodes of each type, whereas nsum is not capable of doing so."
206,"to construct all the various training and testing datasets, we performed the following steps: first, we manually matched pairs of users which were members of both networks.","first, we manually matched users whose paths were members of the same two networks and performed a large number of training and test datasets together."
207,we choose the contour so that it detects the first zero to cross the imaginary axis and acquire a positive real part.,we choose the contour so that the one which encounters the first zero will be the one that crosses the imaginary line and we obtain the positive real component.
208,this can be achieved by selecting a certain bit sub-pattern in the input vector.,this can be accomplished by choosing a certain bit sub-pattern for the input vector.
209,they use the quality characteristics to aggregate measurements to an ordinal scale.,quality features are used to aggregate measurements from ordinal scales.
210,cyclo-cross is a relatively new sport that typically takes place in winter and is dedicated to cycle road-riders who are preparing for the new season.,"cycling is a relatively new sport, typically taking place in the winter, and is dedicated to cycle road runners preparing for the coming season."
211,we set the granularity of the delta to be in days to match the real dates in the gold standard dataset.,"we applied our method to the gold standard dataset, and made the data granularity to days to correspond to the actual dates."
212,"in recent years, github, a hosting platform for software projects, has gained much popularity among a large number of software developers around the world.","github, a web hosting platform aimed at software projects, has gained much popularity among many software developers throughout the world in recent years."
213,"secondly, we need to take the weights attached to the rules, which we interpret as certainties, into account.","next, we need to take into account the weights corresponding to a set of rules we interpret as certainty."
214,one potential solution to mitigate the drawbacks of checkpointing is to proactively probe the core for failures.,one possible solution to mitigate the drawbacks of checkpointing is to proactively probe the core to identify possible failures.
215,"time series forecasting is a problem encountered in many fields of applications, as finance (returns, stock markets), hydrology (river floods), engineering (electrical consumption), etc.","time series forecasting is a difficult problem with frequent applications in different fields, such as finance (returns, stocks), hydrology (river floods), engineering (electricity demand), etc."
216,"interestingly, significantly improved the previous results without needing any parameter tweaking.","interestingly, it turned out that we could improve the previous results significantly without any parameter tuning."
217,"additionally, every leaf node has a second label, which is either yes or no.","additional annotation is present in the second label assigned to every leaf node, which can be either yes or no."
218,"after each choice, we will remove some items from the remaining by the following rules.","after each choice, we remove some objects from the rest according to the following rules."
219,this includes defining node states as well as filling the npt for each node.,this includes defining the states of nodes and filling in the npt for each node.
220,"in particular, i would like to thank him for the insightful discussions, and, especially, for his invaluable help in the preparation of this paper.","i would like to thank him for insightful discussions and, more importantly, for his invaluable help in the preparation of this paper."
221,"therefore, by invoking these three parts tradeoff in the performance index, we can characterize the properties of the tracking capability and the communication ability.","therefore, we can characterize the properties of the tracking capability and the communication capability by encoding these three parts tradeoff in a performance index."
222,"energy providers plan the installation of wireless sensor networks within power substations, where the channel is different from what the classic wireless communications are expecting.","we propose that energy providers design wireless sensor networks in power substations, whose channel may differ from the standard one for wireless communications."
223,it can also be used by a physician to abduce symptoms and other conditions that must be met by a given treatment recommendation.,a physician may also use it to suggest symptoms or other conditions which need to be met for a certain treatment recommendation.
224,it appears to be an unavoidable aspect of any system that aspires to human-like intelligence.,this seems to be an unavoidable feature of any system that strives to achieve human-like intelligence.
225,"also known sometimes as blocks), and one mapper is launched per split.",mapper is launched once per partition (also called blocks).
226,this test comprised the reading and writing tests and the subjective-skills questionnaire and allowed us to compute how much the children had improved in either of the conditions.,"this involved the reading and writing tests, a sub-skills questionnaire, and let us compute how much the children had improved in either condition."
227,"perform better, on both real and synthetic examples, than those same forecast methods working with reconstructions that are built using the traditional methods mentioned above.","the same prediction methods working on reconstructions built by traditional techniques are shown to perform better on both real and synthetic examples, in both experiments and synthetic experiments."
228,the neighborhood of each agent is defined by an adjacency matrix that can have fixed or variable connectivity (fixed or power-law) and a regular or stochastic character.,all of these queries follow a fixed or a variable connectivity matrix between each agent and his neighbor (restricted or power-law).
229,these two estimators should be combined to form a powerful decoding framework.,let us combine these two estimators to build a powerful decoding framework.
230,"to begin with, the following proposition tells us that a loop can be defined without mentioning a dependency graph.","initially, the following proposition shows that a path can be defined without mentioning any dependency graph."
231,"on the other hand, shows the fraction of the largest component with respect to the total network size in the pertaining year.","on the other hand, the number of major players, relative to the total network size for the corresponding year, shows their fraction."
232,"this tiny example captures the essence of a common type of program; there are many programs which, for example, create a list, work on the list, and then destroy the list.","this small example captures the essence of the most common type of programmer; many programs for instance start a list, work on the list, and then npaste the result back into a list."
233,this model can be used to categorize web pages and is useful to generate information such as the similarity and relationship between different web sites.,the model provides a means to categorize web pages and is useful to generate inferences about similarity and mutual interest between different web pages.
234,we used a logistic function to score potential matchings between candidates and hiring institutions.,we used a logistic function to score the potential matches between candidates and hiring institutions.
235,"in contrast, finding out how payments affect payoffs requires the manager to know how the users value payments relative to data rates.","alternatively, figuring out how payments affect payoffs requires a manager to know how users value payments with respect to data rates."
236,these algorithms start from a random initial configuration (population) and use k-means to evaluate their solutions in each iteration (generation).,these algorithms start from an initial random configuration (population) and then use k-means to evaluate their solutions in each iteration (generation).
237,colours in panels (a-c) depicts the logarithm of the fraction of customers with the given measures.,the colourings in panels (a-c) depict the logarithm of the fraction of customers that satisfy the specified measures.
238,deep neural networks have been used with great success on related tasks.,similar tasks have been successfully implemented with the help of deep neural networks.
239,analysis tool plug-ins are used to execute the analysis tools within etb.,analysis tools within etb are used to execute analytics tools as plug-ins.
240,"therefore, we can use this knowledge to build sample xml documents that can be used as input to the algorithm.","hence, we can make use of this data to build a sample xml document model that can be used as input to our algorithm."
241,"since the new estimate is more accurate than the old one, the process can be repeated by estimating a new, more accurate prediction.","the process can be repeated with a new, more accurate prediction, since the new estimated estimates are more accurate than the old one."
242,in principle one wants to choose values of the hyperparameters that provide asymptotic consistency ,in essence one wants to choose hyperparameter values that provide asymptotic consistency.
243,another robot is piloting a helicopter to observe in which direction the fire is spreading most rapidly.,another robot pilots a helicopter to observe which direction the fire spreads fastest.
244,those methods are limited in lack of capabilities of adopting visual information.,lack of capacity to adopt visual information limitations these methods.
245,"they and many others since, developed and trained their systems using far fewer training images, at the cost of somewhat more elaborate network architectures.","however, these authors, and many others since, have developed and trained their systems using far fewer training images, at the cost of quite elaborate network architectures."
246,computer viruses and worms spreading through the internet have caused severe economic damages all over the world.,computer virus attacks and trojans have caused severe economic damage around the world.
247,the last row of the table reports the average values for corresponding columns.,the last row of each table reports average values of their corresponding columns.
248,"long lasting partnerships not only add runs on the teams score, it may also serve to exhaust the tactics of the fielding team.","prolonged partnerships are not only important in adding runs to a team score, but they may also be used to exhaust tactics of fielding players."
249,it also contains many plugins that implement scanning and testing an application.,it also contains many plugins that make scans and tests part of the application.
250,some common tendencies exhibited by authors include collaborations with the people from her own institute or with people sharing the same research interest with her.,collaboration with people within an institute or with other people with similar research interests to the author are two common patterns of behavior displayed by authors.
251,but i think we do that because we already know the person and the person already knows us.,"we believe this is the case because we know that a person already knows that person, and the person also knows that we do."
252,"equation describes the system dynamics encapsulating all aspects of object birth, death and transition while equation encapsulates all aspects of sensor detection and false alarms.","equation describes the system dynamics encapsulating every aspect of the object birth, death and transition, while equation is an umbrella term to address all aspects of the sensing and false alarms."
253,a version of this paper containing all proofs is available from the authors webpages.,the pages of the authors are the link to an extended version of the paper including all proofs.
254,the location (latitude and longitude) of each end user is randomly generated.,is performed randomly and each end-user s location (latitude and longitude) are established.
255,"otherwise, without this bayesian approach, each data point would give the same information (inversely proportional to the total number of candidate points).","otherwise, the number of candidate points would be the same for all datapoints without this bayesian approach (inequally proportional to the number of total candidate points)."
256,"meanwhile, data collectors that receive data from sensor nodes, are always ready to receive data from them.","the data collectors, on the other hand, receive data from the sensor nodes, and are always ready to receive data from them."
257,"this means that data can be reconstructed, after carrying out modifications in transform space.","this means that once modifications of the transform space have been made, the data can be reconstructed."
258,"this is because in many networks, edges are weighted and the weights usually present a high variance.","this is because in many networks the edges are weighted, and thus the weights usually exhibit high variance."
259,a strategy determines which step(s) of an expression to execute.,the strategy determines which expression step(s) to execute.
260,receivers closer to cell boundary have larger expected distance to the nearest transmitter.,receivers closer to the cell boundary have greater expected mr distance to the closest transmitter.
261,the base case corresponds to either an empty tree or a single node (root).,the base cases correspond to either a tree that is empty or the root has one nested node (root).
262,this condition is used as a filter when checking if some data is determinantal.,this condition is used as a filter to check whether some data is determinantal.
263,"the third way of introducing priorities is by changing the order in which customers are served within a queue, which is a popular technique to improve performance of production systems, cf.","the third strategy introduces priorities by changing the order in which the customers are served within a queue, which is a popular technique to improve the performance of production systems, cf."
264,the model as well as the quality assessments were highly understandable for practitioners and considered the best that can be done with static analysis.,this model was easily understandable for practitioners and considered the best model possible in terms of the quality assessment.
265,"informally, a fuzzy language consists of certain event strings associated with membership grade.","formally, a fuzzy language consists of certain event strings, associated with the membership grades."
266,"as with other approaches, the experiments were run on data sets orders of magnitude smaller and much lower dimensionality.",our experiments on the null hypothesis have been conducted on data sets orders of magnitude smaller and much lower in dimensionality than the other approaches.
267,sub-document clustering is now a possibility for large-scale document collections where splitting documents into fragments creates even more objects to cluster.,"clustering in subsets of documents is now an option for large scale document collections, where breaking documents into fragments creates even more objects to cluster."
268,it evaluates if and how well the software fits to what was intended.,these evaluation criteria evaluate whether the software performed as designed and how well it did.
269,"however, the learner can not expect such rich feedback.","however, learning cannot expect the learner to receive such rich feedback."
270,updating knowledge bases is an important issue in the area of data and knowledge representation.,data and knowledge representation is an important problem in a number of research areas for updating knowledge bases.
271,"the relatively recent discipline of data mining involves a wide spectrum of techniques, inherited from different origins such as statistics, databases, or machine learning.","data mining is a relatively new discipline and covers a wide range of techniques, inherited from diverse fields including statistics, data mining, and machine learning."
272,the importance of community lies in revealing the intermediate scales of network organization and identifying hidden structure in network theory.,community theory is relevant because of the discovery of intermediate scales in the network structure and the identification of hidden order structures in network theory.
273,"therefore, we will have to rely on simulations to assess the accuracy of the approximations.",therefore we will have to rely on simulations for a good approximation.
274,"secondly, collective resolution using relationships necessitates iterative solutions that make multiple passes over the data.","second, collective resolution involving relationships leads to iterative solutions that traverse the data multiple times."
275,"if we use the global classification error rates, they seem to perform well, however if we use the fitness value or look at fig.","we see that they perform well when using global classification error rates; however, they perform poorly when using fitness values and considering fig."
276,while the ease of use of a software library is subjective it can be quantified by the number of lines of code required for usage and compared against other libraries when using the same programming language.,"while the ease of use is subjective, the number of lines of code required to use and compare a software library to other libraries for the same programming language can be quantified."
277,"training and test sets were disjoint, results are averaged.",the training and test sets were disjoint and thus the results are the mean of both sets.
278,"however, the introduction of copy variables can be detrimental to decision privacy.","however, introducing copy variables may affect decision privacy."
279,"arguments can be value, which are copied to the task, or they can be input, output, or inout, which have the expected meanings.","input, output or input arguments with expected meanings can be in, out, or in, and they can either be value, that is copied into the task, or they can be either, or both."
280,"in other words, as information flows it incurs additional delays from each node that handles it.","this means, each node that handles this incurs additional delays as information flows proceed."
281,"for example, the diagram expresses that there is something which is both black and a bird (such as a crow).","the diagram, for example, shows that there is something which is both black and bird-like (say, a crow)."
282,"while it is a constant speedup, it is certainly not negligible.","although this is a constant speedup, it definitely is not negligible."
283,this approach introduces bias into the method because the same sample-set is used both for estimating the gradient and the baseline.,the method may be biased if two other methods are used for the gradient and baseline estimation using the same sample-set.
284,note that there are three distinct occurrences of this episode in the data sequence though we can have only a maximum of two non-overlapped occurrences.,"notice that this episode will occur at most three different times within a given data sequence, though we can have only one nonoverlapping time."
285,"there are many ways to represent curves and surfaces, therefore, the exchange of geometric data between those systems often requires approximate conversion.","curves and surfaces can be represented in many ways, and thus the exchange of geometric data between these systems often involves approximate conversions."
286,"also, this allows the algorithm to occasionally move away from being too greedy.","this also allows the algorithm to occasionally relax, leaving it too greedy."
287,"semantics, traces are possibly infinite sequences of states that a program run goes through.",semantics: traces are possibly finite sequences of states that are traversed by a program flow.
288,this algorithm assigns to each web page a measure of its importance or popularity based solely on the link structure of the web.,"based solely on web link structure, we have assigned to each web page a measure of relevance or popularity for that web page."
289,another reason is that xbinder generates code to ensure all of the restrictions related to user-defined simple types.,another reason is that xbinder generates code to guarantee all the restrictions associated with the simple types defined by the user.
290,this is a useful aspect of the algorithm that has great potential for cognitive and clinical neuroscience.,this is a useful feature of the algorithm that is attractive to cognitive and clinical neurosciences researchers.
291,the sets containing data sizes are copied onto the read-only memory of each sensor node during deployment.,"when the sensor node is deployed, it copies the set that contains the dataset sizes to its read-only memory."
292,we just perform some changes on it depending on the actions of.,"we then make some modifications to it, depending on the actions of."
293,we also fix refractory period for neurons (which is same for all neurons).,"in addition, we fix the refractory periods of the neurons in a loop (which are the same for every neuron)."
294,"unfortunately, this means that a human has to understand the problem domain and write down relevant meta paths before analysis can begin.","unfortunately, this means that analysis can only begin when an individual has enough knowledge of the problem domain to write the relevant meta paths."
295,follow same step as in previous section to find max score only among proposed splits.,simply search for max score among the proposed partitions by following the same steps as in the previous section.
296,"dealing with factorizations of fragments of a fixed text, it is more convenient to use a different quantity for this aim.","since we are dealing with factorizations of fixed text fragments, it is more convenient to use different quantities."
297,"however, one could use two independent normal meta-programs to encode our desired task.","however, one might use two independent normal meta-languages to encode our desirable task."
298,a classical channel model which characterizes channel uncertainty is the compound channel,the compound channel model is a classical channel model which characterizations the channel uncertainty.
299,"this criterion also assumes that decision makers are very risk averse, which is not always true.","this measure also assumes that decision makers are very risk averse, which is not always the case."
300,the hybrid approach acts as an umbrella bringing together the concepts of agent intelligence and core intelligence.,our hybrid approach provides a basis to unite both agent and core intelligence concepts.
301,"with packet generation, we can perform the zrp as an extension of the model in ref.",we can perform zrp as an extension of the model described in ref.
302,"it is more convenient to express proof reductions in terms of program reductions, because for that purpose the lambda notation is superior to the proof tree notation.","proof reductions can be expressed in terms of program reductions, as this does not require the lambda notation, which is superior to the proof tree notation."
303,what picture do we get when we zoom in on different types of users?,how much of the picture can be recovered by zooming into different type users?
304,these formats are designed to be easy for humans to read and programs to parse.,these formats have been designed to make xml code easier to read for humans as well as for parsing programs.
305,"their relationships play a role in determining if they are similar enough, and consequently, if they should be clustered together.","their relations guide us to determine if these relationships are similar enough and, consequently, if it is important to cluster them together."
306,"once everybody is online, the only thing that changes is browsing behavior.",the only thing that changes once everyone is online is browsing behavior.
307,"what players really share is the way how to behave towards each other under different circumstances, which is determined within the framework of an emotional profile.",we view the framework of emotional profiles as a measure of how well players actually share information about each other under various conditions.
308,"however, regardless of winning, we have the decision of whether or not to buy a yacht.","however, we still have to decide whether or not to buy a yacht regardless of the outcome of a race."
309,"for example, we found that the similarity of users behavior is correlated with their gender and their age.","we show that based on gender and age, users behaviour are similar."
310,"in each step, the asgd algorithm samples a mini-batch of edges and then updates the model parameters.",the asgd algorithm samples some min-batch edges at each step and then updates the model parameters.
311,"once identified and extracted, data characteristics could be used to improve wireless service quality and generate new mobile applications.","once identified and extracted, the data characteristics will be used in ways that can lead to improved qos improvements and the potential for novel mobile applications."
312,we will now look at the performance of our spit filter and derive expressions for its expected loss.,we now evaluate the performance of our spit filter and derive expressions for its expected loss.
313,"else if the list contains only one element, it has to return this element.","if it has only one element in its list, it has to return it."
314,could be used to mine the usage data after the data have been pre-processed to the desired form.,"after pre-processing the data into the desired form, the utility data could be used to mine the graph."
315,sketch) now we are ready to show the theorem.,we are now ready to prove the theorem using sketches.
316,"nowadays, most wireless devices are powered via power cables or battery replacement, which limits the scalability, sustainability, and mobility of wireless communications.","nowadays, most wireless devices are powered via power cords or battery replacements, limiting the scalability, durability, and mobility of wireless communication systems."
317,"it is in fact a parameter-free, feature-free, data-mining tool.","it is actually a parameter-free, feature-free, data-mining tool."
318,going from uncountable to countable is a remarkable progress.,it is remarkable how far we go from uncountable to countable.
319,"it should not be surprising, as all characters spoke english, with the same voice.","this should not be surprising, since all characters spoke english in the same order."
320,"when contains difficult-to-solve instances, the performance curve before learning typically starts high and gradually decreases, or rises quickly, reaches a plateau, and then gradually decreases.","the performance curve prior to learning typically starts high, then drops slowly, or it rises very high, reaches a plateau, and then slowly declines when the problem contains challenging instances."
321,we can compute the inconsistency indicator of our assessments (subjective or not) rarely getting zero which stands for fully consistent assessments.,they can be used to compute consistency indicators (subjective or non-subjective) rarely getting to zero when we have made a fully consistent assessment.
322,"the selection is done by the user himself, but he is provided with a bundle of automatically generated context sets to select from.",they are used to make the selection between users own choice but they also receive a bundle of automatic context sets to select from.
323,tasks are always stolen as high up in the task hierarchy as possible.,tasks are always stolen from as high up in the task hierarchy as possible.
324,no lexical normalization was applied to tags during post-processing.,tags were not applied in lexical normalization during postprocessing.
325,"again, a directive to the setup tool can replace this implementation.","again, we can easily replace this implementation by a directive to the setup tool."
326,writing a good human-oriented proof is the art of creating the correct images in the mind of the reader.,writing a good human-centric proof is an art of inducing an image to the mind of the reader in a useful manner.
327,"finally, the outlets with the most negative scores around this dimension are all international media outlets.","finally, we find that the worldwide media outlets are the outlets with the largest negative score on this dimension."
328,we have one queue in each station so no scheduling is needed.,"we keep only one queue at each station, and no scheduling is required."
329,"these rankings may change significantly over time, leaving a trail of historical information that can be used to make predictions.","these ranking processes are subject to change over time, leaving a trail of historical information allowing them to be used as indicators for predictions."
330,we should design the power allocation to strike a better balance between reliability and secrecy.,we need to design power allocation to balance the reliability and secrecy requirements better.
331,"when we want to optimize systematically and simultaneously various objective functions (usually conflicting between themselves), we will have the process known as multiobjective optimization.",the method we take is called multi-objective optimization (which is what happens when a process has both goals) in which the objective functions are optimized simultaneously (generally conflicting).
332,"classically, the regressor can for example be chosen according to some statistical resampling (cross-validation, bootstrap, etc.","formally, the regressor might select a set of statistical resampling options, like cross-validation, bootstrap etc."
333,"therefore, improving (or reducing) one metric may end up in degrading the performance of the others.","therefore, improving (or decreasing) one metric may degrade the performance of the others."
334,"classification with model selection provides state of the art results with limited training size sequences, for handwritten digit recognition and textures.",classification with model selection brings state of the art results on limited training size sequences for handwriting digit recognition and texture recognition.
335,robot hands can grasp at most one object at a time.,robot hands can grasp up to one object at a time.
336,our matlab code will be made available shortly from our webpage.,we will shortly be making our matlab code available on the google webpage.
337,"however, it uses the information on the state of the plant.","however, it uses the information of the state of the plant."
338,"in particular, power limits the computation, communication and locomotion capabilities of the robots.","specifically, the robots s computational, communication and locomotor capabilities are limited by power constraints."
339,the application domain and the relationship to customers are in most companies not problematic.,most companies have little problem with application domains and relation to the clients.
340,the decomposition procedure keeps a small subset of candidate clusters in the master problem.,the decomposition process preserves a sparse subset of candidate clusters for the master problem.
341,the inner iteration is to update the solution by zap with the given measurements.,the inner iteration is dedicated to updating zap solution by taking the given data.
342,"we combine the reference sequence, nucleotide pileup and the genotype calls.","we combine reference sequence, nucleotide pileup and genotype calls."
343,"as we will see, parameterized complexity seeks to have a conversation with the problem which enables us to do just that.",we see that parameterized complexity is about having a conversation with the problem that does exactly this.
344,"each node can be either a source, a relay, a destination or a mixture.","the nodes in a channel can be either a source, a relay, a destination, or a mixture of both."
345,"this is not surprising, since as we have seen in the previous section, the resulting connection probabilities in the two methods are quite similar, cf","this is not surprising, since as we have seen in the previous section, the two methods give quite similar bounds on the link probability, cf."
346,it is also common practice in deep learning to increase the effective size of the training set by duplicating the training data many times and applying realistic transformations to each copy.,a common practice in deep learning is to exponentially expand the effective size of training datasets by re-sampling the training dataset many times and applying realistic transforms on each replica.
347,"however, different agents might have different policies, which indicates that risk is taken into account differently by different agents.","this implies, however, that different agents may have different policies, indicating that different agents take risks differently."
348,"their experiments indicated that with this post-processing technique, the node learning objective can be better met, which is translated into improved detection rates.","their experiments suggest that their technique can accomplish the node learning objective better, translating into improved detection rates."
349,they are usually very efficient and achieve excellent results-the generated solutions are near optimal.,is usually very efficient and achieves good results-the generated solutions are almost optimal.
350,"however, entropy estimation remains a difficult problem: there is no unbiased estimator for entropy, and the maximum likelihood estimator is severely biased for small datasets.","it is however still a difficult problem to perform the entropy estimation: there is no unbiased entropy estimator, and the maximum likelihood estimator is strongly biased for very small data sets."
351,"in this section, the approach is illustrated on two simulation examples.","in this section, two simulation examples illustrate the approach."
352,these cells can be of two different types: they can store real numbers or integers.,one can use two types of cells: real numbers or integers.
353,"it does not require gradients and hence, it can be used on problems that are not continuous or differentiable.",this design does not require gradients and thus may work for problems that are neither continuous nor diffusive.
354,"additionally, every leaf node has a second label, which is either yes or no.","in addition, every leaf node in the graph has a secondary label that is either yes or no."
355,therefore the powerful tools from logic discussed above can not be applied in that context either.,"hence, the powerful tools from logic discussed above can not be applied here either."
356,these metrics can be very useful in describing a distribution without having to plot it.,the usefulness of these metrics is to describe a distribution without having to plot it.
357,any probabilistic learner can be simulated by any team with the ratio of successful machines equal to the probability of success for the probabilistic learner.,the probability of learning success is the ratio of the success probability for any team in a probabilistic learner.
358,symmetries can also be found within individual solutions of a constraint satisfaction problem.,it also permits us to find symmetries in the individual solutions of a constraint satisfaction problem.
359,what factors influence the success of word-of-mouth product recommendations?,what factors impact the success of word-of-mouth product recommendation?
360,"this is partly due to news coverage which might be more granular in some languages, partly due to noise and errors in the event detection process.","this is partly due to the fact that news coverage in some languages is likely to be more refined, and partly due to noise and errors in the event detection process."
361,"of course, now the user has to specify two bounds on different conditional probabilities and he has to have some reasons for distinguishing between the two conditional probabilities.","indeed, now the user has to specify two bounds for the variation in conditional probabilities, and moreover, he needs to have certain reasons for distinguishing the existence of two conditions on the probability distributions."
362,"for developers to produce rules that can improve the system, they need to actually look at data.",developers must actually analyze the data in order to produce rules that can improve the system.
363,container virtualization provides better performance than hypervisor-based virtualization.,container based virtualization provides better performance than hypervisor based virtualization.
364,"pig provides concise primitives for expressing common operations such as projection, selection, group, join, etc.","pig provides concise primitives that enable representations for common operations such as projection, assignment, set, join, etc."
365,an essential functionality towards this goal is the capability to provide meaningful explanations about why data is present or missing form the result of a query.,another crucial feature for our approach is the ability to make sense of the information that is present or absent from an answer to queries.
366,"for this reason, the findings of our expert-based assessment should be interpreted with some caution.",these points should be taken into account when interpreting the results of our expert-based evaluator with caution.
367,"furthermore, it does not differentiate between random individual frame drops and consecutive frame losses.","furthermore, it does not distinguish between random overlapping frame drops and consecutive frame drops."
368,"if more than one errors occur during this period, we will detect multiple disk errors during the scrubbing process.",we will detect multiple disk faults in the scrubbing process if more than one fault occurs in this time interval.
369,random variables (in the current case being an exponential with half of the mean of the original).,"random variables (in the current case, it is an exponential with half the mean of the original)."
370,then we add the key-value pairs to the vertex as its properties.,we then assign properties of the vertices of our system as keys to pairs of vertices.
371,one node is added to the search tree according to a criterion that tells where most likely better results can be found.,a criterion that tells us where more likely better results can be found is added to the search tree of one node.
372,"this means that they are given zero mass in the analysis, and their projections are determined using the transition formulas.",this implies that they have a weight of zero during analysis and their predicted motions are determined by transition formulas.
373,"based on this kind of representations, methods such as edge-based segmentation, graph-based segmentation, watershed segmentation can be applied.","we can use such a representation to apply methods such as edge-based segmentation, graph-based segmentation and watershed segmentation."
374,"validation data was also generated on the fly, but we always chose the same pairs of patches and kernels to ensure that validation error could be compared across iterations.","the validation data was generated on the fly from the same selection of patch and kernel pairs, which we wanted to keep consistent across iterations in order to compare validation errors."
375,it is something so common in our daily routine that we usually do not even make a note of it.,"so common in our daily routine, that it is rarely mentioned at all."
376,"indeed, pork and butter are closely aligned with the calorie, fat, protein, sodium, and cholesterol curves of fig.","indeed, the calorie, fat, protein, sodium and cholesterol curves in fig."
377,region selection expressions are then used to identify relevant parts of a table.,these regions are then used for query parameters to identify relevant regions in a graph.
378,we do that either by increasing the link weights towards selected nodes (click bias) or by adding new links pointing towards those nodes (link insertion).,"we do this either by increasing the link weights towards the selected node (click bias), or by adding new links directed towards the selected node (link insertion)."
379,the built-in bound predicate determines how software maps to hardware.,how the software maps to the hardware is determined by its built-in bound predicate.
380,can we model and exploit these data to steer the online community to a desired activity level?,can we model and exploit such data to guide the online community towards a desired activity level?
381,a counterexample can be produced to help developers understand the source of inconsistency and correct the program.,we can provide counterexamples to help the developer understand the source of inconsistency and correct the program as well.
382,the few success stories songs and videos that have spread in a chain reaction from person to person to reach millions keep marketers searching for formulas for creating viral campaigns.,the few success stories of songs or videos that resonated with people across the globe by generating chain-reaction hits reaching millions keep marketers searching for formulae for viral messaging.
383,"then, we may build more complex models to simultaneously learn distributed representations of users by adding additional user layer on top of the document layer.",we can then add an additional user layer on top of the document layer to obtain more complex models for learning simultaneous distributed representations of users.
384,"there is not much difference in learning performance between the online and batch modes, as we will see.","we will see that between on-line and batch modes, there is no great difference between the learning performance."
385,"using the abstraction theorem, we can obtain the main result that typable terms are normalizing.",we can prove the main result of the normalization of types in terms of typeable terms by means of an abstraction theorem.
386,then the solutions can be mapped and the weight will be the same.,"then, the solutions can be mapped to the same weights and the weights will be equal."
387,holding an egg works best with a grip that is neither too weak nor too strong.,"to hold an egg, a grip that is neither too weak nor too strong is optimal."
388,"we can see that using a single group of features, the highest prediction accuracy can be achieved using concept-related features.",we can observe that using concept-related feature space yields the maximum prediction accuracy when performing a single-set feature analysis.
389,"this can be done by converting the rules into sequences, calculating the graphs which enable the application of both sequences, and then checking whether the application of a sequence disables the other.","one can achieve this by transforming the rules into sequences, computing the graphs for which one set of rules disables the other, and checking if one sequence makes a switch to the other."
390,"moreover, channel prediction enhances the sum-rate, and the higher the predictor order, the better the sum-rate performance.","in addition, channel prediction improves the sum-rate performance, with higher predictor order providing higher sum-rate performance."
391,"thus, it is important to incorporate this human behavior into the models.",it therefore seems important to incorporate such human behavior into our models.
392,"one trader might trade high tech, one trader health care, another trader autos, and so on.","for example, one trader might trade high tech, one trader may trade health care, one may trade autos and so on."
393,"indeed, they work at a level of granularity which is finer than channel flows.","indeed, the works are granular at a level finer than that of channel flows."
394,"however, as cultural habits are deeply ingrained, reading behaviors might be hard to change.","however, it may be difficult to change reading behaviors as cultural habits are deeply ingrained."
395,"the simplest one is the just mentioned by definition, consisting of a single node.","the simple one, by definition, consists of a single node and is the one just outlined."
396,"in this section, the power allocation policies and the transmitter switching policy will be presented.",we present the power allocation policy and the transmitter-switching policy in this section.
397,we interpret cluster i as voxels activated by the stimulus.,we interpret cluster i as voxels which are activated by the stimulus.
398,it also highlights the importance of the travel time budget in the residential locations choice.,we also highlight the importance of the travel time budget for residential location selection.
399,"such a size is computed under the assumption that memory accesses are grouped by grid function and dimension (for stencil accesses). as an illustration,",this scale is computed under the assumption that memory accesses are divided into grid function (for stencil accesses) and dimension (for stencil accesses).
400,developing an algorithm that works under this relaxed assumption is a challenge.,it is a challenge to develop algorithms that work in this relaxed assumption.
401,what is needed is that the policy change triggers a procedure that pushes the notification to the team leader.,the requirement is that the policy changes trigger a procedure sending an alert to the team leader.
402,the median success rule compares the median fitness of the population to a fitness from the previous iteration.,the median success rule compares the population fitness against its previous iteration fitness.
403,"i meant roughly the approach that someone trained in statistics, or in some area such as scientific computing where strong domain-specific assumptions about the data are routinely made, might adopt.","that would be roughly the approach that someone studying statistics might adopt, or a field such as scientific computing where it is routine to make strong domain-specific assumptions on the data."
404,some annotations (actions) are identified by simple regular-expression parsing.,some annotations (functions) occur using a simple regular expression parsing.
405,all of these operations require access to data which is owned by different units.,all the latter operations require access to data which lies across the many different units.
406,"they have their relative pros and cons in terms of performance, complexity and implementation issues.","there are relative pros and cons to these models on the level of performance, complexity and implementation issues."
407,the key ingredients to build these links are conditional independence and the recently introduced causal conditioning.,conditional independence and recently introduced causal conditioning are key ingredients for creating link constructions.
408,deep neural network based methods have resulted in better performances in this domain too.,we also examined that the performance of deep neural network based methods in this domain is better.
409,for each language variant a diversity index is calculated as the average of the proportions between linguistic and geographical distances from the given language variant to each of the other language variants (cf.,a diversity index for a language variant is calculated as the mean of the differences between the linguistic and geographical distances between a given language variant and all the other language variants (cf.
410,this new distance function encodes any additional trips to and from the root that a vehicle has to make if it runs out of capacity.,this new distance function encodes any additional walk up and down a tree a vehicle must make in order to fulfill the load before it gets stuck.
411,"no clear topology was at our disposal, but a notion of limit, which served to define continuity equally well, and obtain an equivalent of the theorem.","we have no clear-cut topology, but we can draw a notion of limit, which serves equally well as a continuity definition, and obtain its theorem equivalent."
412,"of course, there are so many possible combinations of diseases that it would be impossible to store information about them all.",there are a great many combinations of diseases that it would be impossible to store information for each of them.
413,the detailed tables of comparison for all combinations of parameters are available on github.,detailed comparison graphs for all parameter combinations are available at github.
414,this is also a realistic option since dash does not specify where video adaptation occurs.,this is also a feasible option because the dash does not specify where the video adaption happens.
415,that means our task is not a multi-label sentiment analysis problem.,this indicates that our problem is not a multiclass sentiment analysis problem with multiple labels.
416,"system administration is the realm of computer science which deals with the planning, configuration and maintenance of computer systems.","system administration is the branch of computer science that deals with the design, configuration, and operation of computers."
417,caffe: convolutional architecture for fast feature embedding.,caffe: a convolutional architecture for fast feature embedding.
418,"any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.","any opinions, findings, or conclusions or recommendations expressed in this material are those of the authors and don't necessarily reflect those of the sponsor."
419,dealing with large number of points requires yet a new angle.,dealing with a large number of points requires yet a new way of seeing the task.
420,"if the call var(x) succeeds, however, we have gained nothing and still have to perform var(x) at runtime.","if var(x) is a success, however, we gain nothing and are required to var(x) at runtime."
421,causes the total reward earned to decrease as agents are added.,causes the total reward earned as agents become more diverse to decrease.
422,model uncertainty about the true state of the world with a probability distribution over the state space.,a probability distribution over the state space is used to model uncertainty about the true states of the world.
423,"finally, verifapp shows the recorded vote on the screen.","finally, verifapp displays the recorded vote on the screen."
424,collection selection selects a few relevant thematically related clusters for each query and therefore improves search performance.,"cluster selection selectively chooses a few relevant thematically related clusters per query, thus improving the search performance."
425,"in particular, there should not be a single agent who can enforce the inclusion of alternatives in the choice set no matter which preferences the other agents have.","specially, no matter what the preference of the other agents are, there should not be a single agent who enforces the inclusion of alternatives into the choice set."
426,the top shows the sound signal in a raw form as amplitude vs time.,the top shows the raw amplitude vs time of the sound signal.
427,"a word is called an (integer) power if it can be written as the concatenation of two or more copies of another word, like.","a word is called an (integer) power if it can be expressed as the concatenation of two or more replicas of another word, as."
428,"if we run the model on the us population density map many features of the backbone of large, real agents are recreated.","we reconstruct many features that reflect real agent populations, but also apply the model to the us population density map."
429,"intuition suggests that mentioning well-known entities can affect the spread of an article, increasing its chances of success.","intuition suggests that mentions of well-known entities can influence the spread of an article, increasing its chances of success."
430,we might have expected the utility to decrease after a certain point because of the reduction in the processing gain.,"we might expect that as the processing gain decreases, the utility is expected to decrease after some point."
431,"most literature from the control community assumes sensors to behave reliably, but recent results are making clear that this assumption is not free from risks.","most of the control literature assumes sensors to behave reliably, but recent results show that this assumption is less and less true."
432,"furthermore, the variance in reward after spiking is much lower than after not spiking and, once again, tightening the metabolic constraint will tend to further decrease the variance after spiking.","furthermore, the reward variance after sputtering is much smaller than that after no sputtering and, again, the relaxation of the metabolic constraint will tend to decrease even more the variance after sputtering."
433,the dialogue for some scenes was written while shooting was in progress.,the dialogue for some scenes in the film was written while filming was in progress.
434,agents acquire knowledge incrementally by learning multiple tasks consecutively over their lifetime.,agents acquire knowledge incrementally by sequentially learning multiple assignments over their lifetimes.
435,"the input information in the look-ahead window includes the wind station power output, the electricity and heat demand, and the central grid electricity price.","the input data in a look-ahead window includes the power output of the wind farms, the electricity and heat demand, and the price of electricity from the central grid."
436,"on the other hand, the authors showed an algorithm using a linear number of messages but requiring very large running time.","in contrast, authors presented an algorithm that takes linear time and is quite effective but requires very large run-time."
437,this suggests that they have different disease patterns from the other provinces.,this suggests that the different provinces have different disease patterns than the other provinces.
438,it shows that temperature is one of most important factors impacting link quality.,this illustrates that temperature is one of the most important influences on the quality of links.
439,all effects of a task are collected in the transaction for that task.,all effects of a particular task are collected in a transaction associated with the task.
440,calculating the gradient of this distance function which is used in equation is straightforward.,"it is straightforward to establish a gradient on this distance function, which is used in eq."
441,"also, note that the information structure constraint is not used in the proofs.",note also that the proofs don't use the information structure constraint.
442,"go across the atrium, turn left into the hallway and you will see the library doors.","you will see the library doors at the end of the atrium, turn left into the hallway."
443,the highlight of the paper is mainly on the communication infrastructure that has been implemented in the testbed in order to provide ict services to support a greener smart grid.,the real novelties in the paper are the communication infrastructure that was installed in the testbed to enable ict to support greener smart grid.
444,equation can be used to calculate the correlation of interference for any mobility model.,the interference correlation in any mobility model can be calculated from equation.
445,the regulator can use it to forecast results of exacting taxes or giving subsidies.,the regulator may exploit it for forecasting taxes to be exact or to provide subsidies.
446,"and, is their responsiveness correlated in any way to the number of contacts they resend the message to?","in particular, is their responsiveness closely related in any way to how many of their contacts they relay messages to?"
447,an index function for a library is a function that assigns a priority to every state of every component in the library.,"for example, a library index function is a function which allocates priority to each state of any component in the library."
448,the spinflip program can also be used to explore the fine structure of a solution cluster (paper in preparation).,"in contrast, the fine structure of the solution cluster may be explored by a spinflip program (paper in preparation)."
449,"under limited budget, the system operator should protect a subset of state variables.",the system operator should protect a subset of state variables within a limited budget.
450,"using fair coin tosses, the machine generates a (finite or infinite) sequence of output bits.",the bs generates a (finite or infinite) sequence of output bits via fair coin tosses.
451,the learning algorithm used for training the binary regressors in both approaches was incremental gradient descent with squared loss.,"for both approaches, sequential gradient descent with squared loss was used as a learning algorithm to train binary regressors."
452,"however, all the tested algorithms encountered troubles when coloring graph instances in the phase transition region.","however, the coloring of graph instances in the phase transition region presented problems for all the tested algorithms."
453,unsupervised learning is what an autonomous robot would need in places like mars where it can get little or no help from a human teacher.,"unsupervised learning is what an autonomous robot might need on places like mars, when it can get little to no help from a human trainer."
454,this is done by drawing a connection to the theory of network coding.,we do this by drawing connections to the network coding theory.
455,"in this section, we evaluate against other planners using planning benchmarks from the literature.",in this section we evaluate our planner against other planners using planning benchmarks from the literature.
456,"positive reputation of a bot, in turn, would give credit and reputation to the scientist who created it.","an excellent reputation for a bot would, in turn, credit and reputation the person that created it."
457,"some other well encountered factors, such as communication delays, data missing, etc.","there are also several other well-known factors such as communication delay, missing data, etc."
458,we train the full model end-to-end in a single step of optimization.,"we perform optimization in a single step, by training the complete model end-to-end."
459,"for example, clinical event streams can be bursty, and some existing methods are unable to adapt to or adequately represent this.","clinical event streaming can be bursty, and many existing methods don't fit these or adequately represent them."
460,these two information are really interesting to use when comparing biometric systems.,that makes biometric systems comparing very interesting because of the two relevant facts.
461,"contrary to appearances, most donations come from individuals rather than corporations.","contrary to appearances, donations come primarily from people rather than corporations."
462,we can allocate a dedicated control channel for each node to collect the local csi.,"then, based on our estimation, we can allocate a dedicated channel for each node to collect the local csi."
463,the world through the computer: a new human computer interaction style based on wearable computers.,a new human computer interaction style based on wearable computers.
464,we can model the fluctuations of price through a stochastic model.,the stochastic model allows us to model the fluctuations of prices.
465,"traffic provides income to the service providers which is then invested in infrastructure, which can lead to changes in traffic patterns.","traffic provides income for service providers that will then be invested in the infrastructure, and could lead to changes in traffic patterns."
466,"this combination is well-suited to the language resource community, where the available data is growing rapidly and where a large user-base is fairly consistent in how it describes its resource needs.",this characterization is well suited for the language resource community in which the available data grow rapidly with new features and a large user-base is relatively consistent in expressing its resource need.
467,note that the color bar on the right is on logarithmic scale.,note the logarithmic scale of the color bar on the right.
468,the ten highest scoring movies for each user that were not already liked by her were chosen as recommendations.,all movies that were not yet liked by each user were selected as the ten most-liked movies for that user.
469,gives the score for every search windows on the images of target dataset.,scores are generated by scoring each search window in the target dataset.
470,this contribution is intended to provide a useful introduction for programming with the libraries.,the purpose of this contribution is to provide a good orientation towards using the library extensively.
471,"since these taggers can be trained using a handful of training examples, we can use them to build ner systems even when there are no labeled sentences to train.","now, even if we have no labeled sentences to train, we can use these taggers to build ner systems, since they are trained from a small number of training examples."
472,be aware that this is a log-log scaled graph and so the different slopes indicate significantly different orders of scaling.,"note that this is a log-log scaled graph, and so different slopes in this graph result in dramatically different scaling orders."
473,this allows us to tune the operation of the control system to the desired level of performance and guarantee a desired convergence rate.,the main aim of this approach is to tune the operation of the control scheme to achieve a desired performance and guarantee a desirable convergence rate.
474,equation is the transition probability for a receptor to unbind.,equation gives the probability of transition from binding to adl.
475,estimates combined effects of social targeting and social cues in ads and highlights the value of distinguishing them.,estimates combined effect of social cues and social cues in ads and illustrates the value of sensitivity discrimination between the two.
476,"in information theory, entropy is defined as a measure of uncertainty of a random variable.",entropy is a measure of uncertainty in a random variable and is defined in information theory as a measure of information-theoretic stability.
477,such a projection can not increase the volume and the perturbation distances only get smaller.,this projection can not improve the volumetric properties and only the perturbation distance increases.
478,"hybrid systems modeled by quantum markov chains have already been often encountered in quantum information processing, and the quantum engineering systems developed in the future will most probably be hybrid systems.","hybrid systems as modeled by quantum markov chains have already been commonly encountered in quantum information processing, and there are many applications to quantum engineering that will mainly be hybrid systems."
479,"for each cell, the load factor is defined as the amount of resource consumption in relation to that is available in the cell.","a load factor is defined for each cell, as the sum of resources that is consumed by the cell compared to that available in the cell."
480,of course this depends on the nature of the problem we are trying to solve and the fitness function that we use.,this naturally depends on the nature of the problem we try to solve and the fitness function we use.
481,this is also important for activists and politicians who are using the web increasingly more to influence public opinion.,this is important for politicians and activists who use the web in increasingly larger ways in order to affect public opinion.
482,it works equally well regardless whether the targeted spectrum consists of dominant eigenvalues or not.,this procedure workes equally well regardless of whether the targeted spectra contain dominant eigenvalues or not.
483,consider a two-tier network with a static primary tier and a denser secondary tier over a unit square.,consider the network composed of a series of two nodes with one static primary tier and a denser secondary tier over a unit square.
484,"we could also cite video sensors, with the intuitive reasoning: the target is getting closer if its size is increasing.","videos can also be categorized as sensory objects, which allows intuitive reasoning: the targets get closer if the target size increases."
485,data clouds provide some important advantages for managing and analyzing data compared to competing technologies.,"comparison with the competing technologies, the data cloud offers several important advantages for data management and analysis."
486,"for example, if a user is browsing pants, we might want to recommend a shirt, shoes, or accessories that belong to the same style.","thus, for example, suppose we want to recommend a user a t-shirt or sneakers, or accessories that go along with the same look if that user is browsing pants."
487,this paper introduced an approach for general transfer learning using neural networks.,this paper proposed a generalized linear transfer learning approach using neural networks.
488,this scheme is most commonly used to vectorize pair potentials.,it is because of this scheme that pair potentials are most commonly vectorized.
489,which pair of constraints will be used is a matter of discussion and depends on how the system should be converged and stabilized.,it is open questions which constraint pairs should be exploited and depends on how the system should be converged and stabilized.
490,traditional surveys such as field interviews are costly and do not scale for obvious reasons.,"the obvious reason is that traditional surveys such as field interviews are costly, time-consuming and scale poorly."
491,the intuition underlying reinforcement learning is that actions that lead to large rewards should be made more likely to recur.,the intuition behind reinforcement learning is that actions that bring large reward need to be made more likely to recur.
492,"this means each expert, or data source, should be consistent with respect to the confidence levels it provides.","this indicates that each expert, or data source, must ensure the correctness of the confidence level it provides."
493,"in contrast, our network is discriminatively trained to directly predict the ratio in.","in contrast, our network is discriminatively trained to predict the weight in a direct fashion."
494,"hence, it can identify its endpoints and it sees their degrees.","hence, it can recognize its endpoints and can see their degrees."
495,"then, we must define and explain the diversity measures themselves (next section). in brief",we then briefly define and explain the diversity measure itself (next section).
496,"while enlarging the prediction horizon is of course of primary interest for practitioners, there is of course some limit to the accuracy that can be expected for a long-term forecast.","while it may be of primary interest to practitioners to enhance the prediction window, there is of course a certain level of error that one can expect in the long term prediction."
497,"after a catastrophic failure by the kernel device driver, the shadow device driver was able to take over and place the true device driver back in a sane state.","after a catastrophic failure of the kernel device driver, the shadow device driver was able to take over and bring the true device driver back to normal state."
498,should the project directory not be specified then the current working directory at the analyst site is used as the source project directory.,"in such cases when the project directory does not specify the input project directory, we use the current working directory on the analyst server as the source project directory."
499,we need to incorporate context-based knowledge about how communities are built and how they evolve.,we need to incorporate the context-aware knowledge about how communities evolve and evolve.
500,"relevant commands are orbit, schreierorbit, traceschreier, stabilizer, and others.","the relevant commands are orbit, traceschreier, stabilizer, and others."
501,firstly we fit the faces by ellipses on the thresholded confidence heatmaps.,"first, we fit faces according to ellipse to the thresholded confidence heatmap."
502,"therefore, it was easy to immediately get started and rapidly iterate.","therefore, it was easy to begin and iterate rapidly right from the beginning."
503,"massive graphs occur in a variety of situations, and we need to design better and faster algorithms in order to study them","massive graphs arise in a variety of situations and, to understand such graphs, we need to design better and faster algorithms."
504,these clustered communities were then matched with actual gang affiliations recorded from the police field interview cards.,these clustered communities were then found to match the actual gang affiliations recorded through the cop interview logs.
505,"hence, the approach must also be highly adaptable, detecting new types of fraud as soon as they are noticed.","hence, it is very important that this approach is highly adaptive, detecting new types of rlk fraud as soon as they are observed."
506,"there is much work on language identification including open source utilities, such as the language detection library for java.",software language detection works for java containing open source utilities such as the java language detection library.
507,note that the eigenvectors indicate the direction of the most typical deviations from the average behaviour.,note that the eigenvectors show the direction of the most typical deviation of the eigenvectors from the mean behavior.
508,the prevalence of lying in america: three studies of self-reported lies.,three studies of self-reported lies: how widespread lies are in the us.
509,"the geometry of a sector may be different, a usual choice is a square.",sector geometry may be different from one example to another; a frequent choice is square geometry.
510,these and other tools can be useful to help design ontologies and semantic graphs for knowledge representation.,designing ontologies and semantic graphs for knowledge representation can take advantage of these and other tools.
511,"hence, all links have the same statistical model and the average snr is the same as for all channels.","hence, we maintain the same statistical model for the links and the average snr is the same as that for all links."
512,privacy protection in recommender systems is a notoriously challenging problem.,privacy protection of recommender systems is a notoriously challenging problem.
513,"our goal in designing the competition was to create a day-long design problem suitable for undergraduates in engineering, mathematics and science.","the objective of the competition was to develop a design problem spanning an entire day suitable for undergraduate engineers in engineering, mathematics, and science subjects."
514,"when we need more vocabularies, the ones came from the unlabeled training set was then randomly added to the dictionary.",we then randomly added them to lexicons when we needed more vocabularies than the one given in the unlabeled training set.
515,the restart policy selects a new random seed for the algorithm and restarts it if the algorithm is not making sufficient progress with the current seed.,a restart policy selects a new random seed for the algorithm and restarts it if it is not making progress with the current seed.
516,"however, other features of a sentence, such as punctuation, are also useful when deciding if two words are related.","however, when deriving a relationship between two words, other features of the sentence such as punctuation are also helpful."
517,"if it fails at either of these tasks, its chances of survival are slim.","if both of these tasks fail, the chances of survival are slim."
518,"as discussed above, both batch and online algorithms have their advantages and disadvantages.",both batch and online methods have their advantages and disadvantages as discussed above.
519,"it consists of controlled images, uncontrolled images and three-dimensional images for each object.","each object is represented as a combination of controlled images, uncontrolled images and three dimensional images."
520,two lemmas below shows how to distinguish between limit and successor elements.,the distinction between a boundary and its successor elements is given by two lemmas below.
521,"in contrast to model checking, which involves verifying that a system satisfies the given specification, synthesis aims to automatically construct the required system from its formal specification.","by contrast to model checking, which involves checking whether a given system satisfies the given specification, synthesis attempts to automatically construct the required system based on the given formal specification."
522,"there are many details about the internals of the scheduler, its dependency analysis, memory management, and other performance enhancements that are not covered here.","there is a lot of detail in the scheduler s internals, ranging from dependency analysis to memory management, and other performance enhancements that is not covered here."
523,the next lemma relates the total loss of the learner to its total estimated losses.,the next lemma shows that the total loss of a learner is proportional to the total estimated loss.
524,these components form a mobile platform library that can be easily imported by developers into their applications.,these components are combined together to form a mobile platform library that developers can easily inject in their mobile applications.
525,"in the following, matrices are in bold, vectors bold italic.","note that matrices are bold, vectors bold italic."
526,"next, we generate the clusters by aligning sentences and re-ordering them based on original positions of the sentences in the documents.","next, we aggregate sentences for the clustering, reordering sentences according to their original positions within the documents."
527,"that is, ten minutes after a major news event breaks, the service should be displaying relevant related query suggestions.",it means that the service should display related query suggestions 10 min after an important news event breaks.
528,"the identifier is only associated with anonymous metadata for each individual: school class, gender, year and month of birth.","only data associated to individual, anonymous attributes are collected: class, gender, year, and month of birth."
529,deal selection is the problem of maximizing expected profits by choosing the best deal to bid for every impression.,deal selection is the problem of maximizing the expected profit by selecting the best bid to bid on every impression.
530,"other examples for possible networks include matrix networks, that is a grid of several vertical lines and horizontal lines",a matrices network is another example of a potentially network which is a rectangle consisting of several vertical lines and horizontal lines.
531,"based approach, we try to find a smooth model that can fit the background pixels accurately.",our goal is to use a smoothed model to produce a realistic bound for the background pixels.
532,"after a number of iterations, we recompute the vertices lying on the occluding boundary and restart the optimiser.",we recompute the vertices lying at the occluding boundary and restart the optimiser after some iterations.
533,"room service was really good and quick, eating in the room looking at that view, awesome!","our room was super quiet and our room service was very fast, we ate in our room overlooking the pool area vista."
534,"to summarize, we used two distinct datasets and collected or computed variables in slightly different fashion for each.",we summarized by using two distinct datasets and computing or collecting variables in slightly different manner for each dataset.
535,the association between each pair of words in the compound is then computed by taking the maximum selectional association from all possible ways of regarding the pair as predicate and argument.,the maximum choice association for each pair of words in the compound is then computed by considering all possible notions of regard of the pair as predicate and argument.
536,"afterwards, support vector machine and median filter are adopted to detect the anomaly.","then, we adopt the support vector machine and mean filter to detect the anomaly."
537,"additionally, high-performance computing platforms are limited to organizations with large budgets and highly skilled employees.","in addition, large budget organizations, as well as highly skilled personnel are a rare resource to hire high performance computing platforms."
538,the goal in the following will be to investigate the impact of autocorrelation regarding tf binding sites.,we will study hereafter the effect of autocorrelation on the tf binding locations.
539,decision trees are often less accurate but more interpretable than random forests.,decision trees are often less accurate but are more interpretable than random forests.
540,"thus, the lower the visibility, the more likely a sandstorm is going on, which means more people are tweeting about it.","that is, the lower the visibility of the topic, the more likely it is to cause a sandstorm, which in turn means more people are tweeting about it."
541,"when applying an axis to a set of coordinates, we always return only the coordinates that are valid coordinates in the table.",we always return a set of coordinates the way we applied an axis to a set of coordinates and only the coordinates that are valid coordinates in the table.
542,"noise is unavoidable in images, and it is important to develop segmentation methods that work on noisy images.","noise is present in the images, and it is important to develop segmentation methods that work for noisy images."
543,"the smart grid factors include the electricity prices, demand response, distributed energy sources, storage cells and electric vehicles.","factors involved in a smart grid include power price, demand response, distributed power sources, storage, and electric vehicles."
544,"to understand how to calculate the combining coefficients described in the above equations, let us now look at the following example.",let us now look at the following example to gain an understanding of how to compute the combinatorial coefficients stated in the equations to come.
545,"all extensions are using the python programming language, and are documented using the sphinx package.",the extensions are implemented within python and documented using the sphinx package.
546,it is not exactly our case as we need to crawl and index newly discovered pages to allow users to access them via the search engine.,"this is not very close to our case since we are required to crawl and index newly discovered pages, so that they can be retrieved by the crawler."
547,the determination of a causal coupling strength now is a two-step procedure.,estimating the coupling strength is now a two-step process.
548,"the system also supports network, relational, and entity-relationship database models.","the system supports both the network, relational, and entity-relational database models."
549,readers less concerned with technical details will find an outline of the argument and intuitions for important aspects of the proofs in this section of the paper.,"this section of the paper is intended for readers not overly interested in technical details, as well as providing intuitions for important aspects of the proofs."
550,"block codes works on the fixed size blocks of data whereas, convolutional codes work on data streams of arbitrary lengths.",block code works only on data blocks of a fixed size; convolutional codes work on data streams of arbitrary lengths.
551,"whatever the answer here we are focusing on the inherent ambiguity, which we will note or record in an appropriate way.","we focus on ambiguity, which we will mark or record in an appropriate way in any answer here."
552,now the answer to the next query is also answered the same way as above.,now the next query is answered in the same manner as before.
553,"information loss can occur when securities are sold in discrete quantities (for example, single units), as they are in most real-world markets.","since securities can be sold in discrete quantity (say one unit), which is common in most real-world markets, this can lead to information leakage."
554,"the horizontal axis denotes time, each vertical line corresponding to an individual event.","a horizontal axis denotes time, with each vertical line corresponding to an instance of an event."
555,this data is a representative sample of the web as this toolbar is used by millions of people across different countries.,"since millions of users from a range of countries rely on the toolbar, this data is a representative sample of the web."
556,the evaluation is based on splitting the data into training and test sets.,the evaluation consists of splitting the dataset into a training and test set.
557,repeat with the next sample and continue to keep only the guesses which pass.,again repeat with the next sample and make only the passing guesses.
558,"in short, the idea was to survey recent systems that looked at the entire generation problem, and that were motivated by applications and engineering considerations as well as linguistic theory.","short, our goal was to survey recent systems which have investigated the whole generation problem, motivated by both application and engineering considerations as well as linguistic theory."
559,"if the confidence value of a bit is larger than the preset value of threshold, the destination recognizes a decoded bit as reliable.","when a decoded bit of a stream has an increased confidence value above the threshold set, it is recognized as trustworthy by the destination."
560,"it also partially protects topology, constraint, and decision privacy.","this approach partially protects topology, constraint and decision privacy as well."
561,the configuration files provide support for the functionalities of the core and diagnostic tools.,the settings file contains both core and diagnostic tools functionalities with support.
562,"equipped with the metrics introduced above, we are able to quantitatively assess the creativity of a paper, an author, an institution or even a discipline","we are equipped with the metrics introduced above to quantify the creativity of a paper, an author, a campus, or even a discipline."
563,"inspecting our corpus, we can distinguish three phases in most of the dialogues.",we can see that most dialogues in our corpus can be classified into three phased situations.
564,"targeting the full spectrum of quantiles, it provides a far more complete statistical analysis than, say, classical linear regression.","nss provides a far more complete statistical analysis than, say, classical linear regression, because it takes the full potential of quantiles into account."
565,"totally, billions of negative examples are extracted from the pool.",the total number of negative examples extracted is estimated to be billions.
566,the constraint is useful in resource allocation problems where values represent resources.,the constraint also is useful in resource allocation problems where resources are represented by values.
567,the starting time of this animation is the same as in fig.,this animation has the same starting time as in fig.
568,"given the usefulness of polynomials method, it is an important question how tight is the polynomials lower bound.","as useful as the polynomial method is, the question how tight is the polynomial lower bound."
569,this creates a challenge for a standard video captioner to learn the correct association between words in titles and video observations.,this poses a challenge for the standard video captioner to learn correct association between words in the titles and video observations.
570,the two extreme characters are the egoist players (maximizing their own income irrespective of others) and the completely altruistic players or lovers who try to maximize the others income irrespective of their own payoff.,two extreme players are egoist (maximizing their own payoff irrespective of other players) and completely altruistic (also called lovers) player who tries to maximize other players payoff irrespective of their own payoff.
571,"therefore, a very rudimentary overview is provided next within the context of the decision making problem.","hence, we provide next a very rudimentary overview of the decision making problem."
572,"the following proposition fulfils part of the promise of equation, by producing circle-valued functions from integer cocycles",the first proposition fulfills part of the promise of eq.
573,this is probably also the reason why the seat recline rating was one of the higher correlating features with the overall rating.,this can probably also explain why the recliner seats was identified as one of the features that more strongly related to the overall rating.
574,"the user imports the necessary libraries, creates the functions and imports the inputs.","the user first defines the necessary libraries, creates the functionality, and then imports the data into the library."
575,"in each case, when we apply a rule, we decrease the size of the program.","each time we apply a rule, we decrease the size of the program by one in each case."
576,"it is, however, not so easy as it looks like.",it turns out that this is not as easy as it first appears.
577,"some pages are associated with apis or tools to extract its metadata, but unfortunately they are non-unified, extremely specific, and what works on one page would not necessarily work on the other.","there are apis or tools to extract web metadata, but unfortunately these tools are not unified and very special and what works for one page may not necessarily work for another."
578,"before we discuss varieties of tree languages, let us define quotients of tree languages.",let us define quotients of tree languages before turning to the discussion about varieties of tree languages.
579,this value was determined by experiment from our data set and may need to be adjusted in a different situation.,our benchmarks are from our data set and may need to be adjusted to suit a different situation.
580,a special mode of restriction is to randomly generate a selection of records.,we define a special mode of restrictor that randomly generates record sets.
581,"throughout, a quantity based on the perturbed sample is denoted by adding an asterisk.",a perturbed sample quantity is denoted by an asterisk whenever it occurs.
582,"while zooming in, users can pan around by moving the viewport to view different regions in the video.",users may move the viewport to see different regions of the video as they zoom in.
583,"the first type does not require any input, and the second requires some form of input (from standard input).","the former one has no input, and the latter requires some input of the form (such as standard input)."
584,"the videos are staged actors walk around, browse information displays, sit down, meet one another, leave objects behind, fight, and so on.","a video is a set of scenarios in which actors walk along, explore the information displays, sit down, meet, leave objects behind, get into fights, and so forth."
585,"recovering this lost information will be the key to making strong conclusions, such as distinguishing between two closely related species (or bacterial strains) in a metagenomic mixture.","recovering this mismatch information is central to making strong conclusions, such as distinguishing two closely related species (or bacterial strains) within a metagenomic mixture."
586,"this combined with the use of state-of-the-art chess engines for position analysis, provides players with extremely powerful tools for opening study and preparation.","this approach, combined with state-of-the-art chess engines for position analysis, provides players with powerful tools for opening study and preparation."
587,"that is, at most one variable can take a value within this interval.","that is, a value in this interval can be taken by at most one variable."
588,is closely related to the amount of channel state information (csi) at the base station (bs).,is closely related to the channel state information (csi) received at the base station (bs).
589,might have pushed other patients further in usually long emergency lineups.,"this is especially true when emergency waits are usually too long, and may have driven more patients further."
590,"in medical image analysis, image segmentation is an important task and is primordial to visualize and quantify the severity of the pathology in clinical practice.",segmentation of medical images is an important task and can in fact play an important role in the understanding and quantification of pathology in clinical practice.
591,it allows them to detect national news bias and thus improves transparency and democracy.,this enables national news bias detection and thus improves the degree of accountability and democracy.
592,spectral partitioning traditionally uses the graph laplacian.,"traditionally, the graph laplacian is used for spectral partitioning."
593,"finally, a pooling function is used to merge the vectors into one.","finally, we use the pooling function to merge the vectors into a single one."
594,"custom actions can easily be added by either extending or aggregating the existing implementations or implementing the action interface directly, allowing for a diverse variety of repetitive use-cases.","extended or aggregations of existing implementations can easily be implemented as custom actions, allowing a wide variety of repetitive use-cases, but avoiding any major impact on performance."
595,be a set of joints connected by links arranged in a tree-structure.,"consider a tree-structure of splints, which is a set of joints with connected links."
596,"the simulator is fed with an instruction trace, corresponding to a given program executing a given data set.","the simulator is fed an instruction trace, representing a given program execution, per instance of the data set."
597,the use of non-linear parameter estimators comes at a price.,the use of a nonlinear parameter estimator comes at a price.
598,people trust the company based on the quality of produced software; thus they also trust the programmers who create the software.,we will establish that people trust the companies based on the quality of the software produced; thus they also trust the programmers who create the software.
599,"problem, which demonstrated the inadequacy of the safety footprint notion in yielding complete specifications.",these problems have exemplified the inadequacy of the safety footprint notion in yielding a complete specification.
600,in essence the auto-encoding layer is representing the data as a smaller set of variables that describe the data in a more concise manner.,in essence the auto-encoding layer can be thought of as representing the data as a smaller set of variables to describe the data in a more concise way.
601,previous studies have used simple keywords to filter climate change tweets.,previous studies used short keywords to filter out climate change tweets.
602,"this is not to say that there are more false statements in real-life, just that there are many more possible false statements than there are true statements.","this is not to say that real-world statements may have more false statements than true statements, just that false statements are likely to exist in an increasing number of spaces."
603,the dashed line is a qualitative description of the phase boundary given by eq.,the dashed line is the qualitative description of the phase boundary given by eq.
604,an algorithm which performs well on the test problem by effectively tackling most of the challenges offered by the test-suite is expected to perform good on other simpler problems as well.,"one could expect that an algorithm that performs well on the test problem, efficiently tackles most of the constraints of the test problem and does well on the other simpler ones."
605,"patches are local portions, or snippets, of a signal or an image.",patches are local pieces (or snippets) of a signal or image.
606,adding an extra piece of history does not change the conditional distribution for the next observation.,adding more history in the gnf does not change the conditional distribution for the next observation.
607,"since the new estimate is more accurate than the old one, the process can be repeated by estimating a new, more accurate predictor.","the process can be repeated to estimate a new more accurate predictor, since the new estimate gives a larger value than the old one."
608,a number of businesses and organizations are using twitter or similar micro-blogging services to advertise products and disseminate information to stockholders.,twitter or similar micro-blogging services are used by many businesses and organizations to advertise products and provide news to their shareholders.
609,"every morning, users had the latest episodes of their favorite series pre-fetched on their mobile phones",users did not always check their cell phones with the latest episode of their favorite series before waking up in the mornings.
610,"comparing uniform quantizers with the same number of bits but different step sizes, we see that smaller step size produces better performance in the waterfall region but a higher error floor.","we compare uniform quantizers that have the same number of bits but different step sizes, and we see that larger step size produces better performance in the waterfall region but a larger error floor."
611,"there is no clear picture of what causes these topics to become extremely popular, nor how some persist in the public eye longer than others.","we don't have a clear picture of what makes certain topics so popular, or how some remain in the public eye longer than others."
612,"the taxonomy is composed by a set of topics, each one is defined by a set of keywords or hashtags that should co-occur in a particular way.","each topic in the taxonomy is comprised of two or more topics, each of which is defined as a set of keywords or hashtags that should coincide in a particular way."
613,"also, the higher the prediction order, the larger the sum-rate gain.","we also note that the better the order of predictions is, the larger the sum rate gain is."
614,note that we are not making the coarse belief assumption and supposing that workers can have arbitrary beliefs.,note that we are not making a coarse belief assumption and supposing that worker beliefs may be arbitrary.
615,global arrays includes functionality to control the mapping of a global array onto the processes.,global arrays include functionality to control the mapping of a global array to a process instance.
616,we provide a brief overview of logistic regression and how it is used to train the readouts from the sensor to produce the desired output.,we give a brief overview on logistic regression and how it can be used to train the readings from the sensors into providing the desired output.
617,this experiment shows the advantage to bring all the system improvement together and solve a real-world scale problem.,"this example shows the advantage of bringing all the improvements to one area, by solving a real-world problem of scale."
618,"so, we prefer to write our own algorithm, even if most ideas are from existing work.","as such, we have chosen to write our own algorithm, although most of the ideas from previous work come from the literature."
619,"is offered using tools for instance management, data management on the instance and execution management of a task on the instance.",an instance deployment with instance management tools is offered and data and task execution management are implemented on the instance.
620,"admittedly, a preprocessing step is required to build the metric.","admittedly, we need to construct a metric in a preprocessing step."
621,"conversely, separable dimensions are those where there is no such implication, such as height and sweetness.","conversely, separable dimensions are those that lack such an implication, like height and sweetness for example."
622,it shows that these types of information are all value-added and combining them is a workable way to get better results.,"it shows that all types of these representations are value-added, and combining them is a tractable approach for obtaining better results."
623,this school is located in a wealthy district of a large city and belongs to the private catholic sector.,this school is located in a wealthy neighborhood of a large city and belongs to the catholic private catholic sector.
624,we can estimate the direction of the target based on the simple information given by the sensors.,"using the simple information offered by the sensors, we can estimate the direction of the target."
625,"the policy is probabilistic instead of being definite using probability amplitude, which makes it more effective and safer.","the policy focuses on probabilistic entanglement in place of being deterministic and uses probability amplitude instead, and thus it is more effective and safer."
626,the interposed neuron performs the summing and passes its result to the inhibitory neuron.,the interposed neuron performs the summation step and passes its results to the inhibitory one.
627,"in other words, this structure is still far from being practical.","in other words, the structure is still far from being practical."
628,"color bars show the natural logarithm of density, changing from minimal nonzero density (dark) to maximal one (white), zero density is shown by black.","the color-bar is a natural logarithm of the density, and ranges from minimal nonzero density (dark) to maximal one (white), zero is shown in black."
629,"there is a subtle issue with this, but exploring it will put us on the right track.","there is a subtle issue here, but exploring it will lead us to the right direction."
630,"the darker the vertex, the larger the percentage of neighbors of the vertex that belong to the community.",the dark vertices have larger values for the fraction of their neighbors that belong to the community.
631,we can perform a sequence of invertible operations at transmitter and receivers to convert the channel to its simplest form.,the aim of our procedure is to convert the channel from its simplest to its simplest form and execute an invertible sequence of operation at both the transmitter and the receivers.
632,"the program should be combined with the definition of the domain predicates vertex, e, character, state, f describing the given phylogeny.","the program must integrate the definitions of the domain predicates of the vertices, e, char, f, and state for the given phylogeny."
633,they guarantee to deliver messages with high probability to all nodes with little communication overhead.,they guarantee a message delivery with high probability at all nodes with minimal communication overhead.
634,"speed data does not indicate if a person is turning at an intersection or merely stopping at a stop sign or red light, so multiple alternative pathways exist that match some of the speed data","this implies that several alternative trajectories exist, which are more consistent with the speed data, because the speed data does not reflect whether a person turned around at an intersection or simply stopped at a stop light or red light."
635,"other studies have shown that such face-to-face interaction between employees can have important effects on productivity and innovation, but these are phenomena that require evaluation over a longer period.","other studies have shown that such face-to-face relationships between employees can have important effects on productivity and innovation, but those interactions require long-term evaluation."
636,"actually, in a number of cases it is relevant, and even mandatory, to start the implementation procedure from a set of models that does not come from a structured specification","in fact, starting the implementation procedure from a set of models, that does not arise from a model-driven specification is of great interest, and even mandatory in several cases."
637,the cup rule is used in a wide range of situations including major sporting competitions like the world cup.,the cup rule has been used in a wide range of scenarios including major sporting tournaments such as the world cup.
638,"the generated output is formatted in plain text, which is then forwarded to the db.",this generates a plain text output that is passed on to the db.
639,"for example, we use a country code to determine a country: layer names, unlike cv-classes, do not provide a hierarchy.","we use country code for country-specific data: layer names provide no information about hierarchy, unlike cv-classes."
640,"handicapping, in sports and games, is the practice of assigning advantage through scoring compensation or other advantage given to different contestants to equalize the chances of winning.","handicapping, in sports or games, is a practice that assigns an advantage to a player through scoring payoffs or other advantages in order to even out its winning chance."
641,"as they are defined by the agent programmer at design time and do not (in principle) change at run time, we avoid including them in the configuration for the sake of readability.",for the sake of readability we avoid mentioning these at design time since they are defined at design time by the agent programmer and don't (in principle) change at run time.
642,"the importance of being promoted has, among other things, spawned a black market which claims the ability to manipulate the voting process.","the importance of promotion has, among other things, given rise to a black market that claims that it can manipulate the voting process."
643,fuzzy c-means clustering method is used for layer segmentation.,layer segmentation is performed using the fuzzy c-means clustering method.
644,"wireless technology is widely used in cyber-physical systems such as air-traffic control, power plants synchronization, transportation systems, navigation systems and human body implantable devices.","wireless technologies are widely used in cyberphysical systems such as air traffic control, power plant synchronization, vehicle navigation systems, navigation systems, and human body implantable devices."
645,a deepdivesystem is only as good as its features and rules.,depthsystem is only as good as its features and rules.
646,"numerous different networks can be constructed, depending on which entities we use and how we connect them to each other.","it depends on which entities and how we inter-relate those entities to each other, a variety of different networks can be constructed."
647,quite a bit of time and effort went in to putting this competition together.,this contest has been developed and staged with quite a considerable amount of time and effort.
648,"energy-constrained wireless networks, such as sensor networks, are typically powered by batteries that have limited operation time.","battery-powered wireless systems often run on battery and have limited system lifetime, which affects the energy efficiency in energy-constrained wireless networks such as sensor networks."
649,"the program then tries to apply the following rules, in order, on each node.",the program then tries to execute the following rule in the order of that node.
650,"possible events would be rain, forest fires, or occurrences of invasive species.","rainstorms, forest fires and the occurrence of invasive species might occur."
651,"if we had observations from the other dataset, then we could use fine-tuning to adapt the convolutional neural network itself.","we then used fine-tuning to evolve the convolutional neural network itself, if we had observations from the other dataset."
652,"successful learning requires the learner to observe certain restrictions, for example convergence to a correct index.","successful learning requires that certain bounds, for example convergence to the correct index, be observed by the learner."
653,these models learn distributions or weights on simple graphs (typically linear chains).,simple graphs (usually linear chains) are used to learn the distributions or weights of these models.
654,"these data can be bulk exports from databases, application logs, and many other sources.","one can bulk export such data from databases, application logs, and many other sources."
655,the vertical axis is the cost reduction as compared to the cost benchmark in sec.,the lower line shows the reduction compared to the cost benchmarks considered in sec.
656,the way they introduced dynamics is by looking at some relevant measures chapter by chapter and comparing them.,dynamics was introduced by examining some relevant measures chapter by chapter and comparing.
657,"so for a given equilibrium, we can compute the total cost incurred to the population.",this gives us the ability to compute the total cost incurred to the population for a given equilibrium.
658,those non-functional requirements describe properties of the system that are not its primary functionality.,these non-functional requirements document properties of the system that are not essential to its operation.
659,"back to the clustering problem, how do we compute the clusters efficiently using the mmi?","again considering clustering, how would the mmi be able to efficiently compute clusters?"
660,"information flows, this could fit well, but in networks with undirected edges, it is not so useful.","this might work well for information flows, but it turns out not so well for networks with undirected edges."
661,"the price of service remains unchanged, therefore reporting incentives are unaffected.","the service price is unchanged, hence reporting incentives remain unaffected."
662,parameterization refers to the process of mapping a complicated domain one-to-one and onto a simple canonical domain.,parameterization is the process of mapping a multiscale domain one-to-one onto an algebraic canonical domain.
663,"finally, we will combine the concepts into a meta-model to show the complete picture.","finally, to show the complete picture, we combine these concepts into a meta-model."
664,"although it will be hard to migrate thousands of existing scripts, empirical analysis on a distribution sample has shown that most scripts are just a few lines of code, and are mostly automatically generated.","although migrating thousands of current scripts may be hard, empirical analysis on the distributional sample shows that most scripts are only a few lines of code and are mostly generated automatically."
665,"there are, unfortunately, several points of variation when it comes to extracting the in-game values.","sadly, when extracting ingame values, there are several uncertainties."
666,"although this was a safe convention when talking about deduction, it is no longer the case when our interest shifts to models.","though this is a safe convention for discussing deductions, it is not anymore when our interest moves to modeling."
667,our method has the additional advantage of being conceptually simple and easy to implement.,the benefit of our method is that it is conceptually simple and easy to implement.
668,the features could be the number of edges or the number of faces etc.,"for example, features could be the number of edges, the number of faces, etc."
669,the agents are placed at their home counties and colored by their work counties.,we group the agents in their home counties and color the agents according to their working counties.
670,then one embedding can be transformed into the other while preserving all faces including the outer face.,"thus one embedding can be transforms to the other, while preserving all the face, including the outer face."
671,"this phenomena, which is called fading, degrades the system performance.","the phenomena, called fading, degrades the system s throughput."
672,one of the biggest concerns is leakage or tampering with private data.,leakage or manipulating private data remains a primary concern.
673,these neurons are physically wired together by fiber-like projections called axons.,these neurons are physically wired through projections called axons.
674,"for this purpose we will use the median, as it is a very robust statistic insensitive to outliers.","we will use the mean, as it is a robust statistical index that is insensitive to outliers and is highly robust."
675,we do not have to worry for every activation if every dependent context is considered.,"considering every dependent context, we don't have to worry about every activation every time."
676,the effect of video pooling along with each data augmentation method is provided in tab.,"in addition to the two dma techniques, the video pooling effect is given in tab, along with each dma augmentation procedure."
677,"also, we can provide quality-of-service differentiation to secondary users by specifying different protocol parameters across secondary users.","also, we can have differential functionality between the secondary user and qos by specifying different protocol parameters for different secondary user cases."
678,deep neural networks is a branch in machine learning that has seen a meteoric rise in popularity due to its powerful abilities to represent and model high-level abstractions in highly complex data.,deep neural networks are a branch of machine learning that has been seeing a meteoric meteoric rise in popularity in recognition of their powerful abilities to represent and model high-dimensional abstractions on highly complicated data.
679,we can track the time evolution of the probability distribution of messages (or the probability density function in a case where the messages are continuous).,"we can track the time evolution of message probability distribution (or, in the case of continuous messages, the evolution of message probability density function)."
680,we can see that the retrieved keywords often summarize and further explain the documents.,we can see that the retrieved keywords often summarize the retrieved text and further explain the document.
681,"furthermore, the residue of the derivative of any series is zero.","furthermore, the residue of any derivative on any sum is zero."
682,"if we apply vt to a gaussian mixture for clustering of continuous data with an assumption of a common variance to all composite gaussian distributions, the resulting algorithm is identical to k-means.","the above results show that applying vt to a gaussian mixture for continuous data clustering using a conjecture of common variance across all composite gaussian distributions, gives us a method very similar to k-means."
683,"then, to collect the subjective perceptions of the participants we used subjective ratings extracted from questionnaires.",we then incorporated subjective ratings extracted from the questionnaire to obtain subjective ratings in response to the survey questions.
684,"therefore, we can reset the alleles at those loci involved in the path.","thus, in the path involved, we can reset alleles at those loci."
685,a captain serves as an indicator of his ability and skills as a batsman irrespective of external factors like match situation or strength of opposition.,"irrespective of external factors like match situations and batting strength of opposing teams, the captain serves as a reflection of his personal ability and skill as a batsman."
686,take it as a warning sign when it no longer fits on the back of an envelope.,this can be seen as a warning sign when the package will no longer fit in the envelope backside.
687,now we use the same source code as above but instead of optimising the channel code for the downlink for one particular source we optimise it for a range of sources.,"we now reuse the same source code as above but instead of optimizing the channel code for a single source, we optimize the code for the multiple sources."
688,"news sites article pages, blogs, and videos are the most encountered examples of this.","examples of news articles that most commonly occur are article pages on news sites, blogs, and videos."
689,"there is of course no reason to stop the process here, as we can iteratively get even better weights.","this process should not stop here, as we can iteratively find even better weights."
690,"while using the af protocol, the relay node amplifies the received signal sent by the source, and then retransmits it to the destination without decoding.","meanwhile, the relay node amplifies the received signal from the source using af-based relaying and then forwards the uncoded signal to the destination without decoding."
691,the well coordinate variables in our work are continuous but will be rounded before we pass them to the simulator to evaluate the objective function.,we keep the well coordinate variables continuous but we round these before passing them to a simulator to evaluate their objective functions.
692,"work then with an optimization problem on these bits only, setting the noise value on all other bits to zero.",work then on the bit optimization problem reducing the noise value on the remaining bits to zero.
693,"so, the required reconfiguration of the network needs to be done in small (from several minutes to few hours) as wells as large time scales (from few days to few months).","therefore, we can consider a network reconfiguration in both small time scales (several seconds to many hours) as well as large time scales (several days to a few months). to make a good comparison,"
694,another problem one runs into is that there is often not a unique solution.,another difficulty one encounters is that they often have no unique solution.
695,clustering is a helpful first step in studying the metabolic pathways and disease pathology.,clustering provides a helpful first step in studying metabolic pathways and disease pathology.
696,a higher likelihood is then an indication of a higher relevance to the query dataset.,"furthermore, a higher probability indicates that the query dataset is more relevant."
697,authors placed men and women in bad and good environments and then provided them with magazine articles.,"authors used magazine articles as a way to place men and women in bad and good environments, and then published them as magazines articles."
698,"hence, there is a negative externality associated with not investing in self-protection, namely the increased risk to others.","thus, the absence of self protection provides negative externalities, namely, increased risk to others."
699,"statement is false, and execute the remaining tasks only after the condition becomes true.","if the statement is false, then only the remainder of the tasks are executed and the condition becomes true."
700,instead of saving the input expression to a file we put it into the command line and read the results back directly from the external command output.,our default procedure is to write an input expression and read its results from external command output instead of saving it to a file.
701,sometimes they seem to work because of underlying hidden parameters in the input.,these functions usually work partially because of hidden parameter values inside the input.
702,"from now on, proofs omitted in the main body of the paper can be found in appendix a).",as from now on the proofs omitted in the main body of the paper can be found in appendix a).
703,hence form supports a number of non-local operations the most important of which is the sort operation.,"this means that form supports a lot of non-local operations, the most important of which is the sort operation."
704,this task is performed using a classification approach which is the second major contribution of this paper.,the second main contribution of this paper is in performing this task through a classification approach.
705,"in other words, the higher the peak the wider tend to be its basin of attraction.","that is, the more voluminous a peak, the more extensive is its attraction basin."
706,the gray lines in the figures are the expectation lines from the above equation and agree perfectly with the data,the grey dots in the figures are the expectation lines from the above equation and match the data perfectly
707,the theorems below are the control versions of the theorems for the prediction case.,the theorems above are the control version of the predicting case theorems.
708,modelling and specifying strategies is a fundamental research theme in game theory.,a core research theme in game theory has been the modeling and specification of strategies.
709,"this brings me to one big concern about the paper, which is the overall length of the paper.","this leads me to the key aspect of the paper, which is the length of the entire paper."
710,we will then discuss in the following sections how to take channel time variation into account.,we discuss in the following sections how to account for channel time variation.
711,"similarly, we may remember a few things that we need to shop for, but our priority list would often contain only one item: go to the supermarket.","similarly, we may remember few items that we need to shop for, but the last item in our priority set would often be the simple one: to go to the supermarket."
712,other multiple comparison test like tukey lsd and duncan test gave the same type of clustering output.,we also found other clustering outputs of similar type from various multi-comparison tests like tukey lsd and duncan test.
713,the variances and covariances needed to evaluate the determinants and detailed derivations for the following formulas are given in the appendix.,the appendix provides the variances and covariances needed to evaluate the determinants and detailed derivations for the following formulas.
714,"recently, deep learning approach has been applied to this area and well tackled the vocabulary mismatching problem.",the vocabulary mismatching problem was recently formulated and well handled using a deep learning approach.
715,"in addition, we used the timestamp of a rating as a proxy for a time when the movie was actually watched.",we also used the rating timestamp as a proxy for the actual viewing time of the movie.
716,"our method is more focused in finding information from the data given, rather than finding patterns based on personal relevance judgements and this is a major advantage towards supervised learning to rank approaches.","this is a major advantage of our method over rank-based approaches that focuses on learning information from provided data, rather than on finding pattern recognition from personal relevance judgements."
717,"under such a scenario, coverage may not be the right cost function to optimize.",the best cost function to optimize may not be the coverage function in this scenario.
718,"the first column of the table gives the name of program, the second one gives ratio of run ","the first column gives the name of the program, while the second one gives the run ratio"
719,but it seems that in order to make our observations one needs to look at large networks.,"yet, it seems that one should look at large-scale networks to obtain our findings."
720,"then q, followed by p, followed by q, dip their fingers into the box, without looking at the penny, and either flip it over or leave it as it is.","q, p, and q next, dip their fingers into the box, without looking at the penny, and either flip the coin on its side or leave it as it is."
721,this is the case because the model can be used as basis for quality assurance techniques such as reviews.,this is justified as the model is applicable to other quality assurance techniques such as reviews.
722,if a string is already compressed very well it is almost impossible to compress it much more.,"if a string already compresses quite well, it is almost impossible to compress it much more."
723,"many standard invariants not only have high sensitivity to a small proportion of bad samples, but in fact have high sensitivity to a small number of bad samples.","many standard invariants not only have high sensitivity to small numbers of bad samples, but in fact are indeed highly tolerant to small numbers of bad samples."
724,after validating the accuracy of the developed module the next step was to openly provide age estimation as a web service.,once the accuracy of the developed module has been validated our next step was to openly offer age estimation as a web service.
725,the dashed line is a qualitative description of the phase boundary given by eq.,the dashed line represents the phase boundary qualitatively given by eq.
726,note that many references resort to a normalized notion of support by dividing by the dataset size.,note that many references resort to normalized notions of support using the dataset size as the unit of measure.
727,this is almost the same as having a computer in every page of the book without the cost.,this is almost equivalent to having a computer on every page of a book without any cost.
728,modularisation enables us to choose appropriate modules and extend the quality model with additional modules for a given context.,modularization enables us to design appropriate modules for an area and extend our quality model by adding additional modules that are appropriate for the context.
729,"therefore, a good algorithm should not only quantify the topology of the network, but incorporate the dynamical processes that take place on the network as well.","thus, a good algorithm not only needs to quantify the topology of the network, but also incorporates the dynamics of the processes in the network."
730,we can first track all points in the object using breadth-first-search.,we first perform a breadth-first-lookup of the object that can capture all the points inside the object.
731,if neural nets are to learn to generalise well then we must train on much larger numbers of appliances (hundreds or thousands).,"if neural nets are to learn well, they must be trained on a much larger dataset (hundreds or tens of thousands). in this case"
732,"the most pronounced exception is south america, moving into its deep recession.",a most important exception is south america moving into its deep recession.
733,evaluation of the maximum-likelihood estimator where the likelihood equation has multiple roots.,we study the higher-likelihood estimator when the likelihood equation has multiple roots.
734,"nodes may consist of multiple attributes but they always include a latitude, longitude and a unique node i d.","nodes may have multiple attributes but always contain latitude, longitude, and unique i d."
735,resource management functionalities range from gathering resources required for an analytical job and releasing them after their use.,"the range of resource management functions covers gathering resources for an analytical job, and dissipating these resources after their use."
736,"the aggregation procedure is easy to implement, employing a simple criterion, and can be applied to graphs with any link structures.","the clustering procedure is simple, employs a simple criterion, and it can be applied to graphs of any link structure."
737,this test of significance allows us to rank order the discovered patterns.,this sort of significance test permits us to rank the discovered patterns.
738,"since some of the entries can be extremely small, the decoding matrices can be close to singular.",the decoding matrix of the corresponding graph may have close to singular numbers due to the fact that some of the entries may be very small.
739,"when the task scheduler service starts, several threads are created on each worker process.",each worker process starts multiple threads that interact with the server when the task scheduler service begins.
740,"for example, a plant with time varying topology, etc.","for instance, the plant may have a time-varying topology, etc."
741,"in addition to efficiently modeling data samples, kernel sparse coding is well suited for supervised learning tasks.","to be efficient for data sampling, kernel sparsity coding is a good choice for supervised learning tasks."
742,creating small robust networks that are cost-effective will enable easier introduction of the microgrid philosophy to the residential community.,"such a design gives the microgrid philosophy easier adoption in residential communities, and produces small robust networks which are cost-effective."
743,"observing those evolutions allows estimating the simulation distribution and infer global trends of the time series, as the evolution of its mean, its variance, confidence intervals, etc.","this is important, as the mean of the metric, its variance, confidence intervals, etc."
744,"this relatively simple two-class model linked word tokens in parallel texts as accurately as other translation models in the literature, despite being trained on only one fifth as much data.","the data, only one fifth of the total number of words in parallel texts, gave us a very accurate translation model for both words and phrases, a relatively simple two-class model."
745,"also, we do not focus on properties of the agents involved in conversations except for some demographic features like age and gender.","we also don't consider the properties of agents involved in conversations beyond the partial use of some demographic features, such as age and gender."
746,the reward from a target is fairly allocated to sensors covering the target.,the rewards that an agent receives from the target are ad hoc distributed among the sensors that cover the target.
747,"please realize that there are several subtleties of different algorithms and their interactions that are hard to show in a diagram, it is included purely as illustration of the impact of our results.","notice that while this figure illustrates a subtle point of each algorithm and its interaction with other algorithms that is hard to convey in a diagram, we include it for illustrative purposes."
748,"the first term in the residual shows the replacement of the amplitude in the real domain, which is the projection from the estimation to the modulus space.",the first term in the residual displays the transformation of the amplitude of the estimator to its real domain which represents the projection in the modulo space.
749,"since each of these will add a scaled version of an existing column in the matrix, this does not change the determinant.","these will not change the determinant, since each of them introduces a scaled version of the corresponding column in the matrix."
750,the prototype is a meta-interpreter using ground representations for program variables.,the prototype is a meta-interpreter that makes use of ground representations for program variables.
751,"for example, in situations where we wanted to graph how rapidly different strategies converged with respect to generations, it made sense to fix the number of generations.","if one wants to see how quickly different strategies converge with respect to generations, fixing the number of generations would be worth consideration in this setting."
752,"multiple blocks can be used in this case, with each block corresponding to subset of rows in the dataset.","the method is applicable in other cases, where the number of blocks in each block corresponds to some subset of rows in the dataset."
753,this might be an influential indicator for behavioral organization and continuity reflected in overall interaction footprint of students.,this indicates that the sum total interacting footprint of students could be an influential indicator of behavioral organization and consistency.
754,it is defined as predicting the missing links from a partially observed network topology (and some attributes if exist).,"it is defined as the prediction of missing links from a partially observed network topology (and its attributes, if any) in the form of a sparse set."
755,"clustering is a fundamental process for applications such as content analysis, information integration, information retrieval, web mining and knowledge discovery.","clustering is a crucial process in applications such as content analysis, integration of information, information retrieval, web mining, and knowledge discovery."
756,"they are easy to convert into algorithms for trigraphs, but it is hard to get convinced by that without going through all the algorithms.","they are easy to port into trigraph algorithms, but it is difficult to be convinced without a full run through of all those algorithms."
757,we do not actually traverse the time axis in time ticks once for each pattern whose occurrences we want to count.,"henceforth, for every pattern whose occurrences we want to count we don't actually traverse the time axis in time ticks."
758,"allocation is faster because continuations are resized dynamically when needed, whereas other backends need to allocate a large chunk of memory at once.","while for other backends, this requires allocating a large chunk of memory at once, this allocation is faster because continuations can be resized dynamically whenever needed."
759,"while centralized resource allocation schemes can achieve a better performance compared to distributed algorithms, in most practical scenarios, distributed algorithms are preferred over centralized ones.","while centralized resource allocation schemes may achieve better performance than distributed algorithms, in most practical scenarios distributed algorithms generally perform better."
760,"processes, markov chains, and so on, as special cases","we consider, as special cases, process or markov chain, and so on."
761,"we define a function which transforms implementation markings into the related original markings, by shifting these tokens back.","we define a function which transforms implementing annotations to matching original annotations, by backtracking the tokens."
762,"therefore, if problem is feasible, then problem must be feasible.","thus, if problem is tractable, then problem is tractable."
763,"normal, happy, sad, sleepy, surprised, and winking.","it typically includes neutral, happy, sad, sleeping, shock, and winking."
764,do english-speakers not feel those same emotions or do they simply refer to them in a different way? or,so are english speakers not not dealing with the same emotional intensity or are english speakers just referring to it differently?
765,"this will be represented by the agent outputting a convex mixture of action states, specified by the corresponding probabilities of the particular action.","this is represented by the agent outputting a convex mixture of action states, stating its corresponding probability distributions for particular actions."
766,there is at least one positive eigenvalue and the spectral radius of the matrix is equal to the largest positive eigenvalue.,is the smallest positive eigenvalue and the spectral radius of the matrix equals the largest positive eigenvalue.
767,stitching several volume data from a patient can improve the interpretation of data significantly.,stitching several volumes from one patient can substantially improve the interpretation of data.
768,source subspace can easily be found using the bounding boxes available for the source data.,"using the bounding boxes that are available in the source data, the source subspace can be found very easily."
769,"it is available in popular languages such as python, r, julia and integrates naturally with language native data science pipelines such as scikit-learn.","it is available in popular programming languages such as python, r, jaulia and naturally integrates with data science native pipelines such as scikit-learn."
770,role mining concerning communities mainly analyzes the relations between the communities for a specific actor.,community role mining primarily studies the relations among the communities that relate to an actor.
771,"the feedback process shows another sign of robustness, since it works in other systems as well.","we could also show that the feedback works in other systems as well, providing additional proof of robustness."
772,the cluster is primarily used for the purpose of teaching and performing multi-disciplinary research.,the cluster is intended for both cross-domain learning and multi-disciplinary research purposes.
773,these are combined into a large network that can be jointly trained to directly map an image to a sentence.,these are amalgamated in a large network allowing for jointly trained approximations that directly map the image of a word onto a sentence.
774,"now that we can learn mechanisms effectively, we plan to adapt the approach to also learn trading strategies, allowing us to co-evolve mechanisms and the traders that operate within them.","now that we have demonstrated the effectiveness of the method for learning mechanisms, we plan to adapt the approach to also learn trading strategies, in order to co-evolve the mechanisms as well as the traders operating on them."
775,the post-processing step consisting of a mapping with bases of subfields is the key in the binary case.,the key in a binary case is a postprocessing step consisting of mapping bases to subfields.
776,they aim to reduce the predictor dimension prior to any modeling efforts.,"prior to modeling efforts, the key idea is to reduce the predictor dimension."
777,"obviously, the goal is to avoid ruining the current batch.","obviously, the aim is to not ruin the current batch."
778,"an easy accounting argument, left to the reader, shows that player i can not muster a sufficient supply of customers with this maneuver.","the argument that player i can not obtain enough demand by this move is presented below, and is left for the reader as an easy accounting example."
779,the error bars are smaller than the sizes of the symbols and the lines are guides to eye.,the error bars are closer to the symbols sizes and the lines are the eyestimulation guides.
780,we see that methods using clinical data outperform the methods using web data for the majority of the vaccines.,"when performing a majority of the vaccination classes, we observe that methods using clinical data outperform methods using web data."
781,"let us consider alternative random variable, representing an alternative, specific, channel state at the beginning of the super-symbol.","let us consider alternative random variables, corresponding to auxiliary, specific, channel states, at the beginning of the super-symbol."
782,this action produces a copy of the parent repository and essentially generates a simple tree structure.,the action simply generates a tree structure from a copy of the parent repository.
783,kickback does not perform gradient descent on the error function since it uses modified feedback signals.,"kickback uses modified feedback signals, which makes it impossible to do gradient descent on the error function."
784,shannon information theory readily provides the necessary mathematical framework for measuring the information content of a variable.,the necessary mathematical framework to measure variable information content readily comes from shannon information theory.
785,the data we use in this paper are corporate financial reports which are publicly available online.,this paper uses data obtained from corporate financial statements that are publicly available online.
786,the world wide web (web) is a popular and interactive medium to disseminate information today.,"today, the world wide web (web) is a highly popular and interactive method to disseminate information."
787,"when dealing with agents that can communicate, it becomes unclear how we should interpret the notion of minimality.",this leaves us uneasy about how to interpret the notion of minima when dealing with agents who communicate.
788,a decision function defined on the input space is estimated from training samples.,training samples are used to estimate a decision function defined on the input space.
789,"informally, the relation enables us to keep a single member of each equivalence class when building plans incrementally.","formally, the relation allows us to maintain a single member for each equivalence class in a step-by-step pattern construction."
790,spectrum pooling: an innovative strategy for the enhancement of spectrum efficiency.,spectrum pooling: an innovative strategy for channel efficiency gain.
791,"this constitutes a quadratic improvement in the exploration phase of learning, and what remains to be seen is how to embed this into the complete learning package.","this constitutes a quadratic improvement of the exploration phase of the learning process, but what remains to be seen is how to embed this in our complete learning package."
792,one of the first obstacles in discussing the theory of system administration is defining its scope.,defining the scope is one of the first hurdles to discussing system administration theory.
793,we can model the fact that we bought some previous edges by zeroing out their lengths.,"for example, by zeroing the lengths of some previous edges, we may model the fact that some of them were bought on the other."
794,several state-of-the-art approaches couple a pre-trained deep convolutional neural network (cnn) for image representation with a recurrent neural network (rnn) to generate captions that describe image content.,several state-of-the-art approaches combine a pre-trained deep convolutional neural network (cnn) for image segmentation with a recurrent neural network (rnn) for generation of captions from image content.
795,"a portfolio can cover risks related to catastrophic events such as earthquakes, floods or hurricanes, and may comprise tens of thousands of contracts.","the portfolio can cover risks for catastrophic events such as earthquakes, floods, or hurricanes, and may consist of tens of thousands of contracts."
796,"even though can be used in any environment, its features have been designed to work in synergy with.","although can be adapted to any environment, has been designed to work in synergy with."
797,"core affect, prototypical emotional episodes, and other things called emotion: dissecting the elephant.","core affects, prototypical emotional episodes, and other things called emotional: dissecting the elephant."
798,distance exponent: a new concept for selectivity estimation in metric trees.,distance-exponents: a novel concept for selective inference in metric trees.
799,"after preprocessing, the datasets are ready for the feature extraction process.",this preprocessing finally brings the datasets into the stage of feature extraction.
800,biathlon refers specifically to the winter sport that combines cross-country skiing and rifle shooting.,"in particular, biathlon is the winter sport that combines cross-country skiing with rifle shooting."
801,an impact is either positive or negative and describes how the degree of presence or absence of a product factor impacts a quality aspect.,the influence of a product factor can either be positive or negative and describes how the presence or absence of a product factor impacts the quality aspect.
802,"a leader should have big overall influence, since the overall influence represents how close a node is to the core of its community, and the actual potential of becoming a leader.","because global influence is an indication of how close a node is to the core of its community and how close a node actually is to becoming a leader, a leader should possess high overall influence."
803,reinforcement learning acts optimally through trial-and-error interactions with an unknown environment.,the reinforcement learning system is optimally trained by trial-and-error interactions with an unknown environment.
804,"following the same strategy, the fisher curves regarding the remaining components were generated.",the fisher curves over the remaining component of the system were derived following the same strategy.
805,we expect that we should be able to embed a logic like this in ours.,we expect that our logic should be able to embed such logic in other places as well.
806,we have done some preliminary experiments and found that neural nets appear to be able to generalise better if we independently centre each sequence.,"we carried out some preliminary experiments which showed that by focusing on each sequence independently, neural nets perform better when generalizing."
807,"dynamic generation requires fast underlying computations to load, filter and summarize the data, and fast rendering to display the processed data on the screen.","the process is both dynamic, requiring fast underlying computations for load, filter and summarize the data, and a fast rendering to exhibit the processed data on a display."
808,"these actions can be interpreted as team members, cards in a hand, etc.","these actions can be interpreted as the number of team members, the cards of a hand, etc."
809,does not really apply to the problem at hand since the amount of data available is already very limited.,is not really applicable to the problem at hand since the amount of data available is already very limited.
810,the maximum degree is changing during the process and this behaviour is not possible to predict.,"the maximum degree is constantly changing during the process, and one can not predict this behavior."
811,"now that we know how tangles affect eigenvalues, we want to know how often the tangles occur.","now that we know how the tangles affect eigenvalues, we want to know how often tangles occur."
812,"we can then combine positively and negatively weighted word and government vectors into the same query, enabling complex, targeted and subtle similarity computations.","we then combine positive and negative weighted word and government vectors together into the same query, enabling more sophisticated, targeted and subtle similarity computations."
813,"no matter what character comes next, its capital will not change.","irrespective of what character comes next, its capital does not change."
814,"this is the way most prolog applications are used and, thus, our semantics should consider this behaviour in order to measure the coverage in a realistic way.","most prolog applications exploit this approach, so our semantics must consider this behavior in order to provide a more realistic account of coverage."
815,this will allow our optimization framework to allocate resources to videos depending on their quality.,"thus, we use our optimization framework to efficiently allocate resources to videos with regard to their quality."
816,"viewing the earlier results in this light, a natural first step in completing the picture is to return to the simpler dense network as a vehicle to focus exclusively on the issue of interference.","in this light, regressing back to more compact dense network as a vehicle for focusing on the interference problem alone seems a natural first step toward addressing the larger picture."
817,tags can influence each other over a long distance via transition probabilities.,"this is because by using transition probabilities, tags can influence each other over a long distance."
818,"so, connectivity is an easy problem and independent set a hard one, but what about expansion?","thus, connectivity is a straightforward problem, and independent set is a difficult one, but how about scale expansion?"
819,"the faster disease spreads to the entire network, infecting essentially everyone it was going to infect, before the slower disease rises beyond the level of insignificance.","the faster disease propagates over an entire network, infecting essentially everyone it is going to infect, while the slower disease goes above the threshold of impossibility."
820,"in fact, cyber-based threats to critical infrastructure are real and increasing in frequency.",these events are real and increasing in the frequency of cyber-attacks on critical infrastructure.
821,the introduction of randomness in continuous models can be done using different approaches.,different approaches have been used to introduce randomness in continuous models.
822,interval arithmetic is a mean to perform numerical computations and to get a guarantee on the computed result.,interval arithmetic is the means of numerical computations and of getting a guaranteed computed result.
823,"movies, however, typically have more ratings and more latent information to infer.","movies, on the other hand, have usually higher ratings and more latent information to infer."
824,"the abstraction enables application developers to create, operate and destroy hierarchical grid structures.","this abstraction allows application developers to set up, operate on, and destroy hierarchical grid structures."
825,youtube now has over a billion users and is continuing to grow.,youtube has grown to more than one billion users and continues to grow.
826,"in this section, we discuss the motivation for our work as well as comment on our design decisions for this framework.",we discuss the motivation for our work and remarks on our design choices regarding our framework.
827,what are typical community sizes and typical community qualities? to address these and related questions,what are typical community size and common community attributes? to address these and related questions.
828,"second, with limited data, training a large-capacity network without regularization from geometric constraints entails a high risk of overfitting.","secondly, the likelihood of overfitting is high if the trained classifier lacks regularization for the geometric constraints when the data are limited."
829,"however, using a quantifier elimination program, we can easily compute that the formula is in fact false.","in contrast, we can quickly compute the contrary of this formula, using the quantifier elimination program."
830,this means that any method that can be invoked by the framework is an entry point.,the idea is that every method that invokes a set of common concepts from the framework can become an entry point.
831,"even if quantum computers do not yet exist, perhaps we should already start worrying.","although quantum computers have yet to exist, we ought to at least start worrying."
832,this becomes the input to the weka suite of supervised learning algorithms.,this is fed into a suite of supervised learning algorithms in the weka suite.
833,"since these resources are limited, it has to decide which node to explore.","one must decide which node to explore, since the resources are finite."
834,the resulting block structure is then stored in a file to be loaded by the simulation at runtime.,the resulting block structure is then stored in a file to be loaded by the simulation at run-time.
835,section describes the system model including the queue model and profit of sus.,"this section describes the system model, including the model of sus, and the profits of sus."
836,the all-at-once model does not have this luxury.,this is not available in the all-at-once model.
837,we could instead ask for it to be a chain (any two elements are comparable).,"instead, we ask for it to be a chain (any two elements are a match)."
838,we want to obtain a sparse set of coefficients (sparsity level k) to represent the signal.,our goal is to obtain a sparse set of the coefficients (k-sparsity level) to represent the signal.
839,"semi-supervised learning can incorporate more prior information, and multiple instance learning focuses on the uncertainty about where to select positive samples for model updating.",semi-supervised learning may incorporate more prior information and multiple instance learning focuses on uncertainty where to select positive samples to update the model.
840,"to evaluate the translation performance of onts, we run a set of experiments where we translate a test set for each language pair using our system and google translate.","in order to evaluate onts for translation performance, we conduct a set of experiments in which we translate a test set per language pairing using our system and google translate."
841,smith teaching logic provides support for logic being a better choice than algorithms.,smith s approach to learning logic provides support for the argument that logic should be used in lieu of algorithms.
842,children made significantly less writing errors compared to the ones that played the control condition game.,"in contrast to the children playing the control condition game, children generated significantly fewer writing errors."
843,"then we expound on the three steps of our validation framework, viz.","we then outline our validation framework in terms of three steps, viz."
844,"matrix factorization assumes that a movie preference is based on a weighted sum of preferences for different genres, with the movie properties being represented in vectorial form.","matrix factorization assumes that film preference depends on the weighted sum of preferences over different genres, with the movie features to be represented as vectors."
845,now most of those data are either ported to or accessible from the web.,most of these datasets are now imported or exposed to the web.
846,"these users tend to mention broader topics in their biographies such as: love, life, world, etc.","this is due to the users behavior in placing their profiles on broader topics such as: lovers, life, world, etc."
847,"short of actual system deployment, only simulations can answer these questions.","these questions are answered by only simulations, which are conducted within a very short timescale of actual system deployment."
848,users liked the speaker detection and immersive visual composition features in the presentation mode.,we found that the immersive visual composition and speaker detection features made the presentation mode extremely appealing to users.
849,and consequently we aim to get the expected shown up direction for a node in the sector.,we then aim at estimating the expected shown heading of a node in the sector.
850,"thus, in these lists we find political leaders, revolutionaries, famous musicians, writers and actors.","we obtain thus lists of political leaders, revolutionaries, famous musicians, authors, and actors."
851,the error will be of more importance for smaller subpopulations.,smaller subpopulations have more significance over the error.
852,"while bayesian models can often significantly reduce overfitting compared with their deterministic counterparts, the inference processes such as mcmc and variational inference are usually much slower to run than direct optimization.","compared with its deterministic counterpart, bayesian models usually run much slower but inference processes such as mcmc or variational inference are much slower than direct optimization."
853,"the ability of answer set programming to model defaults, exceptions, weak exceptions, preferences, etc.","answering set programming has the capability to model defaults, weak exceptions, preferences, etc."
854,"the recruitment process involved an open invitation to all the members of the research groups, followed by a face-to-face consultation where each potential participant had a chance to discuss the details of the study.","this was done through an open invitation process to all members of their research groups, and then an individual, face-to-face, meeting in order to discuss the specifics of the research project."
855,"this avoids the technical hurdles of installing software on the user side, and simplifies updating the software.",this avoids the technical headache of installing software on the user side and simplifies the update process for the software.
856,we can look for polarities in the data; or anomalous scenes or words; or clusters or other configurations of scenes with reference to words or vice versa.,"thus, we can find polarities in the data; asymmetry in the scenes or words; or clusters or other configurations between the scenes corresponding to the words; or vice versa."
857,we can see that the estimated numbers are close to the actual numbers for most name references.,"we observe that for most of the reference names, the estimated values are close to the real numbers."
858,recommended best practice is to select a value from a controlled vocabulary or formal classification scheme.,choice of values from a controlled vocabulary or formal classification scheme is a recommended best practice.
859,this is done by checking for common suffixes on nationalities and matching the first half of the of the words based on exact match.,we do this by checking for shared suffixes with nationalities and assuming that the first half of words are matched by exact matches.
860,the simplest approach we use is to estimate the complexity of different types of traffic.,our approach is based on the estimation complexity over all types of traffic.
861,the question of sufficiency is about how small the basis can get.,the sufficiency issue is about the size of the basis.
862,"time, frequency, or space domain extension is required to render the channel model multi-dimensional.","the channel model needs to be multidimensional either at time, frequency, or in the spatial domain."
863,"therefore, we can reduce the working hours for the implementation and try various algorithms readily.","thus, it is trivially feasible to reduce the work hours to implement the algorithm and test various algorithms."
864,"otherwise, one extra unit of actual demand is counted as well.",otherwise one extra unit of actual demand is included in the count.
865,the target appliance activation must be completely contained within the sequence (unless it is too large to fit).,the target appliance activation is completely contained within the sequence (unless it is too large to fit).
866,"so, on restart, we create an entirely new infiniband resource (using the same parameters as the original).",we can then (using the same parameter set as the original) create entirely new infiniband resources when the network restarts.
867,it solves constraints partially and tries to detect failure as early as it can.,"it partially solves the constraints, and tries to detect failure as early as possible."
868,"actually, there is a quite simple way to verify that they are not reliable due to problems in the numerical evaluation.","although numerical evaluation problems make this sound, checking that they are not solid is quite simple."
869,"the rule creates a new operator, and assigns it to a machine.",this rule creates a new operator and assigns it to some machine.
870,web content mining might utilize text and links and even the profiles that are either inferred or inputted by the users.,"some web content mining might utilize texts, links, and even user profiles that were either inferred or supplied by users themselves."
871,"it can be advantageous to continue adding variables, even as their prospects for being relevant fade away.","as their prospects of relevance fade away, it may be beneficial to continue adding variables."
872,"hence, the larger the look-ahead window, the better the performance.","hence, the better the performance is the larger the look-ahead window."
873,"for block-wise crossover, each node independently determines whether each block is crossed over.","for block-wise crossover, each node determines independently whether or not to cross any block."
874,the approach is trained on already-populated entity pages of a specific type by learning templates about the section structure at the type level.,this approach learns templates from type-level section structure by training a framework on previously trained entity pages of a given type.
875,the usefulness of an index is measured by the successes and failures of decisions based on it.,the utility of the index measures the success or failure of decisions based on the index.
876,the last entry represents the fit to the sum of the preceding data sets.,the last entry in the set represents the fit to the sum of the previous data sets.
877,the platform is designed for both batch mode execution and interactive mode execution.,the platform allows execution of both batch mode and interactive mode.
878,"one benefit of java as an object oriented language is code reuse via subclassing, so we could just make another class that extends, assuming we want this to be part of the same program.","code reuse through subclassing is an asset of java as it enables us to add more classes by extension, in the case of assuming we are involved with the same class."
879,the edge sampling treatment improves the effectiveness of the stochastic gradient descent without compromising the efficiency.,the edge sampling treatment achieves the best performance of stochastic gradient descent without compromising the efficiency.
880,"although entropy estimators have many nice theoretical properties in the asymptotic limit, for finite sample sizes we must ultimately rely on empirical results.","although the asymptotic limit of entropy estimators has some nice theoretical properties, to do well with finite sample sizes we ultimately rely on empirical results."
881,the accurate direct algorithm is used for calculating short-range force while we use the tree algorithm for calculating long-range force.,"while we used a tree-based algorithm to calculate the short-range force with accuracy, we used an accurate direct algorithm to compute the long-range force with accuracy."
882,"machines will perform computations faster, make sense of large amounts of data, and be more energy efficient.","this has implications for computing faster, making sense of large amounts of data, and making machines more energy efficient."
883,"in this tableau, we perform the intersection between each element of the text sensor, with each element of the profile sensor.","in this tableau, we perform intersection between each component of a text sensor and each component of the profile sensor."
884,how does the packet size affect the throughput performance of comparison protocols?,how does the packet size impact the throughput performance of the fad-like protocols?
885,this can be thought of as yet another example of an anomaly stealing the result.,this can thus be seen as another example of anomaly stealing a result.
886,"this could depend on the distance between the two sites, but also the nature of the terrain between them, the presence or absence of waterways and so on.","this could depend on the distance between two points, but it may also depend on the tectonic differences of the terrain between them, the presence or absence of waterways etc."
887,"all of the randomness is in the state transitions, because they uniquely define the output spike train.","all the randomness arises in the state transitions, because they uniquely characterize the output spike train."
888,"indeed, the interpreter can access the program text anyway, so it can copy the text into some string variable.","in fact, the interpreter has access to program contents anyway, so if it wants to copy the text into some line variable it does so by replacing the string."
889,"even if cath does not learn any cards, how do we minimize the probability that she guesses them correctly? to summarize, there is much to be done indeed!","the second question is: even if cath learns no cards, how can we minimize the probability of correct guessing of the cards? in summary, there is indeed much to learn!"
890,this method measures the frequency of a term but also corrects this with the importance of the token.,these methods measure word frequency but adjust for token importance.
891,"whatever the number of bits allocated to the new epoch is, this rate pair will have a slope equal to the ratio of the number of bits remaining for this epoch.","this ratesio pair will have a slope that is proportional to the ratio of the number of bits remaining at this epoch, regardless of the number of bits allocated to the new epoch."
892,"on the other hand, switching to the polynomial framework changes the setup.",by contrast switching the cc framework to the polynomial one changes the setup.
893,"the interpretation of the state of the students can then either be performed by the students themselves, by a human coach or by an automated agent that can deliver recommendations to the students.","for example, the interpretation of a state by a student can be done by the student himself, by a human coach, or by a robot that makes recommendations to the student."
894,"minor though this replacement may seem, however, it has a big effect, as we will shortly see.","although the effect of this replacement is trivial, as we shall shortly see, it is significant."
895,gives an early warning to a user if the credentials are about to expire.,gives a warning to the user before his account is about to expire.
896,"as one of the most complex human constructions, the internet is a challenging system to model.","the internet is a challenging system to model, as one of the most sophisticated human constructions."
897,"each job in the fjs problem consists of a sequence of operations to be processed in a given order, just as in the ordinary js problem.","in the fjs problem, as in the conventional js problem, each task is a sequence of operations to be executed in a certain order."
898,it is becoming commonplace in many applications for the number of units to become very large.,it is becoming standard for many applications for the number of nodes to be extremely large.
899,"considering code inspections, faults are found and removed that have never caused a failure during testing.","faults that have never caused a failure during inspection in code are found and removed, with the goal of eliminating faults in the testing process."
900,"for example, there would be people talking, phones ringing, people coming and going, people working on keyboards, taking refreshment, doing photocopying, and so on.","such scenarios might involve people talking, ringing phones, people coming and going, people working at keyboards, people taking a refresh, doing photocopying, and so on."
901,there is potential in that principle for autonomous robots to achieve the kind of seamless integration of diverse kinds of knowledge and diverse kinds of processing that is a hallmark of human intelligence.,this principle could lend itself to the kind of seamless integration between diverse kinds of knowledge and diverse kinds of processing that is characteristic of human intelligence.
902,signboards are salient markers that act as representatives for certain situations or objects.,signboards are landmarks that may act as marks of interest for particular situations or objects.
903,"the first metric is success ratio, which is the percentage of greedy paths that successfully reach their destinations.","the first metric is the success ratio, which is the fraction of the greedy paths which are successful in reaching their destination."
904,"classification problem, where a statement is categorized as news or not.",classification problem where a statement can either be categorized as news or un-news.
905,it moves a step back and locates the node whose parent-link was desired to be flagged.,one moves one step back to locate the node whose parent-link was selected to be flagged.
906,it is worth looking at the source and target tdags in the opposite direction.,it is worth looking in a different direction than the source and the target tdags.
907,in this section we provide an analysis of the capabilities and current limitations of profile.,"in this section, we provide our analysis of profile capacity and current constraints."
908,recruits are incorporated adaptively into the target network as it learns connection parameters from the target to the recruit and from the recruit to the target.,recruits are adaptively invariant on the target network because it learns link parameters from the target to the recruit and from the recruit to the target.
909,"however, the notion is precisely what programmers mean with the word.","however, these notions are precisely what programmers wish to do."
910,spreading multiple messages in parallel is significantly more complicated because nodes need to select which information to forward.,"as nodes must choose which bits to forward, the spread of multiple messages become much more challenging."
911,"if we construct a sample from individuals all taken from different sites, we would expect their properties to be exactly the same as in an unstructured population.","if we were to construct a sample from individuals, each of which is collected from a different location, we might expect that its property would exactly match that of the unstructured population."
912,the population is initially empty and covering is applied to generate rules as in the standard xcsf approach.,in the standard xcsf approach the population is initially empty and covers are applied to generate rules.
913,the format of the competition and the strength matrix are common knowledge to both teams.,both teams have common knowledge of the format of the match and the strength matrix of the competition.
914,"s first law of diffusion, diffusion flux goes from the region of high concentration to the region of low concentration.","the first law of diffusion is a sfd law, where the diffusion flux from a region with high concentration moves to a region with low concentration."
915,"spectral methods is one of the most widely used techniques for exploratory data analysis, with applications ranging from data clustering, image segmentation to community detection etc.","spectral techniques are one of the most commonly used techniques for exploratory data analysis, their applications range from data clustering, image segmentation to community detection, etc."
916,how long are these conversations and how do they end? when do people respond to a message in a conversation?,what is the average conversation length and what is its conclusion? when can people respond to each other s messages in an online conversation?
917,"once you start to form a picture of his preferences, you can start playing a crossout-style strategy.",we can start an out-and-out strategy after forming a picture of the preferences.
918,dark red (blue) is parameter space where both s and w are active (inactive).,the parameter space in which s and w are active (inactive) is dark red (blue).
919,start with all nodes being facilities and remove them one by one in a greedy fashion.,we start by treating each node as a facility and removing it one by one in a greedy fashion.
920,the bayesian net for that is built using the tool agenarisk.,the tools used in agenarisk to generate the bayesian net are used to construct this bayesian net.
921,"this means in order for us to recommend hydralazine and isosorbide dinitrate to the patient, they must have received standard neurohormonal antagonist therapy before.","this implies that for a patient to receive the standard neurohormonal antagonist treatment prior to this test, she needs to have received at least one of the following hydralazine and isosorbide dinitrate before we can recommend it to her."
922,the purpose of this section is to discuss the relationship between the two quantities.,the aim of this section is to discuss a relation between these quantities.
923,"the feed for an article includes a title, a short summary of the article, its url, and a time-stamp.","an article s feed contains a feed with a title, a succinct summary of the article s contents, the article s url, and a time-stamp."
924,"persons and organizations are tied to each other in several ways, detailing what positions people held in which organizations, where they were educated and of which organizations they are members.","individuals and organizations are connected to each other in several ways, describing what position someone held in which organizations, where she studied and of which organizations she was a member."
925,molecular modeling and simulation is a technology central to many areas of research in academia and industry.,"in many areas of research in academia and industry, molecular modeling and simulation is a key technology."
926,"movies are a common domain in recommender systems research and an important cultural item that people often share and discuss, making them a natural domain for studying sharing.","movies are both a natural research domain for recommender systems, and are highly shared and discussed in many cultural contexts, making them a natural domain for studying sharing."
927,the decoder is allowed to read the counter and reset it.,decoders can read the counter and then reset it.
928,so the non-data traffic for each node will only be relative to the node density in the network.,"in other words, the non-data traffic of each node has a strength that only matches the density of nodes in the network."
929,"entropy is one of the most ubiquitous concepts in science, with applications in a large number of research fields.","the entropy of a boundary is one of the most ubiquitous concepts in science, with applications across many domains of research."
930,"for example, users reported opening multiple tabs in a browser to keep state, or adding items to a shopping cart just to ensure they will be able to remember them.","this can be from users opening multiple tabs in the browser to maintain their state, or adding items to a shopping cart just to guarantee that they will be able to store them later."
931,"we could consider that the time that is relevant for a subject is the time elapsed since her birth, that is, age.","we might believe that the time that is interesting to a subject is the time of birth, that is the age of its record."
932,"but the minutiae of features offered by such software are fairly unimportant, given that these features are all easy to add.","the minutiae of features offered by such software, however, are relatively less important as they are all easily add-in friendly."
933,note that the color bar on the right is on logarithmic scale.,note the color bar in the right-hand side is in logarithmic scale.
934,"for example, in a graph database representing moving object trajectories there may be be different configurations of the edges where each node represents a region in the space.","one might consider different configurations of edges of the dataset representing moving object trajectories, where each node represents an area in a space."
935,as mentioned earlier the captain takes the bulk of the decision in forming the batting line-up.,"as noted earlier, the captain has most influence on the team selection for batting the game."
936,"since the channel has markov structure, if we go back more that one epoch, we do not get useful information.","since the channel has a markov structure, there is little useful information to be acquired when we go back more than an epoch."
937,"sensor networks increase in size, it is important to keep costs to a minimum.","cost control is important, because sensor networks grow in size."
938,it represents one of the most popular forms of horse races where each team ranks its horses to match sequentially.,the sequential ranking of horses is one of the most popular horse racing forms and each team should rank its horses sequentially.
939,"unfortunately, model mis-match is difficult to quantify, since it is systematic, yet unpredictable.","unfortunately, model mis-match is challenging to quantify since the behavior of model mis-match is systematic yet unpredictable."
940,"if the colours of the input registers uniquely determine colours for the output registers, then the colours of the output registers are the result of the computation","when the colours of input registers uniquely determine the colours of the output registers, then the colourings of the output registers are the result of the computation"
941,the web has become pervasive and digital technology permeates every aspect of daily life.,"as the internet has become omnipresent and digital technology permeates every aspect of our day-to-day life, the cost of protecting privacy has become significant."
942,"this mechanism, only used in the learning phase, helps the cells to learn patterns with different real sizes.",this mechanism is strictly used in the learning phase and it allows the cells to learn pattern classes with different real sizes.
943,"typically, they have two kinds of combination mechanisms: decision-level combination and intermediate-level combination.",two types of combinations mechanism are often considered: a decision combination mechanism and an intermediate combination mechanism.
944,the information the agents know is further limited because parts of the box are blinded.,"more importantly, the agents are further limited in the amount of information they know because some of the containers are blinded."
945,news feeds provided by feedzilla are pre-tagged with category labels describing the content.,category labels describe the content of a news feed provided by feedzilla.
946,"in this section, some definitions and lemmas on graph theory and matrix theory are given as the preliminaries.",we start by providing some definitions and lemmas of graph and matrix theoretic problems.
947,"in caching, three decisions are prominent as: what to cache, where to cache, and how to cache?","three decisions are often made in caching: how to cache, where to cache and where to cache?"
948,the system may then be run again and the alignments that are created may suggest a final diagnosis or the need for further investigation and so on.,"the system could then be run again and the alignments that would be created may eventually suggest a final diagnosis, a path for further investigation, etc."
949,calculating this reduction requires to know the probability of each possible system configuration that is compatible with the given system constraints-a challenging problem both methodologically and computationally.,"computation of this ratio requires knowing the probability of any possible system configuration, able to meet given system constraints; it is a challenging problem from a methodological and a computational perspective."
950,"if accepted, the candidate model is trained, tested, and the evaluated results are added to the training set of the (which is then retrained).","if the candidate model is accepted, it is trained and tested and the test set is then added to the training set (which is retrained later on)."
951,"however, those works are mainly conducted from the viewpoints of set theory and operator theory.","however, most of these works have been conducted from the viewpoints of set theory and operator theory."
952,"an inconsistent database may be the only source of data, and we may still want or need to use it.","a single source of data might be the inconsistent database, and it may still be useful or necessary for us."
953,"for the authors, the most influential users are those with a greater positive variation.",authors found that users with a larger positive variance are more influential.
954,"furthermore, we can see categories (such as health) with low number of published links but higher rates of tweet per link.","furthermore, there are some classes such as health which have low number of published links, yet high tweet per link rates."
955,"however, in the course of analysis we often end up with sparser data and thus better compression ratios.","however, we often end up with sparser data and thus better compression ratios in our results during our analysis."
956,"to do so, we created a corpus of example mentions labels with number and gender, respectively.","to do so, we built a corpus of example mention labels labelled by number and gender, respectively."
957,there are often standard ways to obtain representations of higher-type objects such as sets and functions.,representations for higher-type objects such as sets or functions are often obtained in standard way.
958,"solution even with limited processing resources, and to refine the solution as more resources become available.","solutions for the case with sparse processing resources, and as the amount of processing resources increase, to refine the solutions."
959,"convergence means that many media products move between media, a show such as the simpsons or lost is originated as a tv show and migrated to other media (film, game, online).","convergence means that many forms of media, like simpsons or lost, start as tv programs and migrate to other forms of media (movies, games, online)."
960,the former is finding groups of customers having similar purchasing patterns and then establishing marketing strategies according to the patterns.,the former measures trends by finding groups of customers with similar purchasing patterns and then designs marketing strategies based on those patterns.
961,its interface is written in processing and can run on several platforms.,the interface is written in processing and can run on multiple platforms.
962,the language designer wants to include new language features incrementally as the programming language evolves.,an improvement the language designer aims to provide is the ability to include language features incrementally as the programming language evolves.
963,"reasoning on overlapping digits even eludes deep neural networks trained in a supervised manner, but here we did not use the information about which two digits are present in each of the training images.",we note that deep neural networks trained in a supervised manner even have difficulty reasoning about overlapping digits but we do nt use this information here to learn the location of each digit in our training image.
964,second module extracts mid level convolutional neural network features for each proposed region which has been trained earlier on imagenet dataset.,"the second component, after training the local regions for each of the proposed regions from the imagenet dataset, extracts mid-level convolutional neural network features that are the target of the features clustering."
965,a program with nested expressions is a set of rules with nested expressions.,a program for nested expressions is a set of rules for nested expressions.
966,the edge or shape information is very helpful for accurate object localization or resisting background distraction.,"for example, accurate object localization or resisting background noise can benefit significantly from having edge or shape information."
967,"a more reasonable approach here could be giving different probabilities for each sense of a word, and use them to weight synsets in the vectorial representation of documents and queries.","one possible approach here is to assign different probability values to different word senses, and use these weights in synset weighting in vectorial representations of documents and queries."
968,"this mechanism forces the target network to transfer learned knowledge, rather than simply overwrite it.","this mechanism requires the learned knowledge to pass from the source network onto the target network, rather than merely overwriting it."
969,"for example, people using the repository to look for historical litature form one group with specific usage characteristics.","example, a different group of users, with specific usage characteristics, are those who visit the repository for historical littoral insights."
970,"this activity will be archived in a warehouse or other storage mechanism, but the size of the data is too large for data analysts to keep in memory.","this activity is stored in a data warehouse or other type of storage mechanism, but the dataset size is too large to be kept in memory by data analysts."
971,the matrix network might be a good model for an urban city with squared blocks.,this suggests that a grid-like city with squared blocks is a promising model to represent the matrix network.
972,"however, there exists a potential risk to civil safety if the helicopters crash especially in an urban area.","however, crashes of helicopters, especially in urban areas, may pose a potentially serious threat to public safety."
973,it has attracted much attention in the last few years and many solutions are currently available.,"is a problem that has received a lot of attention the last few years, and currently many solutions are available."
974,a transaction is defined as a set of products purchased by a customer at a time.,a transaction is defined as a set of items purchased by a client at a time.
975,here is a simple way to handle interaction with the environment which suffices for this paper.,the paper here presents a simple solution that copes well with environment interactions.
976,the construction stage consists of executing the next steps within a given number of iterations.,the construction stage is the execution of the next step within a given number of iterations.
977,"when building the network, the construction cost must be under a specified budget.","when constructing the network, there is a target construction cost below a certain budget."
978,note the connection between random networks and arbitrary networks that an instance of a random network forms an arbitrary network.,note that the instances of a random network together form an arbitrary network by tangling them.
979,"described in this way, the scenario feels somewhat creepy, and one is tempted to immediately categorize it as a clear violation of privacy.",the entanglement of the scenario described in this manner is rather creepy and one is tempted to immediately categorize it as a clear violation of privacy.
980,"we will briefly sketch how our neural networks could be deployed at scale, in the wild.","we briefly sketch how our neural nets could be deployed on a large scale, wild-life setting."
981,the latter typically works better if specific knowledge of the problem is available.,"if specific knowledge of the problem is available, the latter tends to perform better."
982,"growth in concentration, or increased density, defines regions in where the trajectories accumulate.","regions in which trajectories accumulate are defined by the growth of concentration, or the increased density of the regions."
983,"we extract each of those fields, parse the corresponding dates, and pick the lowest of which.","now, we extract all these fields and parse the corresponding dates and pick the smallest one among them."
984,"people often perform group by operations over categorical attributes, and this step helps them perform such analysis.","the grouping operation over categorical attributes is often performed by human decision makers, and this step helps their analysis."
985,"for example, by establishing the boundary of a forest fire, a sensor network can help fire fighters determine where to concentrate their efforts.","a sensor network may help fire fighters identify which positions to concentrate their efforts, for example, by establishing the boundary for a forest fire."
986,but equivalence relation or partition is still restrictive for many applications.,"however, in many applications the equivalence relation or partition is still restrictive."
987,"at last, we define the spatial capacity as our performance metric.","finally, we define the spatial capacity as our performance metric."
988,they aim to capture both posture and motion information for gesture recognition.,their goal is to capture both posture and motion information for gesture recognition.
989,"decades later, backprop is the workhorse underlying most deep learning algorithms, and a major component of the state-of-the-art in supervised learning.",backprop has become the workhorse underlying most deep learning algorithms and a major component of the state of the art in supervised learning decades later.
990,the autocorrelation time depends on program parameters but also on the measured observable.,the autocorrelation time depends not only on the program parameters but also the measured observability.
991,"the four tapes are called the input, working, history and output tape.","the four tapes are called the input tape, working tape, history tape, and output tape."
992,it can in particular be used for treating the model as an expert system.,can be implemented primarily as an expert-system model.
993,we can determine the angles of the directions of maximal magnification and shrinking and the amount of them as well.,"we can then calculate the angles of maximizing magnification and shrinking directions, and also their number of directions."
994,"any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the national science foundation.","any opinions, findings, or conclusions or recommendations expressed in this material are those of the author(s) and don't necessarily reflect those of the national science foundation."
995,"when the request message costs too many bits to feed back from the receiver, the throughput will decrease.",the throughput decreases when there are too many bits to be returned by the receiver as a result of the request message.
996,machine learning methodology usually consists in several pre-processing steps aiming at cleaning data and preparing them for being fed to a battery of algorithms.,machine learning methodologies usually include several preparatory steps with the goal of cleaning data and preparing the data to feed a battery of lsn algorithms.
997,what about maximizing the overall service usage for a target group of users?,what is the optimal utility of a target group of users?
998,the presented technique can also be used to embed the reduce system in form.,we can also use the presented technique to embed the reduce system in a declarative form.
999,"however, it is natural to try to leverage the work on clustering for the functionality that the paper targets.","however, if this are the functionality that the paper aims to fulfill, it is natural to try to leverage the work on clustering."
1000,"to the commonly used activation functions relu and swish, which will later be used as a benchmark for their experiments.","they were introduced to the commonly used activation functions relu and swish, which will be later used as their benchmark."
1001,"early works in machine translation focused on solving it with statistical methods where translations are generated with statistical models, depending on parameters derived from analysis of the text.",early works on machine translation focused on solving translation problems with statistical methods in which translations are generated using statistical models based on parameterizations extracted from the analysis of the text.
1002,one would need to add as a attribute each server and sender as a boolean expression which would lead to a combinatorial explosion.,it would require one to treat each server and sender as boolean expressions and to use boolean sequences for them all to be associated.
1003,an increase in the randomchance threshold equals an increase in the bots willingness to take on an attack despite knowing that the chance of winning the according battle is low compared to the win-chance threshold.,"a randomchance increment equals an increase in the bots willingness to take part in a conflict, despite the fact that the probability of winning the corresponding war is small compared to win-chance increment."
1004,"notably, the time steps needed per episode tend to much lower variance for the largest alpha considered, while the amount of time steps is the smallest in the considered range.","notably, the frequency of the per-event time step varies significantly from the maximal alpha considered here, while the smallest lag time step is typically found in the smallest range of considered alphas."
1005,"but, logistic regression model was chosen as it provided a few surprising insights that could be of interest to the experts.","the logistic regression model, however, has been chosen as it yielded some surprising insights that may be of interest to experts."
1006,"besides the visualization of the value function, we have created several learning curve graphs by collecting metrics for every episode trained.","in addition to visualization of the value function, we collected metrics for each training episode on a variety of learning curve graphs."
1007,this approach of splitting an image into meaningful subparts to colorize each of these parts individually was already suggested before.,"such a strategy for partitioning an image into meaningful subgraphs to color each of these partitions separately, was already proposed before."
1008,part of the reason for this drop in performance could be the use of unoptimized hyper-parameters as the default values were used to represent a baseline for the td-algorithm.,the downsizing of the performance of the td-algorithm could also be a result of the use of unoptimized hyper-parameters whose values were meant as the baselines for the td-algorithm.
1009,moreover we needed to visualize the value function which can be easily done for the above algorithms.,"furthermore, we have to visualize the value function which can easily be performed with the above algorithms."
1010,"however, a problem arises once the distance is added to the equation.","however, once the distance is added to the equations, a difficulty arises."
1011,this data sample consists of instances that are randomly taken from the original dataset.,this sampled dataset consists of instances randomly sampled from the original dataset.
1012,larger learning rates caused divergence in several cases and smaller learning rates were too costly in terms of iterations needed to reach the same accuracy w.r.t.,"in fact, in several cases the larger learning rate caused divergence, while the smaller learning rate made it too costly due to the number of iterations needed to reach the same accuracy."
1013,"with higher support threshold, the algorithm has to go through way less potentially frequent higher number item sets again.",this is a way to ensure that the algorithm is only traversing higher potential instance sets again with a higher threshold support.
1014,the song recommendation to the user is made out of these emotions and the interactions.,these emotions are then used to recommend the song to the user.
1015,and to discuss contexts where the method might be relevant for getting the accuracy gain and where not.,we also discuss contexts where and where the method might be useful for obtaining accurate resolution gain and when it is not.
1016,"evaluation: the larger the channel sizes (within the range of sizes under investigation), the lower the mse becomes.","evaluation: the bigger the channel size (over the range of channel sizes to be investigated), the lower the mse becomes."
1017,"in summary, we used imdb review data to train a logistic regression based sentiment analysis model which is applied to twitter data to retrieve the sentiment of early reactions on movies.",we summarize how sentiment sentiment of movie reviews has been learned for imdb reviews data training a logistic regression based sentiment analysis model which will then be applied to twitter data to learn sentiment profiles for movies.
1018,the performance was also monitored using comparison between original pictures and reconstructed ones based on the original luminance channels y and the predicted channels cb and cr.,it was also studied how predictions of channels cb and cr are predicted based on the original images and on reconstructions based on original channels y.
1019,"in this work, these methods of measurement are altered to fit their application to trees.",these methods of measurement will be modified in this work to fit the generalization to trees.
1020,the decision trees built in this study use gini index as the cost function.,the decision trees that are constructed in this study use the cost function gini index.
1021,"most values are not only stored as an average, but median, min, max, variance, skewness and kurtosis are generated as well, if applicable.","in particular, we save not only the average, but also the median, min, max, variance, skewness, and kurtosis, if applicable."
1022,"in order to verify that the knowledge graph meets a prescribed structure, we decided to use shex (structural schema language for rdf graphs).","so, we decided to use shex (a structure-aware schema language for rdf graphs) to verify that a knowledge graph has the prescribed type structure."
1023,"to link the two data sources, we also asked the testers to provide their anonymous user id in the evaluation form.",we also asked the participants in the evaluation form to input their anonymous user ids in order to bind the two data sources.
1024,the resulting trees are easy to intrepret and explain the relationship between predictors and the outcome feature in the form of rules.,these resultant trees are simple to interpret and provide a relationship between a predictor and a outcome feature by means of a rule.
1025,"the volumetric volume to be shipped, using arc a in week w and on weekday d is now dependent on all requests that could be shipped in week w and on weekday d. this volume can be required by the requests arriving at the lsp on that particular day, but also all requests whose shipment can be delayed to that day.","this quantity depends, using arca s on weekday ws and on weekday ds, on all requests that may be shipped on a given day, and also on all requests that can be delayed until that day."
1026,the task of text style transfer is part text understanding and text generation.,a text-style transfer task combines text understanding and generation in the following way.
1027,"one economic sector, which enables trade and mobility of humans, is the transportation sector.",the transportation sector is one of the economic sectors that enable human movement and trade.
1028,therefore we plan to capture the mood of each user manually by handing him a questionnaire before he starts the test round.,"therefore, we plan to manually capture the mood of each user by giving it a questionnaire at the beginning of the tagging round."
1029,"physical activity, obesity and mortality: does pattern of physical activity have stronger epidemiological associations?","fitness, obesity and mortality: is the patterns of physical activity associated with a stronger epidemiological association?"
1030,"in this case, the missing values will be estimated by using the other variables.","where missing values are not known, the other variables are used as a guess."
1031,multiple approaches were implemented in order to create a bot that can play the game of risk.,attempts to create a bot that plays a given game have been pursued using several approaches.
1032,"and we can see a good result that if we use more samples, the length is lower, that is to say, we can get more accurate result.","we may see that by utilizing more samples, the length of the approximation gets shorter - that is, we can obtain more accurate approximations."
1033,"this includes a discussion of initialization, learning rate and number of iterations performed.","we also discuss our initialization, learning rate, and number of iterations needed to complete the task."
1034,"finally, for the predicates averagecostfortwo, offersonlinedelivery, isdeliveringnow and switchtoordermenu we created our own predicates in ken:ontology to allow for a higher expressiveness, again by using label, comment, domain and range.","we also created a predicate on ken:ontology and modeled it by the user, using label, comment, domain and range, for the predicates averagecostfortwo, offersonlinedelivery, isdeliveringnow and switchtoordermenu."
1035,then it estimates the latent variable z of the n datapoints for all d distributions.,"next, each d distribution is iterated to estimate the latent variable z of the n datapoints"
1036,"when looking for the reinforcement learning algorithm that fits to our problem best, we went through the process of trying to fit many different algorithms to our needs.",we tried to fit many different reinforcement learning algorithms to our problem by looking for one that best fits.
1037,"for each of the best performing algorithms, we will also attempt to interpret the results and identify the reasons for its relatively high accuracy.",we also aim at interpreting the results and identifying reasons for this high accuracy for each of the optimal algorithms.
1038,"to take the shortest of these routes to save resources, for example, gasoline.","for instance, for saving gasoline, one takes the shortest of the two routes."
1039,"in addition this graph shows a certain overlap in both clusters, which indicates a certain similarity.",it can be observed from the graphic that there is a certain degree of overlap between both clusters which indicates that both clusters are similar.
1040,the ranked list can be utilized to determine the physical activities that play an important role in predicting a certain health status.,this ranking is also useful for identifying the physical activities that play a significant role in predicting a given health state.
1041,"it was noticeable, that the validation error curve oscillated way more in this scenario.","we can observe, that in the latter case the curves of validation errors oscillated significantly more."
1042,"as said before, standard q-learning uses experience it obtains only once.","as already said, standard q-learning takes advantage of the experience it gains only once."
1043,these additional details give insights into both aspects: the feature importance and the boundary value at which the classes are separated.,these additions provide insight into two aspects: feature importance and the boundaries separating classes.
1044,more game-theoretical research was done to find out new strategies.,the finding of new strategies has also received more game-theoretic research.
1045,"before starting the iterations, we add the bias nodes to the input layer.",we first attach bias nodes in the input layer before starting the iterations.
1046,"the benchmark models used in experiments could be introduced in this context, too.",we could introduce some parallelism as well to the benchmark models used in experiments.
1047,the focus of the approach used in this research to generate new problem instances is to generate similar data to the data set at hand.,our approach here is rooted in the notion of building a model that generates new problem instances generating such an annotation set that is close to the data being considered.
1048,we looked at the biases but there was no straightforward pattern observable.,"we are aware of the biases, but we found no straightforward pattern-like observability."
1049,"confusion matrix a confusion matrix provides a description of the model performance in the form of a matrix with true and false positive, and true and false negative values.","confusion matrix reveals the performance of the models in terms of true or false positive and true or false negative values, respectively."
1050,"however, this higher resolution enhanced crop, once fed to the cnn, gets reshaped to match the cnns input format, hence canceling the effect of the enhancement of the resolution of the crop.","however, as shown in the figure, when the tagging data is fed to the cnn, the improved crop is reformulated to match the input format in the cnn, therefore cancelling out the resulting crop resolution enhancement."
1051,the research questions have been covered throughout the entirety of the report and with help of our testers.,"thanks to our testers, the research questions were answered throughout the paper and brought to light."
1052,"using a discrete model this emotional analysis can distinguish between fear, anger, sadness, disgust, joy and surprise.","this model uses a discrete model to classify emotions as fear, anger, sadness, disgust, joy, and surprise."
1053,to calculate the size of the latent space representation of our data we need to use a formula given in the assignment.,we will use the formula in the assignment to calculate the size of the latent space representation of our data.
1054,it indicates that the simple models are unable to capture the complex decision boundary between the classes.,this indicates that the simple models can not capture the complex decision boundary between the classes.
1055,"the innovation with respect to already existing recommendation systems is pursued here, by relying on the emotional reaction of the user received by his facial expressions, taking into account the emotions they show throughout the entirety of the song.","here, our approach advances the current knowledge of recommendation systems by taking into account the emotional reactions of users based on their facial expressions and the ones they display throughout the song."
1056,"and lastly, we stated the limitations of our research and indicated possible future areas for improving it.","finally, we have discussed limitations of our work and outlined possible future directions for improvements."
1057,"all tasks should be divided equally, and regular comparison between planning and the state of the work at hand should be performed, so that adjustments can be made.","should be spread evenly over all the tasks, and periodically compare the planning with the state of the actual job so that we have room for adaptation."
1058,"we got that the wolf of wall street is expected to be a big hit, the unbelievables is supposed to be quite profitable, and the movie annie will probably not bring much profit.","we see that wall street wolf is expected to be a big success, unbelievables is expected to earn several thousands of dollars, and annie s movie should probably bring relatively little revenue."
1059,the easiest way to do so is with the command pip install-r requirements.,this can be done easily by using the requirement list of pip command.
1060,"although the idea of dividing the image to colorize particular objects is not new, the proposed method leads to better performance.","although image partitioning is not new, the proposed method gives better performance in coloring smaller regions of the image."
1061,"complex model while the accuracy of the complex models was rather low, some insights could be gathered from the visualizations.","though the accuracy of complex models proved rather low, visualizations exhibited a variety of insights."
1062,a second property of gradient ascent to be determined is its stopping criteria.,we also describe the stopping criteria for the gradient ascent as mentioned earlier.
1063,"in the trivial approach, the car starts to the left and when not able to continue anymore it changes direction full throttle and so on and so on.","for the non-trivial approach, the cars start on the left, and change direction full throttle until no longer able to do so."
1064,"the production of the dataset happened a collaboration between numerous companies, and because of this, to our knowledge, the dataset exceeds all other freely available datasets in its number of features, while still having one of the biggest song libraries.","we acknowledge the generous cooperation between several companies on the production of this dataset, and are told that it far exceeds any other free publicly available dataset in number of features while still being one of the largest song libraries."
1065,the ui is built using javafx and css.,the ui is created using javafx and css.
1066,"to interpret this plot, features are listed in descending order indicating their importance from high to low.",these plots are interpreted with features being listed from high to low importance in descending order of their importance.
1067,these techniques will be trained on imdb review data in order to predict the sentiment of tweets.,these techniques are trained on imdb review datasets to predict sentiment analysis of tweets.
1068,for creating activation functions in an evolutionary approach they utilize mutation and crossover.,mutation and crossover are utilized in the evolutionary approach for designing activation functions.
1069,knn on the other hand is a very fast method that does not require a long learning process.,knn on the other hand is a very fast method with no lengthy learning time overhead.
1070,the decision rule is designed to determine on a day-to-day basis how to handle the incoming shipment requests.,"the decision rule is an entity of the class of rules that determines, day-to-day, how to deal with incoming order."
1071,"the use of larger context window helps to make more accurate predictions, as well.",it also helps in generating more accurate predictions when the context window is large.
1072,"as a conclusion, we can determine that the dynamic emotion of the users can indeed be utilized to make suitable recommendations for the users, adapting and supporting their current state of mind or even changing it.","finally we can determine that dynamic emotions of users could indeed be used to model recommendations in a suitable manner for users, to support or adapt their current state of mind, and perhaps even change their future intentions."
1073,"for each trained music object, a music object vertex is created.",we create a music object vertex per trained music object.
1074,for the following experiments the initial points of the gradient ascent procedures (c.f.,the initial positions of the gradient ascent procedures are used in the following experiments (cf.
1075,"intuitively, only the mj hypothesis seems to be somewhat promising, as the others do not even consider whether the tweet is giving a positive or negative opinion about x.","intuitively, only the mj hypothesis seems to be relatively promising as the others don't consider whether the tweet contains a positive or negative impression for x."
1076,the goal of useful data generation and manipulation in the latent space.,we aim to develop data generating and manipulation techniques that work in the latent space.
1077,"from this state the next actions we would take and the next states we can reach by those actions have the lowest qvalues, which is logical because from this state (from the valley with low speed) it is really hard to get out and have a remarkable progress towards the end state.",the reason is that it is really hard to get out of this state (from a valley with low speed) and have remarkable progress toward the end state using the actions of those actions to reach that state.
1078,"on their website they write: ""a kernel density estimate (kde)",their approach is called kernel density estimation (kde) according to its website.
1079,the win-chance threshold is used to determine whether the bot should start an attack against an adjacent country.,the threshold of win-chance is used to determine whether the bot should start an attack on an adjoining country.
1080,the following section gives an overview about the current state of research in the related domain and projects considered aiming a similar result.,the following section presents the state of research on related domain and projects that look at making similar results.
1081,the output of the notebook is included in the submission so it is not necessarily required to run it your self.,notebook output is included in the submission and so no run-time has to be md.
1082,"after implementing the policy and the value function, we were able to experiment with the parameters, and pick those that get the car to the hill in the lowest number of steps after enough games played.","once the policy and the value function had been implemented we were able to experiment with the parameters, selecting the one resulting in the smallest number of hops for the car; after a sufficient number of games were played."
1083,then the recommendation system would output the id of song with the highest rating for user.,"then, the recommendation system outputs the song i d of the song that was the best rating by user."
1084,"for example, stress levels can be determined with the help of medical sensors to evaluate heart rate and blood pressure.","for instance, clinical sensors are equipped with heart rates and blood pressure to assess stress levels."
1085,this could be explained by the bot starting a lot of risky attacks early and conquering additional territories which he is then not able to protect later on.,this observation may imply that the bot starts lots of risky attacks early and conquers new territory in a manner that it is then unable to defend later.
1086,"this is done to keep the bot from placing all its troops into a single country, as this could provoke unwanted behaviour such as the bot focusing on keeping one of its owned countries alive.",this avoids the bot from focusing its whole power on a single country because this could lead to unwanted behavior like the bot focusing on staying alive in one of its own countries.
1087,the parameters we can experiment with are lambda (the weight decay) and alpha (the learning rate).,"we experiment with lambda (weight decay), and alpha (learning time)."
1088,the probability distribution used for the sampling process is determined by the volume distribution over the weekdays of the source data set.,the volume distribution over the weekdays in the source data set is determined by the probability distribution used during the sampling process.
1089,choosing rr representation as pointed out in the previous discussion there can be relationships between tweets such that one might even consider rr representation for this task.,we note that it can exist relations between tweets in a manner that one may even consider choosing the rr representation in the following discussion.
1090,"the answers given from the users gave us good ideas for implementation, which will be covered later in the section corresponding to the futures lines of research.","we asked the users to contribute some good ideas for implementation, which will be discussed later in the section covering the future research directions."
1091,"the authors do not include the testing of most of the hyperparameters in the paper, however they refer to the code for that, and considering the amount of tunable hyperparameters for a system of this size, the exclusion is reasonable.","the authors omit tests for most of the hyperparameters in their papers, but reference code where applicable, and the exclusion seems reasonable considering the number of tunable hyperparameters needed in a system of this scale."
1092,"in addition, a better and more theoretical based convergence condition could be used to minimize as much as possible the error stemming from the optimization algorithms.","therefore, the objective function could be used to minimize the error induced by the optimization algorithms, in a better, more theoretical way."
1093,"without padding, we would not have been able to get back the original size of our image matrices, which is why we ended up using padding.","we realized that without it, we would not be able to get back our original scaling algorithms for our image matrices, which is why we ended up using padding."
1094,"after measuring the importance of all the variables, random forest will return a ranked list of the variable importance.","when all the variable weights are measured, random forest returns an order list of the variable importance points."
1095,"starting from the second row of the input layer-hidden layer weight matrix (the first row is for the biases), the magnitudes of the weights follow the same pattern with the binary coding, and the same applies to the hidden layer-output layer weight matrix.","the weight magnitudes of the input layer weight matrix show the same behaviour with the binary embedding, and the same pattern holds for the hidden layer weight matrix (the first row indicates the biases)."
1096,"the method starts by randomly initializing the mean, standard deviation and weights of the mixture model.","this method is based on randomly initializing mean, standard deviation and weights of the mixture model."
1097,this facilitates the learning of a speech in a more natural environment than the other datasets.,this allows the data set of speech data to be more natural than those from other datasets.
1098,"why are the best performing functions not compared with other activation functions from the relevant literature that also outperform relu and swish, like alterations of relu?","what is the logic behind the results of relu and swish, like alterations of relu, not comparing fn with other activation functions from the pertinent literature?"
1099,"are there any bad examples that occurred in the creation of these examples and that show methodical limits to the used method, which might encourage further research?","could it be instructive to explore these assays for bad examples which occur at the time of creating the particular ones, and that show methodic limits on the used method?"
1100,"further, if tweets are interactions (retweets, answers, etc.)","we further define interactions between tweets (retweets, replies, etc."
1101,therefore choosing an alternative metric for success could greatly improve the results of our model.,"hence, our model can greatly improve the performance of such operations when we choose an alternative success metric."
1102,it is integer valued by the same reasoning that applies for ta.,is integer-valued using the same reasoning applied to ta.
1103,"to deal with putting the state outputs of the system into the desired bins, we wrote a function that converts the exact state values of the arrays into their respected bin number.",we have written a function which converts exact state values for arrays into their given bin count matrices when dealing with the problem of pushing the system s output states in the desired bins.
1104,"moreover, research has suggested that there is an association between sitting time and mortality from all causes and cardiovascular diseases, independent of leisure time physical activity.","furthermore, research suggests that, independently of leisure fitness activities, sedentary time is associated with mortality due to all causes and cardiovascular diseases."
1105,"should be shipped directly using the arc from one to three, or using the two arcs from one to two and from two to three.","it should be possible to ship all elements from one to three directly over the arc, or to transport objects from one to two and one to three over the arc."
1106,"even thought the main deliverable of this project was to implement the methods mentioned in the paper, some experimentation with other similar optimization methods was conducted.","although applying the methods introduced in this paper was an important deliverable, we have conducted some experiments with other similar optimization approaches."
1107,further the information over the number of occurrence for each keyword is lost.,"furthermore, the information of the number of occurrences per keyword is lost."
1108,"the output layer weights are hard to interpret since they encode some kind of ruleset, that decodes the input codes from the hidden layer.",input layer weights are hard to interpret because they are encoded by some kind of rule set that decodes the input codes of the hidden layer.
1109,"lastly, accuracies are averaged and can be used to examine model performance.","finally, the accuracies are averaged and can be used to assess the model performance."
1110,this constraint sets a relationship between the trucks going on one route in one week and the volumetric load shipped via one route in one week.,this constraint describes the distance between the number of trucks operating on one route in a week and the volumetric loads shipped on that route in a week.
1111,the authors relationship to the considered stock) and embed stocks in a market segment.,the authors relations between the considered stocks) and embedding stocks in market segments.
1112,require considerable amount of data on the items and user preferences to predict the best match for the user.,is difficult and often requires massive amounts of user information including item details and preferences to predict the optimal match for a user.
1113,"each instance then is one single tweet, but examples might be all the tweets in one time instance.",the event then consists of a single tweet instance but for simplicity examples could also be all tweets of a time instance.
1114,"similar thing happens with the actors and their awards: for one actor multiple awards can be listed, therefore we would need multiple lines which have the same data listed in them, with the only change being the name of the award.","the same may be true for awards, with multiple awards one actor can be awarded, and so we would need multiple lines that have the same information, with the only change affecting the award names."
1115,this means the bot does not make use of knowledge about the game dynamics and rules.,"that is, the bot is not relying on its knowledge of the game dynamics and rules."
1116,"furthermore, we have added a linear decay to this epsilon, to reduce the chance of making random actions linearly until the last episode.","we have further modified this epsilon to linear decay, to reduce the probability of a random action to a maximum of linear time up to its last episode."
1117,class imbalance problem class imbalance is a problem that occurs when there is an unequal distribution of classes in the dataset.,the class imbalance problem: class imbalance is the problem that arises when the classes on the dataset are not uniformly distributed.
1118,"after all the iterations are done, we can plot the learning curve which shows the error in every iteration, so we can see how the learning curve changes as the number of iterations grow.","when all the iterations are finished, we can plot the learning curve by its error, so we see how the learning curve change with the number of iterations."
1119,"however, throughout the entire third phase, we will compile the content for the report in parallel with the tasks mentioned above.","however, in the third phase we compile the report content in parallel with the tasks as described above."
1120,"after all, the challenge presented by a unique state does not change based on the history of moves prior to the state.","afterwards, if a specific state is unique, then a challenge due to the history of moves prior to the state is unchanged."
1121,"with hierarchical clustering, the data points can be partitioned in a tree way known as hierarchical way by using either top down or bottom up approaches.","the results are obtained by the methods of hierarchical clustering, where a data set is partitioned tree-like either via top down or bottom up approaches."
1122,"however, we also look into the possibility of using only the indirect feedbacks in the future by evaluating our metric.","however, when evaluating our metric we also explore how to handle indirect feedbacks alone in the future."
1123,"in addition, with the utilization of a dendrogram, we can reasonably guess the number of clusters.","we also note that we can reasonably guess the number of clusters that may appear, using a dendrogram."
1124,"in addition to the metrics originating from game design theory, several graph features are measured as well.","our metrics are not limited to metrics derived from the game design theory, but instead include several graph metrics."
1125,both measures are based on uni-and ngrams occurring in the compared sentences.,both measures rely on the occurrences of the unigram and the ngram of the sentence under consideration.
1126,a convolution layer and upsampling layer in the back.,are generated from backward convolution and upsampling layers.
1127,overview this health metric is concerned with the low-density lipoprotein of a given patient.,"to summarize, the health metric is a measure of the low density lipoprotein for a given patient."
1128,"the echo nest dataset has all the core, most important metadata and derived features of all the songs, like artist name and id, country, release date, tags scraped from various websites, duration, artist popularity and familiarity, loudness, danceability, energy, mode, tempo and keys to join it to the other databases.","the echo nest dataset consists of the core, most important metadata of each song, including name and country, release date, tags scraped from the various websites, duration and popularity of the artist, smoothness, taint, tone, mode, rate, and keys for a tie to the rest of the dataset."
1129,weighting the given instances by their similarity to the instance that requires explanation.,we weight a given instance by its similarity to the instance for which an explanation is needed.
1130,"the user id is also asked in the form, in order to collect patterns and actions from certain users, which would help to learn some general behaviours from the testers.","the tester also needs a request to enter a uid to gather patterns and actions from a particular user, in order to learn some general behaviors."
1131,"due to the high number of trees in the random forest, manual interpretation of each of the trees is not feasible.","as in the random forest, interpreting each tree manually is not practical due to the large number of trees."
1132,"the hypothesis language for multi-instance includes the normal multi-instance rule, multi tuples and multi joins.","the multi-thresholding language consists of the standard multi-thresholding rule, multi-tuple, and multi join."
1133,"for example, if there are four lanes in the network and there is an allowance for delay of two days, then in the model there are four times three decision variables for each request, where each decision variable corresponds to which lane and with how much delay a request is shipped.","for example, suppose that the network has four lanes and two-day delay allowance, where each decision variable in the model corresponds to a different lane, and with how much delay a particular request arrives."
1134,"to cover this, it would be ideal to ask the user whether they want to improve their mood or rather stay in the same one, which would lead to a more suitable recommendation.","thus, the ideal approach would be to ask users, in order to reduce irritation, whether they would rather like to improve their mood or rather stay in the same mood which would lead to more personalized recommendations."
1135,value attribute is considered the representation that is one level above boolean in complexity.,a representation that is one level above boolean in its complexity is called a value attribute.
1136,the authors clearly indicate and describe the employed experiment procedures and point out where they had to train for loss initialisation due to time constraints which enhances the overall picture of clean and technically sound work.,the authors clearly describe the experimentation procedure applied and point out where loss initializations were needed due to a time constraint adding a clean and technically rigorous picture.
1137,"this is not necessarily the case of multiple maxima so that new additional uncertainty is introduced, which is the subject of interest here.","this does not necessarily result in multiple maxima for this purpose, causing a new additional uncertainty which is critical for our purpose."
1138,the advantage of this approach is that it is quite simple and successful in practice.,the benefit of this approach is that it is quite simple to implement and is practical successful.
1139,"based on these functions, a convolutional network was built to predict the two chrominance channels of a picture cb and cr given the luminance channel y (c.f.",both convolutional networks based on these functions were constructed and trained to predict the dual brightness channels of the picture cb and cr using luminance y spectral channel estimation (cf.
1140,"this schedule is then placed into the decision rule, which can then be used by the lsp to handle incoming shipment requests on a day to day basis.",this schedule is then used to place decision rules to handle incoming shipment requests to the lsp and thus allows the lsp to become operational in the day to day schedule.
1141,"khwaja mohd salik rajiv ratn shah yifang yin roger zimmermann yaman kumar, rohit jain.","rakut pradhan, raj ratn shah yifang."
1142,"one cluster included individuals who are rather active in walking and standing, while the other cluster contained those who were rather sedentary.","one cluster contained individuals who were quite active when they were walking and standing, and the other cluster contained individuals who were relatively passive."
1143,"of course, we use distinct keyword to eliminate duplicated cuisines.","of course, to avoid duplicate cuisines, we use distinct keywords."
1144,"the assumption is reasonable on the small network implied by the data set, as the geographic distances between the terminals can be feasibly travelled by a truck in one day.",the assumption holds for the small network data set since the geographical distances between terminals can be very likely traveled by a truck over a single day.
1145,"for training our music recommendation model, we primarily aim to use the dynamic emotion annotations of the pmemo dataset.",our main approach to train our music recommendation model is largely based on using the dynamic emotion annotations from the pmemo dataset.
1146,stating in the middle the agent moves outward following the line).,"stating in the middle that the agent moves on the edge),"
1147,interpretable hierarchical clustering by constructing an unsupervised decision tree.,interpretable hierarchical clustering by unsupervised decision tree construction.
1148,"that is, unsupervised clustering algorithms identify inherent groupings within the unlabeled data and subsequently assign label to each data value.","this means that unsupervised clustering algorithms identify the inherent clustering in the unlabeled data, and then assign the label to each data value."
1149,"on the downside, we lose some information: the context of the words gets lost by merely counting them, since we do not preserve the order of the words.","though this has some downside, as we don't preserve word order in this manner we lose some information: the meaning of the words is omitted by merely counting them."
1150,makes it much more convenient and easier to have the software tested by external parties.,this makes it much more convenient and easier for external testers to test our software.
1151,when evaluating our model we plan to test it by external testers which will get a series of recommendation while we frequently capture their emotion.,our model will be tested by an external tester who will provide a set of recommendations while we frequently capture emotion.
1152,they do well in explaining the method and activation spaces on a level such that also readers that are not precisely known to the domain (e.g.,they do well in explaining the approach and activation spaces in such a way as to also attract readers not familiar with the exact subfield (such as the swipt process).
1153,an excellent approach for evaluation used in the paper was the user study.,a user-testing approach has proved to be a strong approach in our paper.
1154,"the approach is pretty simple for recommending songs for users on the positive end of the emotional spectrum, we simply try to match their mood with our song recommendation.","the approach is rather simple and is based on recommendations from songs to positive users in the emotional continuum, our aim being to fit moods to our song recommendations."
1155,"state-value function using q-learning, as described above, obtaining the state-value function from the learned q-values can be done straight forward by taking the maximum over all possible states, q(x, a) for all states x. tuning pai.e.","state-value functions via q-learning can be straightforwardly obtained by taking the maximum over all possible states, q(x, a) for all states of a matrix as described above and by using the learned state-value function."
1156,given these reasons we can state that this paper is relevant to an ai audience.,we believe that this paper is of interest to the ai audience for the following reason.
1157,there are states in this space that are impossible for the agent to reach (e.g.,"each of the states in this space is either impossible for the agent to reach, such as z."
1158,"finally, we feed the model with the selected subset of features for the training procedure.","finally, we feed this trained model the selected subset of features to it."
1159,the problem belongs there because in our interpretation the uncle is able to put on almost as many cloth items as he wants (e.g.,our interpretation of the problem has to do with the uncle being able to put as many clothes as possible (cf.
1160,"although, in reality, it is not possible to split items, this assumption is often used in reality.","although item splitting may not be possible in real life, this assumption often holds true."
1161,hence the risk bot is choosing actions in the battle phase that increase the number of countries owned by it while avoiding loosing troops over the course of the game to eventually achieve its goal of winning.,"therefore, in the battle phase the risk bot chooses actions that increase the number of countries owned by it while avoiding killing troops over the course of the game, in order to eventually achieve its goal of winning."
1162,"the explanations cover an overview of the metric, illustrating results from the best models and summarizing the main results.","we explain the metric, illustrate the best model results, and summarize main results."
1163,"machine learning algorithms can either be supervised or unsupervised although some authors also classify other algorithms as reinforcement, because such techniques learn data and identify pattern for the purposes of reacting to an environment.","this is primarily due to the fact that the techniques learn data and identify patterns for an environment to help in the action, although some authors have also classified others as reinforcement techniques."
1164,an agent will make a decision based on a heuristic value of the current state of a game.,an agent will make a decision based on a heuristic value of the current game state.
1165,to create the clusters we had to train the k-means algorithm on a dataset.,we ran the k-means algorithm on a dataset and trained our clustering algorithm on that dataset.
1166,the jupyter notebook is a web-based notebook environment for interactive computing.,"the jupyter notebook is a web-based, interactive computing environment with a graphical user interface."
1167,"as a conclusion, we can conclude that most of the people liked the idea behind the project.",our conclusion is that most of the people liked our design.
1168,"machine learning, statistical learning and the future of biological research in psychiatry.","future psychiatry research is underpinned by machine learning, statistical learning, and evolutionary biology."
1169,"then found the optimum, if the algorithm produces a path which satisfies the time constraint.","the search is then done for the optimum, such that an algorithm produces a path satisfying the time-bound constraints."
1170,we realized that this happened because we used the same iri-s for cuisines in all datasets.,we realized this was the case because we did not use the same lri-s for cuisines across the entire dataset.
1171,this could lead to a meaningful result and potential improvements for the development of the program.,such a model can give rise to a meaningful result and potential improvements in the evolution of the program.
1172,"the cosine distance results in more links than the jaccard, because it connects entities for weaker matches.","the cosine distance will result in more links than the jaccard, since it creates connections among entities that are less likely to be matching."
1173,"the optimal number of channels can be explained by the fact that having more channels means learning more features, which leads to more accurate approximations of the input images.","the optimal number of channels can be explained by the fact that having more channels means learning more features, which allows us to approximate the input images more accurately."
1174,which of the various machine learning approaches outperforms the others in terms of predicting the health status of individuals for each health metric accurately and can we explain the predicted results and the accuracy?,"how to explain the accuracy of predicted eq and how to improve the accuracy of predicted values based on the metric, can we specify which machine learning approaches outperform the others in terms of predictive accuracy of individuals in the different metric levels?"
1175,"a huge advantage of a web based solution is, that it does not require client side installation.",the major advantage of the web-based solution is that it does not require any client side installations.
1176,"to overcome this problem, we used the sh:closed predicate which restricts the properties a node can have to the ones that are mentioned about a shape.","in order to overcome this problem, we have applied sh:closed predicate that restricts the type of properties a node can have to the ones referred to in the context of shapes."
1177,"overall this methods shows some potential, as there is more space for some relationships, which would already break a classic planar arrangement.","the overall approach is a promising one, as it allows some relations to be more granular, and does break the tradition of planar arrangements."
1178,"for emotion estimation, we will be using existing face recognition and image manipulation functions already built-in opencv library.",we will use preexisting face recognition and image processing functions already built in to the opencv library for the emotion estimation.
1179,"for a visual validation, above two images show the original one on the left and the one with predicted colors on the right.",we show the two images showing the original image on the left and the one with the color predicted on the right.
1180,"short amount of time, even for the big problem instances provided.",it takes a very short time for the big problem instances as well.
1181,"building a tree in the random forest follows a process called ""bagging"".",the construction of a tree in a random forest involves a process called baching.
1182,"do the authors think the simple growth of computational power to support larger context windows will be enough to overcome this challenge, or does it take more than that?","do the authors think that overcoming this difficulty is just a simple scaling of computational power for sustaining larger context windows, or is it more complicated than that?"
1183,does it converge every time or do you have to be lucky with the parameters?,"is it always convergent, or does it require luck and variables to hold?"
1184,the problem is not suitable for attribute-value representation for multiple reasons.,there are multiple reasons why the attribute-value representation is not suitable for this problem.
1185,"ideally, we would have all the features needed for each approach available in a common data set of games played.",we would ideally like to know whether each of our approaches has all the features needed by our approach and have a common dataset of games played.
1186,"based on the imbalance, it was likely to relate restaurants to an indian or street food cuisine that maybe do not serve them.","the imbalance caused by the variables was likely to link restaurants to indien or street food-based cuisines, which may not be actually served."
1187,"to match with the options provided by the ui we combine fear, anger, sadness and disgust as negative impressions and joy and surprise as positive ones.","we combine fears, anger, sadness and disgust as negative impressions, and we use happiness and surprise as positive impressions to match the categories of preference offered by the ui."
1188,"the parameters used for training the nn can be changed within the code in lines (alpha:, lambda:, epsilon:, max iterations:).","in line of code, one may vary the parameters of the nn training set (alpha:, lambda:, epsilon:, max iterations:)."
1189,"as indicated in several of the other sections, we experienced the structure and choice of abstraction levels in the paper really positively.","we experienced the structure and choice of abstraction levels in the paper in a very positive way, as was specified in a number of other sections."
1190,"instead of using a substitute variable, i would advise to use abbreviation for the name of the measure.",i recommend to call the measure by its abbreviation rather than by its substitute variable.
1191,"with the information retrieved from the raw data set, we conducted several data pre-processing steps to guarantee that the following features would be available for the model.",we performed several data preprocessing steps to ensure that features from the retrieved raw dataset would be available for the model.
1192,the summary aims to provide the main ideas in a illustrative way focusing on as little detail as possible to understand the subject.,we aim to give an illustrative summary of the main ideas to ensure that as little background as possible is needed to understand the subject.
1193,it is used in evaluation when the number of samples belonging to each class is equal or classes are balanced.,is used for evaluation when the number of samples belonging to each class is equal or between classes are equal.
1194,the problem of generating meaning full sentences with some arithmetic is as almost as old as natural language processing itsself.,the problem of generating meaningful complex sentences with some computational analysis is as old as the problem of natural language processing itself.
1195,the advantage of this algorithm is that it is able to train with a small number of samples.,the advantage of this algorithm is that it can be trained on a small number of training samples.
1196,"further, the training might me faster and simpler while the results are easier to interprete.","furthermore, the learning process could become fast and simpler while the results would be easier to interpret."
1197,"first, we converted our pictures to the lab colorspace which is more helpful for this exercise than the rgb colorspace.","first, we do colorspace resampling on the css, which is more helpful in our experiments than the rgb colorspace."
1198,"this fact also characterized their health metric outcomes, resulting in active individuals being more healthy than those from the sedentary cluster.","this result has accompanied the data analysis of the health metric performances of these clusters, with active cluster members exhibiting a higher level of health than those in the sedentary cluster."
1199,they have the advantage that only a camera with the average resolution is required on the hardware side.,one advantage of these techniques is that the hardware side is only required to rely on a camera with the average resolution.
1200,"finally, they combine the two networks using the fusion module and let the ensemble train for two additional epochs.","finally, the crossover module merges the two underlying networks and then allows the ensemble to train in two additional time slots."
1201,also it covers all of our needed entities with their corresponding predicates.,we cover also all the required entities and their corresponding predicates.
1202,it is designed to be able to handle the shipment requests on a day to day basis even in the presence of delay allowance.,is designed so that it can handle daily delivery requests in the presence of delays.
1203,the summary of the questionnaire's answers can be found in section b of the appendix.,the answers to the questionnaire are summarized in section b of the appendix.
1204,"this translates into, that the user needs more time to take a decision on what to listen or watch.","thus, the user needs more time to decide whether to listen or watch something."
1205,"that means that the agent can only observe his position or velocity as the (index of the) interval that he is positioned in, but not as the precise value.","this means that, for an agent, its location or velocity can be only viewed as the (index of the) interval it resides in, but not as the true value."
1206,we decided for-htr to use only the two relations from the assignment for the new rule.,"we decided to use for-htr, which means we only need to use the two relations contained in the assignment of the new rule."
1207,they are easily explainable and therefore a good choice to consider for our project.,these can be easily explained and thus seem a good candidate for consideration in our work.
1208,"comparing the normal method and the bootstrap method, the normal method does not require bootstrap iterations and thus runs faster.","comparing the ersatz method with the bootstrap method, the ersatz method requires no bootstrap iteration, so runs faster."
1209,"precaution avoidance performing initial tests with available models, using simpler models (if possible), ask for help on the related online discussion groups.",a caveat is to perform initial tests using the available models and in less crowded scenarios ask for help in related on-line discussion groups.
1210,"for each experiment, the hyper-parameters were incremented from zero to one in a series of twenty steps.","the hyper-parameters were varied by a process of twenty steps for each experiment, from zero to one."
1211,lack of ability to express all eight vectors and therefore lead to higher loss networks.,incapability to express all eight vectors and thus leads to higher lost networks.
1212,"using the models build so far and knowing an individuals current activity pattern and its confounders, we will be able to predict its health status.",we will make a prediction about the health state of an individual by leveraging the models built so far with information about the individuals current activity patterns and the factors that influence them.
1213,"during this project there were challenges that we could not solve, therefore in this section, we would like to point these out.",we would also like to point out some challenges encountered during this project that we were not able to overcome.
1214,"in states with a red left arrow the agent will go left, in blue right arrow states the agent will go right, and in asterisk states the agent will do nothing.","blue right arrow states indicate the agent is left, blue left arrow states indicate the agent is right and asterisk states represent nothing done by the agent."
1215,"as only one state action pair is updated per iteration more states mean less updates per state action pair on average, when the amount of iterations is kept the same.","if the number of iterations is constant, more states will mean less updates per state action pair per iteration."
1216,"one can identify the following behavior: if the agent has a positive velocity, he will almost always accelerate positively (white area).","the behavior is then simple to characterize: if an agent s velocity is positive, it is avpcnticly always accelerating positively (white region)."
1217,"this translates into, that the user needs more time to take a decision on what to listen or watch.",this means the user needs to allocate more time to decide whether or not to listen or watch.
1218,"richard zhang, jun-yan zhu, phillip isola, xinyang geng, angela s lin, tianhe yu, and alexei a efros.","richard zhang, jun-yan zhu, phillip isola, xinyang geng, angela s lin, tian yu, and adie efros."
1219,"additionally, every possible move will be evaluated with different player strengths using the internal monte carlo tree search, an heuristic method to evaluate the value of a move using sampling.","furthermore, the internal monte carlo tree search, a heuristic approach for quantifying the value of a move, evaluates each possible move against the strength of different players."
1220,"if you plan to execute the jupyter notebook, please run the code cells first.","first of all, please make sure the code cells are executed by a jupyter notebook."
1221,"as a solution, we used python to accomplish both parts of this transformation.",this was done by using the two parts of the transformation in python as the solution.
1222,by analyzing ambient noise or by evaluating the noise level as such.,"either by the ambient noise, or perhaps in terms of the noise concentration itself."
1223,"but it has to be taken into account, that while the two minority classes were merged for the explainable models, the complex models have been trained on all three classes.","however, notice that while the simplifying classes were combined into explainable models, the complicated models are trained on all three classes separately."
1224,there are a few gains that we could archive by using this representation.,this representation allows us to archive some gains that will interest us.
1225,you have provided hyper parameters for your networks and the adam optimization.,the hyper-parameters of your networks and the adam optimization parameters are stated.
1226,"this is also the case for the wald, normal and score ci, which all perform well in this scenario.","all these techniques perform well in this scenario, including wald, normal, and score ci."
1227,the neural network and testing environment was developed in python in the form of a jupyter notebook.,the implementation of the jupyter notebook for computing neural network and testbed has been built in python.
1228,"jihyun park, kexin zhao, kainan peng, and wei ping.","we thank jihyun park, kexin zhao, kainan peng, and wei ping for their valuable discussions."
1229,each fold has the same percentage of each class compared to the original dataset.,"compared to the original dataset, each fold has the same percentage of nodes of each class."
1230,a major concern in the evaluation of the experiments is the accuracy of the gradient ascent procedure.,the accuracy of gradient ascent procedure is a crucial issue for our evaluation of experiments.
1231,"but most likely the chosen latent space representation is too small to capture all the details, we will see about that later.","but most probably, the chosen latent space representation is too small to capture all the details, as we shall see later."
1232,"firstly, i want to thank my supervisor tjark vredeveld, who helped me to develop my thesis to the point it is right now.","first, i would like to thank my supervisor tjark vredeveld, who prompted me to develop this thesis to the point that it is today."
1233,the main goals of a q-bot is to minimize the number of troops lost in battle while maximizing the amount of controlled territory.,the main goals of the q-bot is to minimize the number of troops that are lost in the battle while maximizing the number of captured territories.
1234,"because health metrics are subject to change quickly, it is necessary to store those instances in a set to identify severe values over multiple measurements.",these instances have to be stored in the set to identify severe values over multiple measurements since health metrics change so quickly.
1235,"relying on the accuracy metrics of the training set is therefore misleading, as instead, the model new data is not the same compared to the training set.","that is, it is misleading to rely on the accuracy metric of the training set when the model learning features are not similar to those from the training set."
1236,"then, the car will visit all four spaces equally often and will not learn to distinguish between them.",the driver would then visit all four places equally often and no distinction between the spaces would be learned.
1237,note that one vertex is created for each of the perceived emotion while one vertex is created for each member of the set of chord-set extracted from a music object.,"note that a distinct vertex is created for each perceived emotion, and one vertex is created for each member of the chord-set extracted from the music object."
1238,results by combining classes it was possible to reach an even higher accuracy for explainable models than for complex models.,"a even higher accuracy is achieved for explainable model than for more complicated model, and improved predictability achieved by class fitting result."
1239,"for each step, the learning parameters and the optimization method is given.",learner parameter and optimization method are given for each step.
1240,this section provides a brief overview on understanding and interpreting a decision tree.,we give a very brief overview about understanding and interpreting decision trees.
1241,it could be interesting to remove the assumptions that it is not allowed to store shipment requests at intermediate terminals.,the assumption that shipments requests are not saved at intermediate terminals is reasonable and could be interesting.
1242,"semantic similarity measurement, as it shows the best correlation with human evaluation in several tasks (c.f.",the measures of semantic similarity are important because they provide the best equivalence to human evaluation across various task runs (cf.
1243,building upon recent works in the unsupervised learning domain in nlp to pre-train a model on unlabelled data to develop general-purpose abilities and knowledge that further can be transferred to downstream tasks.,"this builds upon recent work on unsupervised domain learning in nlp, where trained model classes can learn general-purpose abilities and knowledge that can be further adapted for downstream operations."
1244,"example hypothesis the following examples of hypothesis are based on the following language of (tweetid, subject, author, connotation, tweets: type) (c.f.","for example, the hypothesis theoretic examples represent the following language expressions (tweetid, subject, author, connotation, tweet: type)"
1245,"to interpret random forest, one can instead count the occurrences of a given feature, where important features will appear more commonly in the trees.","a different way of approaching random forest interpretation is to count the number of occurrences of a given feature, where important features occur more often on trees."
1246,the only question that arises is with which data the pre-trained network model is trained.,the only remaining open question is with which data the pre-trained network model should be trained.
1247,the paper can have an impact on the topic of image restoration.,we hope that this paper will be helpful for future research in image restoration.
1248,"after internal discussion and research being carried out in the early stages of the project, it was decided by the entirety of the group to focus on the recommendation for music content.","then, the encompassing group decided to focus on music content recommendation, after intense discussion and research in the early stages of the project."
1249,"the higher in the tree, the more relevant it is in explaining the relationship between predictors and output.","the higher this tree, the more relevant it is for elucidating the relation between predictors and outputs."
1250,the best feature subset is selected by comparing the predictive performance of the base algorithm for various feature subsets.,the prediction performance of the baseline algorithm over various feature subsets is then considered to be the best one.
1251,the performance becomes worse and then performance becomes better as the instance size increases further.,"as the instance size increases further, the performance becomes worse and the performance becomes better again."
1252,"let g(n, a) be the graph representing the network.","let g(n, a) represent the network represented as a graph."
1253,"the fact that the sentiment values are right-aligned, and thus more positive than negative, can lead to the conclusion that when people are tweeting about movies, they predominantly write positive things.","this suggests that when people tweet about a movie, they tend to tweet about positive things as well, since sentiment values are right-aligned and thus more positive than negative."
1254,"since both datasets have cuisine entities, we decided to make the connection through these.",we chose to make this connection through the culinary entities in both datasets.
1255,"within the decision rule, there are two main components working together.",there are two main components that work in conjunction inside the decision rule.
1256,"also, we would lose the information about the previously mentioned (n:m) relations present in the problem.",we also lose the information of the earlier mentioned (n:m) relations present in our problem.
1257,"given some textual input the aim is to rewrite the text in a way that preserves its gist while changing its tone, sentiment, syntax or other stylistic features.","the task is to rewrite a text s gist to preserve its tone, sentiment, semantics and other stylistic features with respect to some textual input."
1258,"this way, the machine running the p.s.e.",this way the machine running p.s.
1259,as far as this can be judged the paper seems to be completely technically sound.,the paper is technically sound in that respect as far as this can be judged.
1260,"for example, the detection and coloring of abnormal tissue in the body.","for example, to detect and color abnormal tissues in the body."
1261,"id, weight and volume of the shipment requests are irrelevant for this research.","we make no difference in this research to the id, weight, and volume of the delivery requests."
1262,considering a similar aggregated metric for overall evaluation of models is also sensible in this work.,it is also reasonable to look into using a similar aggregated metric as an overall assessment measure of models in this work.
1263,"by varying the time step to a smaller size, the amount of instance per example gets smaller.",the number of instance per instance becomes smaller as we shift the time step down to the smaller scale.
1264,recursive feature elimination feature selection is a technique to select a subset of the most relevant features for a dataset.,recursive feature elimination feature selection is the technique of choosing a subset of features in a dataset that are the most relevant.
1265,in this case they use these it is also noted that instead of models to classify the sentiment of tweets.,we also observe that sentiment models are used instead of models in this context to categorize tweets.
1266,increasing the number of epochs would also help our model in its prediction capability.,it would also help our model predictably by increasing the number of epochs.
1267,this means that we assume the information that was given in the assignment as known to the reader.,this means that we assume the information provided as part of the assignment is known to the reader.
1268,"the reason why the weekday model is discussed here is to help to understand the general model, as it is a build-up to the weekly model.","the point of discussing the weekday model in this paper is to help make the general model more understandable, since it serves as a refinement of the weekday model."
1269,this query allows us to verify our result for some of the previous queries.,this query allows us to check our result on certain kinds of query below.
1270,"in the following, the received aggregated answers will be analyzed and the results are compared to our expectations.","the received aggregation answers are evaluated, and their results are shown to be satisfactory."
1271,"considering such a great impact, these systems have been increasingly getting improved, to get more reliable and thus increase the users trust in such systems.","since this is such an important effect, these systems have been continuously improved to make them more reliable and thus increase user trust in those systems."
1272,"lastly, our experiments have some bias; an analysis of algorithmic error, hyper parameter tuning and the ability to estimate the maximal amount of initializations needed with monte carlo simulations were used in their creation.","finally, our experiments are somewhat biased; their design was based on analyzing algorithmic erroneousness, tuning hyperparameters and estimating the maximal number of initializations necessary for monte carlo simulations."
1273,"the trick is that the grayscale picture contains the details, such as contours of a picture, so it has the l value from the lab colorspace.","the trick is that the images with grayscale attributes contain details, such as the contour of the image, so we have the l values from the lab colorspace."
1274,"a scenario where this assumption would apply could, for example, be the transport of valuable freight that is only insured for direct delivery from origin to destination.","for example, suppose a valuable shipment is transported only by an agent insured only for direct delivery from the origin to the destination."
1275,"hence, we deem it important to come up with a way to measure the mood and engagement of players to be able to assess how the players are feeling.","hence, we believe that it would be important to propose measures to gauge player mood or engagement to evaluate how players feel."
1276,the program for solving the ilp and applying the decision rule is implemented in java.,is implemented in java for solving an ilp and for applying the decision rule.
1277,"lastly, some experiments are provided that illustrate how the previous meta-results of retaining cluster structure in the latent space translate to the overall goal of achieving better results with latent space arithmetic for data generation and manipulation.","finally, some experimental results are provided that illustrate how the earlier meta-result of preserving the cluster structure on the latent space transforms to the goal of improving the results in latent space arithmetic in data generation and manipulation."
1278,"after obtaining the schedule of trucks, based on the old shipment request data, the operational decision rule can be used to assign all shipment requests that are stored at, due to delay allowance, or arrive at the terminals of the lsp on a day to day basis.","the following operation decision rule is designed to assign all the cargo requests that are saved in the cache due to delay allowance, or arrive at the terminals of the lsp one-by-one, and is based on the old cargo request information."
1279,"the kaggle dataset contains entities representing the cuisines, recipes and used ingredients.","the kaggle dataset includes entities representing cuisines, dishes and ingredients used in the recipes."
1280,"for instance, one movie can have a lot of different actors, and one actor can play in several different movies.","for example, there can be more than one actor in a film, and one actor can be in several movies at the same time."
1281,"all the health characteristics used in the analysis are used as inputs and because of the approach, the techniques are suitable for clustering and association mining techniques.",the approaches are suitable for clustering and association mining applications because they take as input all the health features used in the analysis.
1282,the research domain of text style transfer can be subdivided into numerous approaches.,there are many approaches to consider text style transfer in the research domain.
1283,"as the logistic regression model explains the the metric with more importance on physical activity patterns and the decision tree focuses only on confounders, the chosen explainable model is logistic regression in this case.","logistic regression is the preferred explainable model, given that this metric captures the observed patterns more closely and the decision tree focuses only on the confounders"
1284,the main neural network code is enclosed in a function for repeated executions.,the main neural network code is encoded as a process that performs repeated executions.
1285,"in addition to the reason that bin packing is well researched, an adjustment of the used models for bin packing would have complicated the problem and shifted away the focus of the research problem to a more general one.",this has also been well studied mainly because the configuration of bin packing models is generally updated; a more generalized bin packing model would have complicated the problem and shifted the focus of the research problem from bin packing.
1286,"in this search space, each activation function is represented as a tree containing unary (e.g.","this search space is represented by a tree containing unary functions, as in qemu s"
1287,they appropriately reference the related works and clearly indicate their improvements compared to the other state-of-the-art researches.,we appropriately reference related works and clearly point out how the proposed algorithms have improved over existing state-of-the-art research.
1288,"thus, a user can complete multiple sessions, allowing the app to meet their needs over a period of time of their choosing.","the user can therefore complete multiple sessions, thus allowing the app to satisfy its users needs for time as they desire."
1289,we run the predefined number of iterations to find better and better weights for the prediction of the output values.,we perform a predefined number of iterations to find better and better weights for predictions of output values.
1290,they enable the model to learn the characteristics of the minority class better.,we better understand the minority class characteristics that the model learns.
1291,the permanent face analysis provides us with a series of emotions per song.,our analysis of live face projections provides a per-song emotion summary.
1292,"as all of the summed variables are binary decision variables, this constraint requires that one of the decision variables is set to one and all others are set to zero.","this constraint essentially means that one of the decision variables is zero and the other one is one, since all of the summed variables are binary decision variables."
1293,"to get insights into this health metric, complex models were used.",complex models have been applied to derive insights into such health metrics.
1294,"this system uses convolutional layers and multiple lstms to generate melspectograms, a widely used form of sound representation.","melspectrograms (svms), a widely-used representation scheme for sound, is generated by convolutional layers combined with multiple lstms."
1295,"the reason for this may be that there were no features in the dataset that correlate to the health metric, or a limited number of instances in the dataset.",this could be due to the lack of features that relate to the health metrics in the dataset or the small amount of instances available in the dataset.
1296,"the second set has two versions, one for the weekday and one for the general model.","the second set has two version, one for the weekday model and one for the general model."
1297,do you think there is a merit in investigating the geometry of conversations when represented as a sequence of vectors in the latent space?,do you think investigation of the geometry of conversations as represented as sequences of vectors in the latent space is merited?
1298,"if there is a volumetric weight of one and a half truckloads needed to be shipped via route a in week w, then the constraint requires that two trucks are driving on that route.","when a route a must ship one and a half truckloads of cargo in week w, then constraint b requires that at least two trucks make the trip."
1299,by analyzing ambient noise or by evaluating the noise level as such.,either by analyzing the ambient noise or by evaluating the noise amplitude as such.
1300,"when comparing linear function approximations against non-linear ones, it can be noted that non-linear performs a lot better.",we notice that the nonlinear approximations perform significantly better than the linear function approximations.
1301,"to mitigate these issues, if they occur during our experiments, we also look at hierarchical clustering and vbgmm which address the problems of k-means clustering.","next, we examine hierarchical clustering and vbgmm as solutions to the problem of k-means clustering to alleviate some of these issues, if they exist during our experiments."
1302,"together, these trees can predict based all of these parts, which is also referred to as the majority vote: when a prediction is made, the majority prediction of all trees is returned as a result.","the ensemble of these partitions can be used to predict the entire tree, as represented by a majority vote: once a prediction is made, the majority of all trees receive a result which is represented as a majority prediction."
1303,"here, combinations of parameters are randomly picked and evaluated for a given number of iterations.","here, a combination of values for a given number of iterations is randomly chosen and evaluated."
1304,"hence, these results need to be analysed with a care.","therefore, we have to carefully analyse these results."
1305,"namely, it would be better possible to represent counts of certain words or word-groups.","namely, counting of particular words or word-sets could be well represented."
1306,distances to all nodes which have not been reached in the iteration are getting updated.,are updated to update the distance of all nodes that have not been reached during that iteration.
1307,"results while the given health metric was not heavily imbalanced, models were not able to reliably predict the classes.",we have observed that the models showed high fidelity at predicting class occurrence while the given health score was not strongly imbalanced.
1308,and email ending on a suspicious domain name) as binary features.,they also saw emails that terminate in a suspicious domain name) as binary features.
1309,aae looses the cluster structure in the latent space and fails to preserve the geometry of data.,aae loses the structure of the clusters in the latent space and fails to preserve the data geometry.
1310,for every cuisine and ingredient a separate iri was created within our namespace ken to implement the idea of this shared knowledge.,"to bring these iri into practice, we have created separate iri in our namespaces for each cuisine and each ingredient."
1311,"although complex machine learning models that employ ensemble learning or support vector machines commonly outperform traditional regression and tree models, the results predicted are not easy to explain.","while ensemble learning and support vector machine are typically performed much better than traditional regressive and tree models, predicting the results is difficult to explain in complex machine learning models."
1312,the split points are called nodes and selected by using a cost function.,we refer to the split points as nodes and assign them a cost function to select them.
1313,"also, we added sh:name to have labels for the properties, increasing human-readability.","we also used sh:label to have properties labels, to make it more human-readable."
1314,"when lowering the acceptance threshold, similar phenomena happened than in the previous experiment.",similar phenomena as in the previous experiments took place when the acceptance threshold was decreased.
1315,beans in general are also often related to a mexican cuisine.,mexican cuisine is also widely regarded as a resource of beans.
1316,"the distribution of observations in a dataset, analagous to a histogram.","a distribution of the observations in a dataset is similar to a histogram, but different from the histogram."
1317,"therefore, if other users with similar preferences rated an item highly, the item is estimated to get a high rating from the active user too.","therefore, if an item received a high rating from an active user that has similar preferences, the item should be considered highly by those users as well."
1318,these songs mostly supported the at-the-moment mood of the testers.,our testers mostly responded with song lyrics that well fit their at-that-moment mood.
1319,while the previously mentioned method allows the td-bot to choose an attack target it lacks the ability of actually allowing to let the bot decide whether to attack or not.,"while the above discussed methods let the bot choose the ap, they lack the ability to actually allow a bot to specify whether to attack or not."
1320,"thus, in the future, we would like to collect more and detailed data to build a better model.",we therefore would like to collect more and more details for a more refined model in future.
1321,resampling involves randomly oversampling the minority class or randomly undersampling the majority class to ensure the classes are balanced.,"resampling involves either randomly oversampling the minority class or randomly undersampling the majority class, so that the classes are equal."
1322,"in this section, we cover the interpretation of the results obtained from lime.",we discuss the interpretation of the results of lime in this section.
1323,and if desired more layers can be added or the data can be altered.,"this also allows the addition of more layers as desired, or alteration of data."
1324,"the metadata features can be easily treated like words, so just checking their occurrence.",metadata features are treated like words and are therefore not hard to check for their occurrence.
1325,"this is, nowadays, most of the content that users consume comes from recommendations made from the applications.","nowadays, most of the content consumed by users is based on recommendations made by the applications."
1326,all of these possible statistics can be considered either in absolute or relative fashion.,this kind of possible statistics can be treated in either an absolute or a relative fashion.
1327,after setting those hyper-parameters more experiments should be run using the other optimization methods on the various cis end examine the advantages and disadvantages of using each method.,we will use the other optimization methods to perform a series of experiments on the various cis and then study the advantages and disadvantages of using these methods after setting these hyper-parameters.
1328,further more the possibility to do latent space arithmetic lays the ground brick for future work in text generation possibilities.,"in addition, the possibility of latent space arithmetic forms the bedrock for future work on generating strings."
1329,"for example, stress levels can be determined with the help of medical sensors to evaluate heart rate and blood pressure.","for example, the monitoring of heart rate and blood pressure is made possible by the use of patient-sensors that measure the stress levels."
1330,risk is a strategy game; the goal is to own all countries in the world by defeating opponents.,risk is a strategy game in which one wants to dominate all the countries of the world by destroying all the opposition.
1331,in general the main insight of this decision tree is about the amount of physical activity.,our main general insight from the tree of decision trees is to observe how much physical activity is actually performed.
1332,"hypothesis might learned based on then be traditional mi, multi tuple, or multi join.","therefore, it might be traditional mi, multi tuple, or multi merge based hypothesis learning."
1333,"in this report, the innovation developed out of the corresponding research will be explained and compared.",this paper will explain and compare the innovation found by corresponding research.
1334,"for our project, we will aim to use the emotional annotations from the pmemo dataset for labeling the songs in our main dataset via transfer learning techniques.",we plan to use transfer learning techniques to make the emotional annotations from the pmemo dataset used in our main dataset for song labeling.
1335,the calculation involves subtracting the current state value from an estimated future state.,the computation involves subtracting the value of the current state from the estimated future state.
1336,the following section gives an overview of the current state of research in the related domain and projects considered aiming a similar result.,"this section provides an overview of the state of the art in related research fields, including projects that aim to get similar results."
1337,"the decision tree outperformed the logistic regression model, consequently, we decided to choose the decision tree model.","they also found that the decision tree model outperformed logistic regression, which prompted us to opt for the decision tree model."
1338,"results for this metric, explainable models performed considerably worse compared to the complex models.",it is quite clear that for this metric explainable models perform much worse compared to complex models.
1339,"we chose limes because we had a good limes.jar experience locally, and also, the preprocessing functions of it seemed very helpful.","we chose lime primarily because we had a very good experience locally with limes.jar, as well as because it provides us a very nice preprocessing functionality."
1340,the kdd process for extracting useful knowledge from volumes of data.,kdd-based methods for extracting useful knowledge from large data.
1341,in this study it is used for measuring model performances for class imbalance problems.,it is used in this study to measure model performance in the class imbalance problem.
1342,"for improvement, especially in the object detection module and in the runtime performance.",several improvements could be made to the object detection module and the runtime performance in particular.
1343,this way we avoid losing information from the edges of the picture.,this method allows us to keep the edges of the picture without losing much information.
1344,"when a user used the like or the skip button while listening to a song, this direct feedback was used as their rating in order to get better future recommendations.","when a user pressed the like or skip button while listening to a song, we used this direct feedback as their rating to receive a better future recommendation."
1345,the missing values of individual health metrics are dropped when building the model for that particular metric.,"when constructing the model for some particular metric, we drop the missing values for individual health metrics."
1346,the values for the q table were stored in a numpy array.,we stored numpy arrays of the values of the q table.
1347,"this is why the chosen model for this metric is svm, which has the highest accuracy of both explainable models.","hence, to design this metric, we use svm which is superior to both explainability models in terms of the accuracy."
1348,it does so when the object detection fails to extract all objects.,it does so when all objects have failed to be extracted by object detection.
1349,each graphic depicts the relation between the incremented hyper-parameter and the average number of turns needed for the adjusted bot to win (turns to win) and the average percentage of games won for each increment.,each figure depicts the relation between the increased hyper-parameter for the number of turns (turns needed for a winning response) and the average percent of games the hyper-parameter can cover.
1350,"to mitigate this issue, non-linear svms gain linear separation by mapping the data to a higher dimensional space.","the non-linear svms, by mapping the data to a higher-dimensional space, help overcome this issue of linear distance gain."
1351,"finally, we have changed the design of the model itself by removing certain layers.","finally, we modified the architecture of the model itself, removing certain layers from the mesh."
1352,"if the prediction accuracy decreases substantially, then it suggests that variable k is strongly associated with the outcome variable.","if the prediction accuracy decreases too much, then it suggests that k is strongly dependent on the outcome variable."
1353,in line with the solution values becoming smaller with higher delay allowance the numerical deviations from the mean are for all three delay allowances about the same.,they indicate that for all three delay allowances the numerical deviations from the mean are practically the same and solution values becoming smaller with higher delay allowances.
1354,"therefore, finding good practices for fair opening rules would help make it easier for developers to make their games more balanced.","therefore, finding a good practice of fair opening rules might help developers to make their games more balanced."
1355,"prediction model does not align, even contradict with medical state-of-the-art research.",the prediction model does not model the outcome appropriately and it even contradicts the state of the art research in the medical field.
1356,"additionally, one might have similar attributes focusing on the subject of the mail.","similarly, one may have similar attribute with special attention on the mail subject."
1357,"on the other side, if the participant shows physical activity through the other three activity measures, he will be assign to acceptable.","for the other two activity measures, if the participant has physical activity through one of the other three activity measures, he is assigned to acceptable."
1358,"the more episodes were used, the clearer we could see it.","the more episodes were used, the more clearly it was evident to us."
1359,the id is irrelevant because each request has an implied id by the data structure of the computer program designed to solve the ilp model.,this id is not relevant because each request has an implicit i d calculated by the data structure of a computer program devoted to solving the ilp model.
1360,to classify whether emails are spam or ham one can use av representation.,av representation can be used to clasify whether emails are spam or ham.
1361,the aim of this case was to make sure all parts of the pipeline worked together in the expected way.,we wanted to make sure that all elements of the pipeline behave in a predictable way.
1362,"simple q-learning is the overall winner, defeating every other bot.","the overall winner is simple q-learning, pinning down all other bots."
1363,depending on the current board situation the agent might encounter a large number of possible attack moves.,an agent encounters a large number of possible attack moves as a function of the current state of the board.
1364,the models will be individually built to predict each health status using all the independent variables.,"the models for each health state are constructed individually, taking into account all the independent variables."
1365,"in the distribution phase, players will choose on which countries to initially place their troops until they have no more to place.",players in the spread phase decide where to initially place their troops until no country has more to place.
1366,support vectors are those data points that lie closest to the decision boundary or the hyper plane.,the support vectors are those data points closest to a decision boundary or the hyperplane.
1367,for that we have implemented two algorithm types: (i) q-learning and (ii) sarsa with an epsilon-greedy strategy.,"ii) sarsa with an epsilon-greedy strategy, which we implement on the basis of the following two algorithm types."
1368,"for example, the current health metric measures might be acceptable, but a few measures ago those values indicated severe health issues.","thus, the values reported in the current health metric might be healthy and yet, only a few measures ago, that measure implied severe health problems."
1369,it may even consist of several disjoint regions (c.f.,the local field may include several disjoint regions (cf.
1370,the position of the dividing hyper plane would change if the support vector of those elements of the training set are removed.,"if we were to remove the support vector from the underlying elements in the training set, the position of dividing hyper planes would change."
1371,the goal of this paper is to argue whether it is possible to implement a bot that can play the game of risk.,the objective of this paper is to argue for a potential deployment of a bot able to play the risk game.
1372,mle is called the maximum-likelihood estimator (mle).,we name mle as maximum-likelihood estimator (mle).
1373,after that we converted the lab values of the images to the rgb color space and plotted them against the original versions of them.,we then converted the lab values of the images into the rgb coloring spaces and plotted them to the original version of the images.
1374,in order to execute the theory the search space needs to be moved into a discrete space.,the search space is now transformed into the discrete space that is necessary to execute the theory.
1375,"using these data points, we aim to identify machine learning approaches to determine the health status of individuals and validate if their physical activity patterns have a direct impact on a given or combinations of health characteristics.",we aim to identify machine learning approaches to enumerate the health status of individuals and validate whether these patterns of activity result in either direct or combinational results.
1376,resource constraints are considered as a feasible solution to a problem instance.,a feasible solution to an instance of the problem is considered when the constraints are based on resources.
1377,"for the purpose of empirically estimating possible cost savings, with respect to the allowance of delay, new problem instances were generated using re-sampling from the before described data set on the same network.",the new problem instances generated using the resampling from the previously described data set were designed to empirically estimate potential cost benefits with respect to delay allowance.
1378,it is suspected that using a deep neural network with the simple features already creates a complex decision space.,they suspect that a complicated decision space would already be produced by using a deep neural network which understands simpler features.
1379,below is a table of the different things for each type to validate in our data.,we outline the different things for which we test our results with each type below.
1380,"with an increasing number of days delay allowance, the ilp formulation becomes more complicated, as the number of variables and constraints increases with the number of days delay allowance.",the ilp formulation becomes more complicated with increasing number of delay days as the number of variables and constraints become bigger and the number of delay days becomes more and more constant.
1381,then we group the result on the country label and count the number of restaurants associated to this country.,we then cluster the results by country labels and count the number of restaurants associated with this country.
1382,deployment of a production network where the gain in accuracy can),is implemented in a production network with a potential gain in accuracy)
1383,"in order to explain the results of the health metric prediction, decision trees or logistic regression was used.",decision trees or logistic regression have been applied to explain the results of health metric prediction.
1384,"this leads to new ideas, which can be built on top of the new method.",this leads to new suggestions that can be built upon top of the new method.
1385,"the second step uses one neural network to colorize each instance individually, and another one to colorize the full image.","the second step uses a single neural network for coloring the individual instances, and a second network for coloring the whole image."
1386,for this reason an additional heuristic which decides based on the win chance if the bot should start an attack or not was introduced.,a different heuristic was introduced that determined whether a bot is expected to start a attacks or not based on the probability of winning a game.
1387,the used queries for those facts can be seen in the appendix b.,the appendix b provides some details on the types of query set used for those facts.
1388,"to address this, the sum over this decision variable becomes a double sum, which sums over all possible delays of the shipment request as well as over all lanes.","for this, we transform the sum over the given decision variable into a double sum, which sums over all possible delays of the shipping request and over all lanes."
1389,"this would end up in combinatorial explosion in the number of attributes, and a very long, sparse matrix with a lot of missing values for the pieces of clothing and their attributes, that the uncle did not wear on most days.",this would lead to a combinatorial bursting of attributes that produced an extremely large sparse matrix whose facets and attributes have many missing values as pieces the uncle had not worn most of the day.
1390,the release of pre-trained weights by the authors and a well-maintained repository along with the excellent results on benchmarking tasks supports the usage of this model for our experiments.,"the model is shared by authors and maintained by a large community, and has excellent performance for benchmarking tasks, which facilitates the adoption of this model in our experiments."
1391,"after internal discussion and research being carried out, it was decided by the entirety of the group to focus on recommendation for music content.",the entire group decided to focus on music content recommendation after internal discussions and research had been conducted.
1392,the strategic level concerns long term planning and large capital investments on infrastructural problems like building highways or railways.,"a strategic level considers long-term planning and large capital investments in infrastructure projects, like road construction or railway construction."
1393,overview homa-ir describes the homeostatic model assessment for insulin resistance.,homa-ir describes a homeostatic model assessment of insulin resistance.
1394,"counter-intuitively, many movies with low ratings end up with high earnings.",what is counterintuitive is that in our experiment many low ratings movies wind up with high ratings.
1395,only the support vectors are captured in this case as values and used for further prediction and analysis.,"in this case, the maximum-outage system is reduced to storing only the support vectors in their values, and used to provide further prediction and analysis."
1396,"cross-validation when a model learns based on a training set of data, it will typically perform extremely well when predicting this training set.",cross-validation: when a model learns from training data it will in general perform extremely well in the prediction domain of this training set.
1397,"it records all pairs (sx, sv, a, reward)","all pairs (sx, sv, a, payoff) are registered (return)."
1398,this paper is addressing the recourse constrained shortest path problem (rcsp),the paper discusses the recourse constrained shortest path (rcsp) problem.
1399,"the study of tst has not only been popular among linguists, but computer science and machine learning researchers as well.","tst is a popular language learning approach not only for linguists, but also in computer science and machine learning research."
1400,"whether they perceived the song as predominantly positive, negative or neutral.","we examine whether participants identified the song as overwhelmingly positive, negative, or neutral."
1401,based on these categories the owner of the cinema can choose the most profitable movies.,a movie operator can select films that are most profitable based on these categories.
1402,task: a busy hospital contacts you to build a system that can learn to predict how long patients will have to stay in intensive care after surgery.,task: contact a busy hospital to build a system that can learn to predict how long patients will need to stay in intensive care after a surgery.
1403,"the collective shap values can show the contribution of each predictor, either positively or negatively, to the outcome variable.",collective shape values can reveal that each predictor in a cluster has a positive or negative impact on the outcome variables.
1404,keeping track of which values are updated during optimization one quickly sees that these are the values that are not changed.,the first thing one quickly notices when the optimizer stops and recomputes which values are updated and which are not.
1405,"results because of imbalanced classes, this health metric could unfortunately not reliably be predicted by the methods used.","unfortunately, the method used here was unable to accurately predict this ae health metric due to imbalanced classes."
1406,"summarising, the authors manage to successfully apply recent advances to a new setting (nlp) aiming to solve a long existent problem.","summarized, the authors successfully apply the most recent developments to a new lane parsing (nlp) setting, which is to solve a long-standing problem"
1407,"imbalanced, where the majority of the instances were class acceptable.",it was in equilibrium when most of the instances were class acceptable.
1408,from our research we believe it is possible to generalize a sentiment analysis model trained on imdb reviews to analyze twitter data to some extent.,we believe that to a certain degree the sentiment pattern analysis model trained on imdb reviews can be generalized to analyze twitter data.
1409,"taking text as input and producing new text as output, in contrast to bertstyled models that are capable to only output either a class label or a span of the input.",this contrasts to bertstyled models which are able to output either a class label or a span of an input and then converts the output to new text.
1410,"the neural network converges with a larger cost, and logically this convergence is reached faster.","we also see that the convergence of the neural network has a larger cost, which logically becomes faster."
1411,"our two main criteria for the dataset revolve around scale and emotion representation: our project needs a large enough, heterogeneous set of songs to be able to recommend songs from the whole spectrum of music taste, and also to not fail on a limited amount of recommendable songs.","our main constraints on the dataset rely on data scalability and emotion representation: our aim is to provide a large, heterogeneous, music collection of sufficient size to recommend songs to a wide variety of music taste, but not to fail to recommend only a small number of recommendable songs."
1412,the third step uses a fusion module to blend the features from step two.,the third step involves combining the features extracted in the two previous steps using a feature fusion module.
1413,"furthermore, it could help boost performance by combining the approaches using an ensemble.","more importantly, using an ensemble of approaches can also help improve performance."
1414,these initially smaller learning rates cause the trajectory to slowly move into more favourable areas of the parameters space from where the procedure can move faster again.,"these initially small learning rates cause a trajectory to move slowly through the parameter space, to more favorable regions and back, from where it can re-fly more quickly."
1415,"first, we have changed the size of the channels by keeping their relation to another equal.","first, we varied the channel size by keeping the relationships with respect to each other equal."
1416,those subsets include confounders and several groups of health metrics.,"these subsets include confounders, and several classes of health metrics."
1417,we think relational could result in the best performing prediction model because we have a lot of students at dke masters that are coming from other universities.,"since we have a large number of master students coming from other universities, we believe that dke can serve as the best predictive model."
1418,understand the model and data more deeply to see why the model has been built in this way.,let us take a closer look at the data and model for our model construction.
1419,"in this iteration of the td-bot, it has been decided to update the weights of the linear evaluation function after each attack move allowing for a faster learning experience while on the other hand risking inhomogeneous learning steps.","this iteration of the td-bot aimed at updating weights of the linear evaluation function after each attacking move to maximize learning while, on the other hand, risking inhomogeneous learning steps."
1420,exponential growth in popularity of natural language processing (nlp) in the past decades has made it an essential tool for overcoming challenges in largescale knowledge extraction.,the exponential growth of natural language processing (nlp) in the last decades has made nlp an indispensable tool to overcome challenges in large-scale knowledge extraction.
1421,it is done so by segmenting the depth information into the two parts and applying distance transform for the palms and finding the minimal depth for the fingers.,"this is done by dividing the depth information into two partitions, applying a distance transform on palms and by finding a minimal depth on fingers."
1422,"as more dimensions are utilised from the dataset, visualisation of these support vectors in much higher dimensions becomes impossible.","such visualization of the support vectors in many more dimensions becomes infeasible, especially as the dataset gains many more dimensions."
1423,"missing data can reduce the statistical power of a study and can produce biased estimates, leading to invalid conclusions.","missing data reduces statistical power of the study and can produce biased estimates, which result in invalid conclusions."
1424,in order to use the application the required packages provided in the requirements.txt need to be installed.,"we only need to install the needed packages, mentioned in requirements.txt, to run the application."
1425,to derive a more stable mood estimation not a single analysis but a series is used.,our approach uses not a single analysis but a sequence of analyses to derive a more stable mood estimation.
1426,"the value for k, for which the line bends the most, is usually taken as the optimal k. because this bend visually reminds of an elbow, the method is called the elbow method.",this bend is visually reminiscent of an elbow and the elbow method is sometimes treated as the best k value for the point where the bend is strongest.
1427,"as input to the validation process we give a shapes graph in the shapes graph we create three shapes, one for each type of entities we and a data graph.","the task we assign as input to our validation process is to build three shape graphs: one for each entity type, and one for data and information entities."
1428,"using a discrete model this emotional analysis can distinguish between fear, anger, sadness, disgust, joy and surprise.","a discrete-time model is used to study how individuals can process emotions such as fear, anger, sadness, disgust, joy and surprise."
1429,"then we order on the cuisine, and for each cuisine we order on the number each ingredient was used.",we then rank the ingredients according to the food they were used in and for each food we rank the items according to the number of times each ingredient was used.
1430,"this means that it is economically reasonable to use an ad-hoc truck on a certain route in one week, but the demand is not constant enough over the whole period to schedule a truck on route a in every week.","this means that the amount of ad-hoc trips needed for a particular route in one week might be economically reasonable, but the demand is not sufficiently constant to warrant scheduling a truck on route a over a whole week."
1431,"to receive the rgb image after predicting the colors, the result needs to be transformed back to rgb before displaying.","this means that after prediction of color, the result should be transformed back to rgb in order to allow viewers to display it."
1432,"this way, they were able to combine multiple overlapping instances out of the object detection module into one image.","consequently, multiple images from different instances of the object recognition module were merged into a single image."
1433,below images show the improvement of a small and a bigger model.,"below, we see the improvement between the small and large models."
1434,"further, the section on related work could be more detailed to give the reader a broader overview on similar methods (if existent).","furthermore, we could provide a more detailed discussion of related work to give the reader a fuller overview of the similar methods (when existing)."
1435,"as with the levenshtein distance, but now we found a lot more links to review, and also, these were different from the ones found before.","we found even more reviews with similar levenshtein distances, but now we had far more review links than they had been before and our testing results were very different."
1436,also the logistic regression model gives the insights of physical activity.,physical activity insights are also obtained with the help of logistic regression.
1437,pruning is the process of removing the branches that make use of features having low importance.,pruning is a process of removing branches that exploit features with low importance.
1438,marius did not know evolutionary search before) can easily follow the methods used.,marius (who had no prior knowledge of evolutionary search) can easily follow the methods used here.
1439,if this variable is set to a value other than zero it indicates that there is an average high demand for a truck on a certain route over the whole period and it might be reasonable that the lsp schedules also these ta trucks on route a in the future.,"if this parameter has a value other than zero it indicates that, over the entire period, there is an average high demand on a specific truck class as shown in fig."
1440,"the variable slr,l,p is extended to the dimension of the allowed days delay.","the dimensions of the allowed days for the slr,l,p variable are extended to the dimension of the number of delay slots."
1441,"recommendations, these biases are usually user or item biases.",these biases are usually user-biased or item-biased.
1442,"without recognizing cycles, tree expansion would in many cases end up as an infinite process.","since there are a significant number of cycles, the tree expansion ends up becoming an infinity process in many instances."
1443,"green points converged to the global maximum, red points to the local max.","the green points converge to the global maximum, while the red points converge to the local maxima."
1444,"although, this assumption is often not applicable for some real world logistic operations, like transport of food, it applies to many companies within the economy and is, therefore, imposed on the model used in this research.","although this assumption may not be true for some real-world logistical operations like food transportation, it is certainly applicable to many enterprises in the economy as a whole and thus is imposed in the model used in this study."
1445,there is an overlap of key features with the logistic regression model.,logistic regression model has overlap with key features.
1446,how many examples does the optimization of the network need to converge?,how many examples is necessary to reach the convergent performance of network optimisation?
1447,each of these algorithms provide clusters with each cluster comprised of a number of similar objects grouped together as output.,"all of these algorithms construct clusters from the output, with each cluster consisting of a set of such objects, grouped into a common set."
1448,"while working with assumptions was not intended to be in the scope of this work, it needed to be considered in the experiments of this work (c.f.","despite the fact that working with assumptions is beyond the scope of this paper, it has to be considered in our experiments (cf."
1449,whereas with more states it will learn that it is near the origin very often and thus that this is a worse place to be than the slopes of the hills.,"in contrast, as more states arrive, it learns that it is near its origin very often, and thus it is slightly worse than being on the slopes of the hill."
1450,during optimization is often a symptom of learning rates chosen too large.,this sensitivity to learning rates is often a symptom of choosing the learning rate to be too high during the optimization process.
1451,"to get a comparable score among all three groups, we divided each reading by the total number of detections of the group it belongs to.",we then divide each read by the total number of detections by the group it belongs to in order to obtain a score that is comparable among the three groups.
1452,not imposing this assumption has the potential to lower the costs even further under delay allowance.,"the advantage of not imposing this assumption is that, even under the delay bounded assumption, the cost can be reduced even further."
1453,"jonathan shen, ruoming pang, ron j. weiss, mike schuster, navdeep jaitly, zongheng yang, zhifeng chen, yu zhang, yuxuan wang, r. j. skerry-ryan, rif a. saurous, yannis agiomyrgiannakis, and yonghui wu.","for instance, john shen, russ pang, ron weiss, mike schuster, navdeep jaitly, zongheng yang, zhifeng chen, yu zhang, ryan skerry, yannis agiomyrgiannakis and yonghui wu."
1454,"this is caused by the car needing to pass this point the most times taking when building up momentum going from one slope to the other, and thus this point being the furthest away from the goal, in a car trajectory sense.","this is because in the car trajectory sense the snr is the point at which the vehicle needs to pass the most when building up momentum moving from one slope to another, and thus this point is the farthest from the target."
1455,in this section all methods used in the scope of this work are introduced in a detailed way such that only some basic knowledge of probability theory and optimization with the reader is required.,in this section we present in a detailed way all the approaches described in this paper such that only a very basic knowledge of probability theory and optimization is required to carry out the work with the reader.
1456,so the weights and the outputs using all samples have the same pattern.,this means that the weights are all ordered and all outputs for all samples have the same pattern.
1457,"it is required to understand the concepts of machine learning, image processing, and neural networks to understand the paper.","the reader must have a thorough understanding of machine learning, image processing and neural network concepts in order to appreciate this paper."
1458,"with these, it is possible to extract the mood of the user from the video set as input in a particular moment.",one can take the mood of a particular user as input to the video set and exploit it.
1459,then the decision rule recursively checks the remaining requests that need to be sent using route a with zero delay allowance left.,then the decision rule recursively checks the remaining requests to send on route a with zero left-hand side delay.
1460,the plot shows for every position-velocity pair the calculated q-value which belongs to the action that maximizes the given state.,the figure displays the calculated q-value of the actions that maximize the given state in each position-velocity pair.
1461,this insight will be considered while resampling new problem instances from the data set.,"when resampling new problem instances in the data set, we will consider these insights."
1462,the completeness of knowledge graphs is a current challenge and applying rules can increase the completeness of a graph.,"the completeness of knowledge graphs is a current challenge, and applying rules can increase the completeness of a given knowledge graph."
1463,measuring engagement of a user is not a novelty and several studies have been going deeper into the topic.,measuring user engagement is not a novel concept and several studies have studied it in more detail.
1464,system sends (publishes through a topic) a message containing the player's state of mind predictions to a broker.,"the system sends (discloses to a broker), through topic, a message containing the state-of-mind prediction of the player."
1465,in the m-step using the latent variables the parameters are the maximized and feed again into the e-step.,the parameters are then maximized in the m-step using latent variables and fed back to the e-step by the latent variables.
1466,"we will be utilizing complex algorithms that capture intricate relationships between the independent variables and the outcome, and are empirically known to produce the most accurate predictions.","we will use an algorithm that captures intricate relationships between the independent variables and the outcomes, and that empirically has been shown to make the most accurate predictions."
1467,"if a restaurant is located in india, then it serves indian cuisine.","if a restaurant is in india, it will serve indian cuisine."
1468,"in every iteration for each training example we do forward propagation to find the predictions for the output values, then we calculate the prediction error (the difference of the actual and the predicted output), and we save it so that we can use it for the backward propagation, where we find the errors made in the hidden nodes.","when we perform forward propagation on each training instance, we first compute the distribution error (the difference between the actual output and predicted output), and save this result for use in backward propagation with error measurements for the hidden nodes."
1469,"this comes due to two reasons: first, it is very well-organized.",this may be due to two reasons: the first one is highly organized.
1470,"this would suggest that if there is a single positive tweet about the enterprise and a single tweet about the overall economic situation, the stock price goes up.","this suggests that if we have one positive tweet on our company, and one tweet on the overall economic situation, the price of the underlying company increases."
1471,"noticing the only observable gain was in computation time, the choice was made to stick to a relatively simple architecture.","for simplicity, the choice was made to stick with a relatively simple architecture, recognizing that the only observable gain in performance was in time."
1472,overview the hdl is the serum high density lipoprotein cholesterol.,hdl is an acronym for high density lipoprotein cholesterol.
1473,"unlike supervised learning, unsupervised data learning involves pattern recognition without the involvement of a target attribute.","in contrast to supervised learning, unsupervised data learning also performs pattern recognition without considering the target attribute."
1474,"the other attributes are supporting metadata, which can be used as well to decide to classify the mail as spam or ham.","additional attributes provide supporting metadata, which can also be used to decide whether email should be classified as spam or shabby."
1475,the other pitfall is that this approach combines two highly computational expensive techniques: evolutionary learning and nn.,another problem is that this approach involves two highly computationally costly techniques: evolutionary learning and nn.
1476,listening to the songs as an aggregated metric in order to describe how the user felt.,we used the listening sentiment as an aggregate metric to describe how users viewed songs.
1477,further assumptions are that unlimited trucks are available at every terminal and that the truck costs per route a t raa and t rsa include the costs for terminal operations and the cost of relocating the truck for the next operation.,further assumptions are made on the number of trucks available at each terminal and that the per route costs in t raa and t rsa comprise the cost of operating the terminal and the cost of relocating the truck for the following function.
1478,"lastly, a autoencoder with more layers was trained.","finally, we trained an autoencoder with multiple layers."
1479,thus using nonlinear approximation for the q-values will almost never converge.,this means that we will almost never converge with the nonlinear approximation of the q-values.
1480,the heuristic algorithm for the fortifying phase is based on the idea of reinforcing those borders with the highest presence of enemy troops.,the heuristic on the fortification phase is based on the idea of reinforcing the boundaries where the highest number of enemy troops is present.
1481,this decision rule is made to determine on a daily basis how to handle the incoming shipment requests in the coming period.,this setting determines how the incoming shipment requests should be handled in a daily timescale.
1482,regarding the optimization algorithm used in the method it seems that any kind of line search method manages to converge.,we note that any class of line search algorithms seems to converge to some state for the optimization problem under consideration.
1483,"without it the size of the output matrix of a layer would always be smaller than the input matrix of it, and we would lose valuable information from the edges of the pictures.",without it the output of a layer would always be smaller than the input matrix and we would lose much of the information that may be from the edges in the images.
1484,tiles that belong to the the center of the spiral (e.g.,tiles that are aligned with a spiral's centers (cf.
1485,the main idea of the extension to the general model is that there are more decision variables determining over which lane and with how many days delay a request should be shipped.,the essence of the extension to a general model is to add a couple of decision variables determining which lanes to route traffic and for how long a request should be delayed.
1486,"in the weekday model, trucks are only scheduled on a weekday basis.",this is the only scenario in which trucks are scheduled at weekdays.
1487,"after generating the game state trees of the selected games, feature extraction is conducted.","after the game state trees of the selected games have been generated, feature extraction proceeds."
1488,"in week w. this side of the inequality consists of a double sum over all lanes utilizing route a and all request that are shipped in week w of the decision variable whether to send request r using lane l slr,l times the volumetric weight of request r wr.",the inequality above consists in a double sum over all lanes utilizing route a and all request messages fts being sent in week w on the decision variable whether to dispatch r requests using lanes l or l times the volumetric weight of r requests received during week w.
1489,the relationship between music features and emotions of training data should be discovered.,we would like to discover a relationship between music features and the sentiments in training data.
1490,there are multiple reasons why a company or an organisation might outsource logistic operations to an lsp.,logistic operations outsourcing to an lsp can be an excellent decision for any company or organisation for multiple reasons.
1491,"the method is not yet applicable for real time image processing and video coloration in comparison to deoldify, which is one of the colorization methods compared by the authors.","the authors argue that, compared to deoldify, which is a colorization method in the current state, deoldify is not yet appropriate for real time image processing and video coloring."
1492,extracted rules from a graph can help to understand and identify underlying concepts and relations of entities or clusters.,the extracted rules from graphs can help to understand and elucidate the underlying concepts and relations between the entities or clusters.
1493,"the learning problem needs to be extended, in order to make relational representations useful.","to make relational representations useful, we have to extend the learning problem."
1494,the experiments regarding the td-learning algorithm focus on tuning the hyper-parameters.,the experiments with td-learning algorithms focus on tuning the hyper-parameters.
1495,variable importance measures the degree of association between the given predictor and the outcome variable.,the importance of a variable measures the degree of an association between a given predictor and its outcome variable.
1496,this assignment was conducted in python by utilizing the numpy and the gym library in a jupyter notebook.,this task was implemented in a jupyter notebook in python utilizing numpy and gym libraries.
1497,"however, this might be an interesting consideration also this could be discretised.","however, an interesting consideration might be that it could also be discretised."
1498,after that we show how we approached the research questions by explaining the way we use the machine learning algorithm in order to answer the research questions.,"next, we give an overview of our research question, and explain the steps we took in adopting the machine learning algorithm to answer the research question."
1499,the formula seen above is used during the tdlearning approach to adjust the weights inside the linear function to evaluate future states based on predicted features.,a linear function inside a linear function that measures future states based on the predicted features is trained using the formulas observed above in the tdlearning approach.
1500,"on the intensive care ward, the patients are constantly monitored, which means that several indicators such as blood pressure, heart rate, temperature, etc.","is monitored by the patients at the irs and this is reflected in some number of metrics, such as heart rate, temperature, etc."
1501,"of course, when we only consider dke course grades we could represent this in multi-instance or even attribute value.","obviously, if we only consider the grade of a dke course we could represent this in terms of multi-instance values or even attribute values."
1502,"the difference from the cosine metric was that here we had closer matches, thereby a lower number of accepted links here.","we observed that these metric was different from cosine metrics: here we had more matches, resulting in lower accepted relations."
1503,"complex model for the complex model, svm outperformed random forest by a small margin.",the svm outperformed the random forest by a small margin in terms of complexity for the polynomial model.
1504,"all the health characteristics used in the analysis are used as inputs and because of the approach, the techniques are suitable for clustering and association mining techniques.","the approach is intuitive, and since the health score can be used as input to our analysis, the techniques are suitable for clustering and association mining."
1505,"this is done by three well constructed levels of abstraction used for introduction of the problem, theoretical foundation and further experiments.","these examples include three well defined layers of abstraction used to introduce the problem, provide a theoretical grounding and guide further experiments."
1506,to evaluate our approach we do plan to have our prototype tested by a group of external testers.,we do plan to send out some external testers to run a tests on our prototype as part of an evaluation process of our approach.
1507,"to get the full picture about how the size of the different layers changes (height, width, depth (number of channels), we printed out the summary of the model.","we printed a summary of the model to give the full picture of how the different layers (lte height, std width, mtf) change with the channel size."
1508,the testing of vaccines is in the current time maybe the best example to illustrate the importance and necessity of the application of such methods and how heavily our society relies on them.,perhaps the best example to illustrate how important and necessary these methods are and how heavily our society depends on them is the vaccination experiment in current times.
1509,"we felt choosing an on-policy method would be beneficial, because we felt for a mountain car to go up on a hill is problem that needs more exploration from the agent, than just following the greedy policy.",we felt the advantage of choosing the on policy method lies in the fact that the problem of forcing an autonomous car to follow a greedy policy is one that needs to be explored by the agent rather than just following the greedy policy.
1510,our motivation with the project was to build a recommender system that relies mainly only on the emotional states or emotional state changes of its users to make recommendations.,our motivation for the current project is to construct a recommender system mainly depending on the emotional state or state change of the user in order to suggest recommendations.
1511,"to evaluate how well the trained model performs in this regime, semantic similarity between input sentences and the respective output sentences will be measured.",the semantic similarity between the input sentences and the output sentences serves as a threshold to test the performance of the trained model in this regime.
1512,"our model could be improved to fit better to this application with more convolutional layers and bigger channel sizes to be able to capture more, and more complex features of the pictures.","to capture more complex features of the image, one could try to improve our model to better fit this application, with more convolutional layers and larger channel sizes."
1513,"in addition to that, our model will need as many features to capture the emotion of the songs as possible.",we further assume that our model needs to extract as many features as possible from the song lyrics to capture the emotion.
1514,for the visualization of our state-space we used the heatmap plot from the seaborn package.,we used the heatmap plot from seaborn package to visualize our state space.
1515,the pmemo dataset is a song-level dataset created primarily for helping research in music emotion recognition.,pmemo is a song-level dataset initially created to aid the music emotion recognition research.
1516,clearly separated entries or strings are easier to process during the linking and the querying in the later process.,it is easier for the link process and later on for queryers to process clearly separable entries or strings.
1517,"furthermore, we were able to move the face recognition entirely onto the client side.","furthermore, we were able to shift face recognition totally to the client side."
1518,"to understand the predicted results, lime and shap were utilised for identifying health metrics that played a key role in class prediction with svms.","lime and shap used health metrics to predict classes, which played a central role in class prediction using svms."
1519,transportation can be divided into two parts: human transportation and freight transportation.,there are two types of transport: human transportation and freight transportation.
1520,colorization of separate instances is easier without the cluttered background of the whole image.,having the image as a background blur makes the colorization of separate instances more difficult.
1521,"subsequently, there is enough supporting evidence for all the conclusions and statements that have been made.",this would give a sufficient proof to support all the conclusions and statements that were made.
1522,next step is to build a graph depicting the score of the selected metric against the various number of features explored by the rfe.,"next, we build a plot showing how scores of the selected metric perform over different number of feature classes explored by rfes."
1523,"hence, before building the predictive models missing values are imputed.",we then smudge the missing values before modeling the predictive model.
1524,it predicts the logit-the natural logarithm of an odds ratio of the outcome variable from the input features.,it predicts a logit-the natural logarithm of the out-performance probability for a given input feature.
1525,columns containing health status classes are not available and thus have to be created.,"we don't have the columns to collect health status classes, and thus have to create them."
1526,"the sparql queries for counting distinct subject-object pairs for support, body coverage, and head coverage can be found in appendix a.","an appendix a has sparql queries for counting the number of different subjects-object pairs for support, body, and head coverage."
1527,further insight was gained by directly computing the ycbcr channels of original rgb images and the predicted channels.,the ycbcr channel estimation using direct computation of the original rgb images and the prediction channel has also been useful for further insight.
1528,"in view of the interesting results obtained in this research and the assumptions imposed to model the problem, there is great potential for further research.","there is great potential for further research in this area, based both on the interesting results obtained by this research and the assumptions made in the model formulated to model this problem."
1529,"and if we use more samples, the length is lower, and the result is more accurate.","however, if we use more samples the time length drops and the result becomes more accurate."
1530,"this research question aims at identifying additional physical activity patterns, that are potentially not known to the domain experts.",this research challenge is to identify additional phy activity patterns that may not be well known to domain experts.
1531,the structure greatly improves readability by using a key idea per paragraph and by subdividing the text successfully using sections and subsections.,"our structure includes the idea of the key idea per paragraph, and effectively makes use of subsections and sections to improve readability."
1532,for being able to reproduce the experiments one to one we want to ask which programming language was used?,"we would like to ask how to replicate the experiments one-by-one, and to which programming language the experiment has been run?"
1533,due to the quality of these results we chose to use our logistic regression model in the following.,we have chosen to apply our logistic regression model in the following result because of the quality of the derived results.
1534,"unfortunately, the reason for this trend could not be found.","unfortunately, it is impossible to identify the reason for this trend."
1535,the second approach this paper will take is a graph theory approach.,the second approach that is used in this paper is a graph theoretic approach.
1536,this broker will then redistributes this message to every system that needs it (i.e.,"this broker then redistributes this message to any system that needs it (that is, it does not consider transmission of sensitive messages)."
1537,"for the distribution heuristic, a table is created with priorities based on the number of players.",the number of players is used to create a table in which the priorities are determined by a distribution heuristic.
1538,each set is a patient and each data instance is measurement record.,"each patient instance serves as a measurement record, and each data instance represents a set of measurements."
1539,these features add up to an easy to read and follow paper in terms of language.,the combination of these features makes the paper an easy-to-read and follow piece.
1540,the disadvantage of this method is that it has a long learning process.,"however, the disadvantages of this method are that the learning process is very time consuming."
1541,"in addition, we do not require any footage of the user to be uploaded to our server, which is encountered as a huge advantage in terms of privacy protection.","in addition, a crucial advantage with respect to data privacy is that our server does not require the users to upload their video footage."
1542,"but, the model implicitly assumes linearity between the dependent and the independent variables and it can perform poorly when there is a non-linear relationship between the predictors and the outcome.","however, the model implicitly considers linearity between dependency and independent variables, and it can perform poorly when there is a non-linearity between predictors and the outcomes."
1543,"we found this assignment easier to implement than the previous assignments, and with less workload (especially compared to the auto-encoder assignment).",we found this assignment to be simpler than any of the preceding assignments and to require less effort (particularly compared with the auto-encoder assignment).
1544,"throughout this report, we will be addressing and covering them, trying to obtain meaningful answers.",our goal throughout this paper is to attempt to answer those questions in a meaningful manner.
1545,"then, reward can be tuned for the whole game, instead of just the battle phase.","then, instead of simply tuning the payoffs for the combat phase, one can tune the payoffs over the whole game."
1546,"we are not going to replicate the assignment text here, as requested by kurt.","since kurt asked, we will not reproduce the assignment text here, we are going to present it here only."
1547,it calculates the distance from a new data point to its k nearest data points.,computes the distance from a new data point to its k nearest data points.
1548,"the approach for this task was the following (based on the example schema:servescuisine, see the used queries in appendix c)","this was performed using the approach specified in (using schema:servescuisine, see the used query sets in appendix c)."
1549,"in our case, this method is not suitable, as we aim to change the mood of the user for the better.",the method we have chosen here is unsuitable as we try to change a user s mood for the better.
1550,"in this project, random grid search was employed to discover a satisfactory combination of parameters.",this project proposed a random grid search method for finding a satisfactory parameter combination.
1551,even for a relatively large number of initializations (e.g.,"nevertheless, if the number of initializations is small (ie."
1552,multinomial logistic regression deals with the problems where the outcome variable can have three or more possible values.,multinomial logistic regression solves a problem in which the outcome variable has three or more possible values.
1553,"after some initial trials, the algorithm was quite easy to implement.",the algorithm was fairly simple to implement after a few initial tests.
1554,"when trying to use our model with a higher number of strides in our convolutional layer or our maxpooling layer, the size of the output matrices would differ from the original, and would not be comparable.","however, the output matrices would have very different sizes from the original and would not compare well to the ones used when we try to perform a higher number of strides on either our convolutional layer or our maxpooling layer."
1555,due to time constraints and limitations in our data we found that we were not able to answer all research questions to the greatest extent possible.,we were not able to address all research questions to the best of our ability due to time constraints and data limitations.
1556,in this section the rationale of learning new rules will be explained and also the performances of those rule will be discussed.,"in this section, we explain the motivation of learning new rules, and also give performances for these rules."
1557,"creswell, antonia, and anil anthony bharath.","crswell, antoline, and anil anthi bharath."
1558,in conclusion this section shows that under certain conditions the two types of uncertainties are well separated from one another.,"finally, this section concludes by stating that under some conditions, the two types of uncertainty separation are well separated from one another."
1559,the amount of missing values per feature is low for most of them.,most of them have low per-feature missing values.
1560,bars colored green indicate a positive impact on the class prediction of the outcome variable and red has a negative impact on the class prediction.,"the green bars depict positive bias of the outcome variable, the red bars depict the negative bias of the class prediction."
1561,this ratio represents the cost of sending request r externally for every unit of volumetric weight that the request has.,this ratio represents the cost of outsourced transmission of r requests for every unit of volumetric weight the request takes.
1562,"one of the question that arises with this is, how do we consider this into our recommendation system?","this raises several questions, one of which is how to incorporate the latter in our recommendation system."
1563,"in order to check the structure of our data with shex, we need two components.",we need two components in order to check the structure of our data with shex.
1564,"shen, tianxiao, jonas mueller, regina barzilay, and tommi jaakkola.","she, tianxiao, jonas mueller, regina barzilay, and tommi jaakkola."
1565,"when trying out the algorithm for the multi-speaker lip to speech case, the authors stated that no previous lip to speech method deals with the multispeaker task, therefore they do not compare their results with those.","the authors stated that no previous lip-to-speech methods had handled the multispeech lip-to-speech case, and thus no other lip-to-speech algorithms have addressed this task."
1566,this means that the data in the data set needs to be labeled.,this indicates that labeling the datasets is needed to label the data in the datasets in question.
1567,"from this bar chart, it can be seen that the decision rule performs the best with zero days delay allowance on small instance sizes.","we can see that the decision rule with zero delays performs best in this bar graph, for small instance sizes."
1568,"this assumption is made to avoid complicated settings, where the shipment of one request cannot be done on the same day it arrives at the lsp.",this assumption is used to avoid tangled setups where sending one request would not be possible until it arrives at the lsp.
1569,one aspect that stood out is that every tester expressed that the recommender system displayed at least one song which was new to the user.,a particular aspect that struck us was that every test subject stated that at least one song had been recommended by the recommender system that was new to her.
1570,the weekday is sampled from a probability distribution over the weekdays.,the weekday sampling corresponds to sampling a weekly probability distribution over the weekdays.
1571,the following presents several ways in which different researchers tried to define user engagement and how they proceeded to attempt to quantify it.,there are various ways in which different researchers have attempted to define user engagement and have subsequently attempted to quantify it.
1572,results people on lipid modifying or blood pressure lowering medication were more likely to have impaired glucose tolerance or diabetes.,result shows that individuals on cholesterol or blood pressure lowering medications tend to be also affected by impaired glucose tolerance or diabetes.
1573,"with a delay allowance of two days, even higher savings are possible.",even larger savings can be achieved if the delay allowance is two days.
1574,the head of the rule is the part that will derive based on the body.,the head of a rule is the part which derives from the body.
1575,"complex model for the complex model, random forest perform better compared to svm.",random forest performance is better than svm for the complexity model.
1576,"unfortunately, due the time limitations of the project it was decided to not be further explore the option of newton type methods and conduct the experiments using the other optimization algorithms.","unfortunately, the alternative optimization algorithms used were decided to not further explore the newton s option due to the time constraints, and instead perform experiments with the other optimization algorithms."
1577,"this happens because the maxpooling has the effect of blurring the details, but in our case the details play a really important role in colorization, therefore without maxpooling our network performs better.","this is because maxpooling has the effect of blurring the details, but the details in our work are the most crucial for our color matching; therefore, our network performs better without maxpooling."
1578,"further, they clearly state where they draw results from and the line of reasoning is clear.","in addition, we clearly state where the results come from and outline the resulting reasoning line."
1579,"contrary to the vanilla implementation of decision trees, not all features are considered instead, a random subset of the considered features when growing the tree.","contrary to the vanilla decision tree implementation, there is no need to consider all features, instead consider a random subset of the considered features as they grow the tree."
1580,"results generally, the more complex models performed better when it comes to this health metric.",results from this health metric typically suggest that more complex models perform better.
1581,"human evaluation on a reliable scale is to expensive for the scope of this work and will only be explored on a small scale, if the resources are available.","the cost of human validation at a reliable scale is too expensive for the scope of this paper, and will only be explored at a fine scale, provided the resources are available."
1582,the current algorithms can also be extended to handle the other remaining phases of the game.,we can also extend the current algorithms to handle the other remaining phases in the game.
1583,"the general performance of the colouring network can generally seen as colouring larger areas such as the sky, the sea or plane background in a single colour.","it can be generalized to consider that the larger landscapes such as sky, sea or plane background colors give a good performance for the colouring network."
1584,"in order to compare the algorithms, two stopping criteria were implemented.",two stopping criteria have been implemented to compare the algorithms.
1585,"also the probability without knowing whether team a plays at home or not is between the two conditional probabilities of team a playing at home and playing away from home, both against team b and team c.",we will also calculate the gap between the conditional probability of team a playing at home and playing away against team b and team c without knowing if team a is playing at home or not.
1586,this lack of direct accessibility of the mle yields additional uncertainty that needs to be considered.,this lack of direct access to the mle induces additional uncertainty that needs to be taken into account.
1587,"a higher value therefore indicates a more defensive play-style, as the bot will only attack if the predicted win-chance is above the threshold.",higher values indicate defensive play-style since the bot will attack when the predicted winning probability is above some threshold.
1588,our aim with the classes is assigning a health status to every participant of the study.,the idea behind the classifiers is to assign a health status to each participant in the study.
1589,"to explain how a new problem instance is re-sampled from the data set, the process of adding one shipment request to the new problem instance is described.",we explain the procedure for inserting a single shipment request to a new problem instance and how it is re-sampled from the data set.
1590,"in these cases it is important to have domain knowledge, otherwise many false facts and relations can be created.",domain knowledge is important in such situations because otherwise many false facts and relations can be generated.
1591,this has been previously covered by detecting static emotions from the users and taking these into account to make the song recommendation.,the previous work has focused on detecting the static emotions of the users and taking these into account when performing song recommendation.
1592,representing a lot of dimensions and identifying the hyper plane remains an impossible task.,it remains an intractable task to represent many dimensions and to distinguish the hyperplane.
1593,"t aa,w is the one-week version of ta discussed before.","the one-week version of ta discussed above is termed as ta,w."
1594,"at the same time, we get data records of the same size.","as one step, we extract data records of similar size."
1595,"however, there is not a strict m-to-n-relationship which makes these tables necessary.","m-to-n-relation does not enforce strict m-to-n-rank relation, however."
1596,program code would need to be adjusted for the new data structure.,the new data structure would require a change of program code.
1597,"for the confounders and the health metrics instead, we have to deal with missing values.",we want to deal with the missing values of the confounders and the health metrics instead.
1598,"with the release of new content, the amount of options for the user to choose only gets bigger.","when new content is released, the amount of choice available to users grows only further and further."
1599,returns the first one that meets the resource constraint as the optimal path.,returns as optimal the first path that satisfies the resource constraint.
1600,"this communication between the two sub-systems was done using an mqtt protocol, allowing to run the sub-systems in separate machines.","we used a mqtt protocol for communication between the two subsystems, allowing the subsystems to be ran on separate machines."
1601,"for each of the eight training samples, the output of each neuron for each layer is shown.",we show the output of each layer for each neuron in each of the eight training samples.
1602,"to understand the plot, red indicates the features having a positive impact on the prediction, and those features having a negative impact on prediction are indicated in blue.",we show that the features having positive predictive power are denoted by red and features with negative prediction power are denoted by blue in order to visualize the plot.
1603,"since uncertain rules usually do not create true facts exclusively (otherwise they would be called certain rules), there will be wrong relations created too.",we will find that this also will produce incorrect relations as uncertain rules generally don't always create true facts (otherwise they would be called certain rules).
1604,under the assumption that the initial points are drawn i.i.d.,assuming that the startpoints are drawn with i.
1605,the possible reason for these is less and less higher number item sets can reach the higher thresholds compared to lower number item sets.,the reason could be that the thresholds for higher number of item sets can not be reached with larger number of item sets as compared to the lower number of item sets.
1606,"similar to the force plot, the summary plot indicates the top features impacting the prediction by the model.",the summary plot reveals top features that impact the predictions of the model similarly to the power plot.
1607,the wrapper is used to build a model to measure variable importance and rank predictors from most to least important.,a wrapper is used to construct the a model measuring variable importance and rank prediction using a weighted rank order from most important to least important.
1608,"we can see that the two curves start with a wide gap between them, but from around the fourth epoch their gap is remarkably reduced, the validation error comes really close to the training error.","we can see that the two curves start with a large gap between them, but they begin to close that gap after the fourth epoch, and the validation error comes out quite close to the training error."
1609,"to overcome this, we looked up the source code of the environment, which helped us understand how the environment works and how to interact with it.",the first step is to look up the source code of the environment to get a better understanding of how the environment works and how to interact with it.
1610,the left one showing an original image and the right one the predicted version.,the upper left part shows the actual image and the lower right the predicted one.
1611,the paper guides the audience through the proposed lip-to-speech end-to-end method and elaborates on most concepts used in the system.,"this paper introduces the end-to-end lip-tabbing techniques proposed in the paper, and provides an in-depth understanding of the major components of the system."
1612,in the following g will denote either of the two densities.,we may label any of these two densities with g in the following.
1613,"in particular, this includes obtaining an overview of the current state of research, similar projects and usable resources.","this includes, among other things, getting an overview of the current state of the research, similar work, and how to access useful resources."
1614,"however this is a pleasant result, it comes with certain pitfalls.","nevertheless, while this is a pleasant result, it comes with a few pitfalls."
1615,the lsp could use this information to schedule the same number of trucks on the same routes for the coming period and hope for lower costs.,lsps could use this information to schedule identical number of trucks into the same areas for the coming week and hope for lower input costs.
1616,"a majority of people in our society are spending a great part of the day in a sitting position-while driving a car, at work or when watching tv.","nowadays, the majority of the population in our society spends a considerable part of the day in a sitting position-while driving a car, at work or watching tv."
1617,"discussion regarding to rule mining, there is often a trade off between coverage and correctness.",there is often a trade-off between coverage and correctness in discussion of rule mining.
1618,these can be loaded into the program to skip the training part and see the outcome of our model in a faster way.,these are fast add-ons that can be loaded into the program to skip the training part and see the output of our model.
1619,for each cuisine we get if it is mostly vegetarian or not.,we get a reaction in terms of whether it is predominantly vegetarian or not for each dish.
1620,from this reasoning we can understand why storing all the data in one table would result in combinatorial explosion.,"we can understand, based on this reasoning, why consolidating all records into a single table leads to a combinatorial explosion."
1621,"the explanation of certain more complex ideas, and most of the numerical results are separated from the body of the text, this helps to keep the of attention of the reader.",these steps keep the reader attention focused on some more complicated concepts and most numerical results are written separately from the rest of the text.
1622,this could be expected since the conjugate gradient method for nonlinear function is quite sensitive to its hyper-parameters.,this is to be expected since the conjugate gradient method for the nonlinear function is quite sensitive to the hyper-parameter.
1623,"as for aggregation of the predicted tweet sentiments, we assign the average of the sentiments predicted for all of the collected tweets about each movie in our dataset.",we also aggregate the sentiment sentiments predicted by our dataset by assigning average sentiments predicted by each movie title to each of the collected tweets for that movie.
1624,"this is because we need to use multi-table representation of the problem, since it involves (n:m) relations.","this is because since (n:m) relations are involved in this problem, we need to turn to a multi-table representation of it."
1625,"here, we will give a short summary of each of these in turn, before drawing a conclusion.","we shall go through all of these in turn, and state a conclusion here."
1626,"first, we had to deal with the continuous state-space, for which we discretized the continuous statespace variables, the position and the velocity of the car.","initially, we consider a continuous state-space of the vehicle in which we discretize the set of continuous state-space variables the vehicle position and the velocity."
1627,it is to be noted that lime explanation is valid only in the neighborhood of the reference individual instance and cannot be extrapolated for the entire dataset.,"we note that lime explication only holds for the neighborhood of a reference instance, and can not be extrapolated to the full dataset."
1628,the value functions are just a big black blob and the argmax visualization shows much random noise.,the argmax visualization shows much of the random noise as a thick black star and the value functions as a small black blob.
1629,rationale there are multiple ways rules are used with respect to knowledge graphs.,there is a variety of ways in which rules are used in connection with knowledge graphs.
1630,there are numerous settings that can be changed by the user but we set it up such that it just works when the user starts the program.,"the user can modify a number of settings to tailor the behavior, but we have made it so that it is only responsive when the user starts the program."
1631,"going one representational layer down to binary representation, one could store the occurrence of a word, so checking if the word exists in the mail.","one could store the occurrence of a word from one representation layer down to a binary representation, and check whether a word occurs in an email."
1632,"garrett bingham, william macke, and risto miikkulainen.","garret bingham, william macke and risto miikkulainen."
1633,"however, we can often observe that the opposite shows to be true.","however, we can often observe that the converse shows to be true as well."
1634,the constraint requires either both of the truck variables to be set to one or one of them to be set to two to meet the constraint.,a constraint requires that either all the truck variables either be zero or at most one of them be set to two to meet the constraint.
1635,"from comparing our predictions with the output values we can see our model is working really well, it could classify each node correctly with high confidence.","we can see that our model performs well, and it can classify every node correctly with high confidence, if we compare our predictions with the input values."
1636,"increasing the representation to relational representation is not necessary, because only one table is used here and no n:m relationships exist.","we don't have to extend the representation to relational representation, because we use only a single table and no n:m relation."
1637,a main advantage of the use of hierarchical clustering algorithms is the visualization capability that shows how much objects in the data set are similar one another.,the main advantage of using hierarchical clustering algorithms is the ability to visualize how much of a collection of objects in the data set are similar to one another.
1638,"instead of asking the user to report the current mood to the service, emotion recognition using facial expressions is also used for mood detection.","facial expression recognition is also used for mood detection, instead of requiring users to upload a state of mind to the service."
1639,these values are calculated by estimates like the expected troop loss and result in a simulated state value which is in turn weighted by the estimated win-chance.,"these values are mapped to estimates like expected losses of troops, and then they lead to a simulated state value which is weighted with estimates of the winning probabilities."
1640,"the above setup can be extended to several stocks, where a hypothesis is learnt for each stock, based on the same dataset of tweets, as whether a tweet concerns a stock or not is queried.","for instance, we might consider several stocks and learn hypothesis for each stock from the same dataset of tweets, thereby answering the question whether a tweet should be written about a particular stock or not."
1641,"as expected, the hessian matrix was more often than not a singular matrix meaning the inverse of the matrix did not exist.","as expected, this corresponds to the fact that the hessian matrix is often a singular matrix, meaning that the matrix is a singular function."
1642,the two main modules of the system are the face encoder and the speech decoder.,"the system consists of two core modules, the face encoder and the speech decoder."
1643,"this, combined with the less complex approximation of states due to the linear evaluation function gives the bot a less detailed understanding of the game, making it easier for human players or more advanced bots to out-think strategies used in simple td-lambda and leverage that predictability to win against the td-bot rather easily.","this, together with the less complicated approximation of states due to the linear evaluation function, offers a more sophisticated understanding of the game, and enables some relatively simple strategies for human players and advanced bots to out-compete strategies employed in simpler td-lambda with much easier predictability in order to defeat td-bot."
1644,especially the utilization of the lane setup of the graph by the decision rule could improve the performance of the decision rule further.,"in particular, the decisions of a decision rule may lead to more efficient utilization of lane setup in the graph."
1645,the decision tree and logistic regression models have very similar performance scores.,the decision tree and logistic regression models have excellent performance matching scores.
1646,we then plotted the evolution of the mean squared errors while increasing the number of epochs.,we then plot the evolution of mean squared error with increasing number of epochs.
1647,running the notebook loads the environment and runs the implemented reinforcement learning algorithm.,the runset loads the environment and executes the implemented reinforcement learning algorithm.
1648,we have decided to use the attribute value representation for this learning problem.,we decided to treat this learning problem as an attribute value representation.
1649,research alternative activation functions for neuron activation in neural networks (nn).,more research is needed on alternative activation functions of neural networks (nn).
1650,"the focus will be on obscurity, tension and length of the principal variation and compared with depth.","we focus on obscurity, tension, and fundamental variation lengths, and compare these with depth."
1651,cost-complexity is a technique where the weakest links or nodes in the tree are pruned by balancing the prediction accuracy to size of the tree.,cost-complexity is a technique that takes into account the trade-off between prediction accuracy and tree size by pruning the weakest links or nodes in a tree.
1652,"tomihisa welsh, michael ashikhmin, and klaus mueller.","tomihisa welsh, michael ashikhmin, klaus meller."
1653,in general the authors do a good job in balancing the detailed math and explaining the concept of their approach.,"generally, the authors manage to balance the complexity of the mathematics and the ease of understanding their approach."
1654,"with the release of new content, the amount of options for the user to choose only gets bigger.","while new content is released, the number of choices users have to make is only increasing."
1655,"the same goes in the opposite case: if the agent has a negative velocity, he will always accelerate negatively.","the converse is true: if an agent has negative velocity, then it will always accelerate negatively."
1656,it is worth noting that the models used in this paper (daaes) have been applied in other settings such as image processing previously (c.f.,it is worth noting that models developed in this paper (the daaes) have also been used in other settings such as image processing (cf.
1657,"the drawback of this approach is that it is biased towards variables with high categories and with correlated features, strong features can end up with low scores.",the downside of this approach is that it tends to bias the dataset towards variables with high class scores and it may fail to identify strongly correlated features resulting in a low score.
1658,"on the other hand, we can also recognize that the highest q-values belong to the states where we are on top of either of the hills, which is also easy to see, since from here with big velocity we can reach states that are bringing us a lot closer to the optimal value of our function.","it is also easy to observe that in either case, the states where we are in the top of any hill can be seen as being the states which bring us closer to the optimal values of our function."
1659,"first, the theoretical background from optimization theory and statistical inference is introduced.",we begin by providing some background in optimization theory and statistical inference.
1660,"this can be calculated using monte carlo experiments, where data is re-sampled often (i.e.","it can be obtained from monte carlo experiments, where data are re-sampled often (i."
1661,the frequency of events where the state is misleading to the ai can be described as obscurity.,the intensity of obscurity can be characterized by the frequency of states which are misleading to the ai.
1662,"we removed all irrelevant symbols and emoticons from the data, along with every stopword according to the english stopword collection of the nltk library.","the data set also includes every stopword provided by the english stopword collection, from which we removed irrelevant symbols and emoticons."
1663,"however, probably due to the page restriction the paper lacks a bit of explanation for neural networks and an intuitive explanation of activation functions.","nevertheless, lacks a bit in the way of a formal explanation of neural network based applications and an intuitive explanation of function activation, probably due to the pagination constraint of the paper."
1664,then we group the result on the ingredient and the cuisine and count how much each ingredient is used for each cuisine.,"we then cluster the results according to an ingredient and a cuisine, and count how many dishes can be made by each ingredient."
1665,"because of this, we decided in favor of the use of natural language generation models.",thus we opted to use natural language generation models instead of neural network models.
1666,these algorithms provide clusters with each cluster comprised of a number of similar objects grouped together as output.,"these algorithms produce clusters with each cluster consists of a collection of closely related objects, which are then grouped together for processing."
1667,"rcsp, one can shrink down the dimension of the relevant variables on the edges.","for instance, the dimension of the relevant variables of a graph at an edge can be decreased by rcsp."
1668,the starting points of the agent in each episode) correspond to lower expected rewards (e.g.,"as we can see, lower expected rewards correspond to lower starting points for agents in each episode."
1669,"if there are too few iterations, it will fail, so the required running time is longer.","if there are too few iterations, the asynchronous process fails, and hence the required running time is larger."
1670,this is done as it is common that parameters with decent performance are close to parameters with even better performance.,this is justified as it is common to find that the parameters with the best performance are close to those that have even better performance.
1671,how to match the musical content with the emotional state of the user?,how does music influence users emotional state?
1672,"in this section, we cover the interpretation of the results obtained from shap.","in this section, we discuss how the results obtained from shap are understood."
1673,"missing value imputation missing data can reduce the statistical power of a study and can produce biased estimates, leading to invalid conclusions.","missing value imputation missing data can decrease statistical power of a study and lead to biased estimates, leading to biased results."
1674,shap shapley additive explanations (shap) is a game theoretic approach to explain the output of any machine learning model.,shapley additive explanations (shap) is a game-theoretic approach to explaining output from any machine learning model.
1675,"on the other hand, choosing too many buckets and thus allowing for many states, q-learning will struggle to learn something meaning full if it is not provided with many more episodes to learn.","q-learning, on the other hand, fails to learn a meaningful final episode if it is not presented with a very large number of buckets and hence has many states."
1676,"of all predictions) happy, neutral and sad, the relative amount of detections per group is very similar and comparable.","the detection patterns per group are very similar and compare well with the other predictions (happy, neutral and sad)."
1677,to counteract this prob here f(xt) is the vector of all features for the current state.,"hence, the vector of all features in the current state is the vector of all edges to counteract the prob and there is only one f(xt)."
1678,"tables can be used to represent the relationship between tweets, they can contain information about the author (e.g.","for instance, if a table can represent relations between tweets, it may have information on the authors (eg."
1679,"however, if we look at error messages we observe that eight errors are found.","we observe, however, that eight errors are inferred from our error messages."
1680,"of the gathered tweets one might get the following attributes: time, author, content.","the attributes one can obtain from the collected tweets are as follows: time, author, content."
1681,"also, need to be adapted to video colorization, and the performance needs to be improved.",video coloring methods also require additional adaptation and performance improvement.
1682,"we also knew we were only going to be able to get a limited number of testers, and mf models are generally considered to be better suited to deal with sparse data.",it is well known that we only have a limited number of test cases available and that mf models generally tend to better cope with sparse data.
1683,"on the other side, if the participant shows physical activity through the other three activity measures, he will be assign to acceptable.","if a participant meets the physical activity demands via the other three activity measures, we assign it to acceptable."
1684,gini index which indicates of how well a node separated the classes.,gini measures the strength of the separation of a class node.
1685,this is due to the higher complexity of the model and using more features.,this is due to the fact that the model complexity is higher and more features are utilized.
1686,overview this health metric is concerned with the type of diabetes for a given patient.,"we compare the age of a given patient with the type of diabetes, presenting a health metric overview."
1687,"furthermore, we were interested in how good the model performs visually already.","furthermore, we were particularly interested in the visually pleasing behaviour of the model."
1688,"to achieve that, we have performed several experiments by changing: the algorithm type and the parameters alpha, gamma and number of episodes to train.","to do so, we have experimented with several different setting values for parameters such as the algorithm type, alpha, gamma, and the number of episode training runs."
1689,"moreover, research has suggested that there is an association between sitting time and mortality from all causes and cardiovascular diseases, independent of leisure time physical activity.","furthermore, research indicates that the mortality rate of all causes and cardiovascular events depend on the length of sitting time, independent of the leisure time physical activity."
1690,"generally, they use certain similarity measures to select users (or items) that are similar to the active user (or the preference of).",they usually use some similarity measure to choose which users (or items) are the most similar to some active users (or preferences of).
1691,"the model is an unsupervised learning algorithm, that is trained end-to-end by minimizing the error between the ground-truth and the generated speech representations.","our model is a unsupervised-learning algorithm that trains the candidate model end-to-end, with the goal of minimizing the discrimination error between ground-truth and the generated speech representations."
1692,"instead of just looking at quantitative scores, the authors also let the users decide on the best results.",the authors also allowed the users to be responsible for deciding which is best performance instead of simply looking at the quantitative scores.
1693,in general lower values for the win-chance threshold seem to result in a lower win-rate in conjunction with a higher number of turns needed to win.,"lower values of the winning chance threshold usually generate lower win probability values, in conjunction with the higher number of turns needed to win a turn."
1694,"besides these given reasons, they have touched on practical and research-related purposes to solve this problem.","besides the reasons above, the motivation for such an assessment has touched on practical and research-related purposes."
1695,"concluding, amongst the three considered methods, the wald method is the only one which can be usefully applied in the setting of multiple maxima.","finally, it is worth remarking that the wald method is the only one that can be useful for multimax bounded optimization among the three considered methods."
1696,"as in tools, opencv stands out as the most used library for face recognition in almost every visited paper and researched project with similar characteristics.","since almost every visited paper and researched project is focused on face recognition, opencv emerges as the most commonly used library among face recognition tools."
1697,"expert knowledge, statistical evidence, or even purely random guessing, can be used to tackle this problem.","this problem can be approached by applying expert information, statistical proofs, or even purely random guesses."
1698,the yellow tiles represent the aforementioned states that were never reached by the agent during training.,the yellow tiles represent states that were not reached by the agent during training.
1699,"a very important point that brings everyone together is that almost all of the testers agreed that music has an impact on their mood and emotion, as well as the possibility that a certain song can change the state of mind or support the current mood.","another interesting fact that unites all testers is the general agreement that music is an influence on their moods and emotions, and the possibility of a particular song triggering a change in mood or energizing a current mood."
1700,"this works probably already good for private applications, but for professional applications one may need an optimized model with an improved object detection method.","this is probably already good for private applications, however for professional applications one may need to develop and optimize the model in conjunction with an improved object detection method."
1701,"in many adversarial board games, certain positions in the playing order have an advantage or disadvantage.",most adversarial board games have some type of advantage or disadvantage of certain positions of the playing order.
1702,"after identifying the optimal number of a subset of features, we explore the outcome of the algorithm to specify the particular features of the subset and their importance.","when the optimal number of features is known, we explore the algorithmic choices to specify the features and their importance."
1703,work with a multi-dimensional array containing all necessary information of the nodes.,work with a multidimensional vector containing all relevant information about the nodes.
1704,the third approach using statistical information of the past helps us to investigate if a prediction model based on this information can give good result in predicting the future result.,our third approach uses the statistical information from the past to determine whether prediction based on this information is good for the prediction of future performances.
1705,executing well in that regard also results in an increased number of bonus troops at the distribution phase of the following turn.,a good execution in this direction also means that more troops are promoted to the distribution phase in the corresponding turn.
1706,is chosen to be the estimate which is used for calculation of cis.,is chosen as the estimated which will be used in the computation of cis.
1707,we recommend boolean because the major information about a email being spam is contained in the body text and other mostly text based elements like links and email addresses.,we choose boolean because the majority of the information for an email being spam resides in the body text and other non-text based features like links and email addresses.
1708,"following this, we reiterate the rfe procedure to explore the updated subset.",we can now repeat rfe on the refreshed subset to explore.
1709,"as mentioned earlier, the original database consists of several tables; in order to create a single table of normalized values, several operations were performed.",the original database consists of different tables; several operations were performed to construct a single regularized table from the other tables as mentioned earlier.
1710,"the sign of the constraint is inequality, as the truck decision variables are integer valued.","the sign of a constraint is inequality, because the decision variables of the truck are integer variables."
1711,"adapting the number of epochs according to the validation curves a more suitable number of epochs was chosen, yielding more appropriate results.",it was found that choosing a larger number of epochs in order to fit the validation curves yields more suitable results.
1712,"since we aim to provide the domain experts with highly accurate models and well interpretable insights, we have decided to approach these goals in multiple steps.","we set out to tackle these challenges in a multiphase approach, providing domain-specific experts with highly accurate models and well interpretable insights."
1713,in this paper we investigate the relation between gross earnings of a movie and its early audience reactions.,"in this paper, we investigate the relationship between the movies total earnings and early audience reaction."
1714,recursive feature elimination is an algorithm that selects the best feature subset by starting from the full training set and removing features one by one until the desired number remains.,recursive feature deletion is a classification algorithm that selects the best feature subset from a full training set and removes features one by one until the desired number remains.
1715,it might be seen as an approximation to the actually used network.,it might be seen as an approximation of the actual used network.
1716,"as a result, in settings where multiple maxima exist, this too will be a collection of regions and thus will note be valuable in terms of parameter estimation.","this also constitutes a set of regions and hence will be valuable for parameter estimation in settings with multiple maxima, as well."
1717,"currently, the model is capable of coloring only larger homogeneous areas, as the right image shows.","the right figure shows that currently, the model is able to color only large homogeneous regions."
1718,the best feature subset for the model was selected using recursive feature elimination.,recursive feature elimination was employed to determine the best feature subset to populate the model.
1719,this representation is the most basic or low level representation in the hierarchy and is only able to have a boolean as value for the attributes.,this representation is the most primitive or low level representation in the hierarchy and only has boolean values as attributes.
1720,overview this health metric describes the body-mass index for a given patient.,we generalize this health score to the weight index of a given patient.
1721,the output of the nn should be the cbcr components of the pictures.,this suggests that the cbcr components of the images should be outputs to the nn.
1722,a straightforward way to perform hyperparameter tuning is to train a model for each available combination of parameters and evaluate performance.,"the strategy of tuning hyperparameters for each available combination of parameters is straightforward, with a model training step and an evaluation step."
1723,"when some team members are unable to work on the project, we need to inform the supervisor and coordinator in time to make adjustments.","if some team members are unable to contribute to a project, we need to tell the manager and coordinator in advance in order to make modifications."
1724,"however, a agent might choose an option that will prove itself to be a poor decision subsequently, compared to an alternative.","however, an agent might choose a subset of the alternatives and discover that the last decision it made turns out to be a bad one."
1725,"models are identified by an id, which will be explained in detail per experiment.",models are identified by an i d which is explained in detail per experiment.
1726,"hence, in this scenario one incorrectly assumes that the data stems from two gaussians, with the weighting of the two as well as the mean of one gaussian being unknown.","hence, in this scenario one incorrectly assumes that the data is coming from two gaussian processes, where the weights for both are unknown, as is the mean of one gaussian process."
1727,a typical application of mmg is the automatic image captioning to automatically assign caption words to the query image.,automated captioning in which captioning words are assigned automatically to query images is a typical application of mmg.
1728,we thought long about this but we think that relational might be the best approach here.,"we have considered this for a long time, but we suspect that the relational approach imposes the best bounds."
1729,"mf techniques are working in a way, that both users and items are characterized with a series of features as latent factors.",mf techniques work in the sense that both users and items are characterized by some encoding of features as latent factors.
1730,the function returns two values being: the two trained weight matrices and an error matrix to display the learning curve.,"this function returns two value representations, namely the two trained weight matrices as well as the error matrices to highlight the learning curve."
1731,"however, in the experimental conditions, the normal method can achieve the desired result with less initializations.","nonetheless, the usual method gives the desired result with only a couple of initialization steps, which is very impressive under experimental conditions."
1732,in this research volumetric weight is used to measure the capacity requirements of requests and the capacity of trucks.,we will use volumetric weight in this research to analyze both requests volume and load capacity.
1733,"drozd, aleksandr, anna gladkova, and satoshi matsuoka.","dael dowd, alexandr hovck, anna gladkova, and satoshi makutta."
1734,"therefore, an image was converted to the ycbcr color space.","therefore, we rescale the image onto ycbcr color space."
1735,"this step is motivated by the drawback of decision trees, being that only horizontal and vertical boundaries are considered.",the main motivation for this step is that decision trees suffer from the drawback that they only consider horizontal and vertical edges.
1736,"here, the number of instances in the new data sample and the original dataset is equal.",is the same as in the original dataset with the number of trials in the new dataset.
1737,"moreover, by resizing the image information in form of new pixels gets added.","additionally, new pixel information is incorporated by resizing the image information."
1738,"on the other hand, games can make use of these algorithms to improve the overall experience of players.","other than the current state of the games, those algorithms can also be used for improving the overall experience of a player."
1739,the exact sparql insert queries can be found in answer sheet kgc-rules-template.txt.,the exact sparql insertion queries are in answer sheet kgc-rules-template.txt.
1740,"they are used in many areas of ai such as deep learning, reinforcement learning or computer vision.","such methods are utilized in many areas of ai including deep learning, reinforcement learning, or computer vision."
1741,"the selfattention mechanism in the decoder uses a form of autoregressive or causal selfattention, which only allows the model to attend to past outputs.","a selfattention mechanism in a decoder is either autoregressive or causal selfattention, where the only use of the model is to address past outputs."
1742,"the last.fm dataset contains song-level tags and song similarity data, while the lyrics of the songs can be found in the musixmatch dataset.","the last.fm dataset comprises a combination of song tags and song similarity data, while the song lyrics are extracted from the musixmatch dataset."
1743,"jheng-wei su, hung-kuo chu, and jia-bin in huang.","jheng-wei su, hung-kuo chu, and jia-bin are from huangdong province, china."
1744,"in order to make policy iteration more stable, two improvements have been made.",two improvements were made to make the iteration policy more robust.
1745,one of the main topics to be covered in this research project is the research questions.,our research question is one of the important themes to be addressed in this project.
1746,"also, as delay allowance enters the model the ilp formulation becomes more complicated and more solutions are possible which could yield the wider spread from the mean solution value.","furthermore, if the delay allowance is introduced into the ilp formula, the ilp formulation becomes more complex and would allow fewer solutions, which could lead to a larger difference in the resulting snrs from the averaged solution value."
1747,we use the advantage of relational representation by not having a fix length of descriptions.,we exploit the advantage of relational representations: we don't have to worry about descriptions being fixed length.
1748,"this covers measures, in which the patient has a high temperature and a high heart rate.",this covers measures that are initiated by a patient who has a very high temperature and a very high heart rate.
1749,this metric has six classes which have a few imbalances.,the classes of this metric that have a high degree of imbalance are six.
1750,"however, in all other phases, it behaves exactly like other bots.","however, it behaves exactly like the other bots during all the rest of the phases."
1751,"the complete notebook, as well as single cells, can than be run and navigated through with the toolbox provided on top of the notebook.",this can then be used to launch and navigate the toolbox provided at the top of the notebook to traverse through a complete notebook as well as single cells.
1752,"when we only look at freely accessible data, there are three general categories of data that can be found.",we show there are three general categories of data when we only consider the readily available data
1753,"we include one example in the report, from which we can see that our model was not able to predict the colors truly well, but some improvement from the greyscale version can certainly be observed.","we provide in the paper an example that shows that our model did not predict the colorings well enough to make a fully plausible prediction, but some of the improvements over the greyscale version can be clearly observed."
1754,"this hypothesis would suggest mail, frequency) is price money is spam.","this conjecture leads us to the following hypothesis, mail(frequency) is price money."
1755,the best feature subset for the model was selected using recursive feature elimination.,recursive feature elimination was used to select the most appropriate feature subset to model.
1756,the conversion of the datasets to rdf was done using yarrrml.,we used yarrrml to convert the datasets into rdf.
1757,avoid asking the user to manually introduce the current mood he is in.,"instead, we can avoid the issue of asking a user to manually introduce the current mood he is in."
1758,this could be summed up as user a could get an item recommended based on the interests of a similar user b.,this can be summed as user a receiving items recommends to users b who share some similar interests.
1759,"to improve the results, we have played around by changing many different parameters.",we played around with a variety of parameters to improve the results.
1760,"our short-term contingency plans focus on how to deal with risks on an hourly or daily basis, while the long-term contingency plans range on a time-span of everything longer than that, up until the end of the project.","our short-term contingency plans focus on how to deal with the risks throughout the day, while the long-term contingency plans span over all the time-spans beyond that until the end of the project."
1761,"the rules seem to be consistent, they show playing at home for team a is a major advantage, the conditional probability of winning against team b and team c is significantly higher when they play at home than when they play away from home.","the rules are consistent, they show that while team a has a substantial advantage by playing at home, the conditional probability of winning against team b and team c is much higher by playing at home than by playing away from home."
1762,"but in the context of this project, using audio signals as input collides with our aim to playback song recommendations to the user.","however, a parallel approach, using audio signals as input, conflicts with our objective of delivering song recommendations to the users."
1763,"from these results, a more defensive approach seems to yield higher win-chances while keeping the number of turns needed fairly low.","the results suggest that a defensive variation is more likely to give higher probability of winning, while keeping the number of turn needed in this mode relatively low."
1764,"these options have some shortcomings, as they reduce the complexity of the representation: it can no longer be distinguished who tweeted what, such that is the relevance of the author is neglected.","these choices have a few drawbacks, one being that they reduce representation complexity: who tweets what can no longer be distinguished, such that the relevance of an author is neglected."
1765,"with delay allowance, it is required that the model solves for the truck schedule of all weekdays simultaneously.",the model has to solve for the peak truck scheduling for all weekdays utilizing the delay compensation.
1766,"explainable model both explainable models, that we have experimented with, have performed very poorly for this metric.",the performance for this metric is very poor for both explainable model ad explainable models that we have experimented with.
1767,"one more thing to notice is that in those states, which the agent can never reach, one can see the random noise.",another observation is that the random noise can be detected in the states that the agent can never reach.
1768,"to then further improve on this result, grid search was employed to narrow down an area closeby these satisfactory parameters.","an area near these satisfactory parameter values was generated, and grid search was then applied to further refine this result."
1769,the numbers show the count of participants by cluster and in total.,the figure shows the number of participants grouped by cluster and total.
1770,"in addition, an improvement can also be observed in the value function.",it also contains a value function which can be refined as well.
1771,the logistic regression model performs marginally better than the decision tree on all parameters and it is used to explain the results.,"given each parameter a logistic regression model does marginally better than the decision tree, and it is used to express the results."
1772,the success of a movie can also be relative to its budget and the number of movie theatres that decided to have it played.,we can also calculate the successful of a movie relative to its budget and the number of cinemas that decided to show it.
1773,to enable this output node we need a positive bias such that this output node can be activated when none of the hidden units is active),to activate such an output node we need a bias positive such that this output node is activated even if none of the hidden nodes is activated)
1774,"but does a connection between being active and staying healthy really exist and if yes, which activity patterns lead to which health outcomes?","this raises the question of whether there is actually a connection between active lifestyle and staying healthy, and, if so, what activity patterns are related to which health outcomes?"
1775,one of the main innovations is that the dynamic aspect of the users is taking into account.,one key innovation is that the dynamic aspect of users is taken into account.
1776,we try to build the decision tree without considering them in order to discover new patterns in the data.,"to find new patterns in data, we try to build decision trees without considering any of them."
1777,the support vectors hence play a critical role in training the model.,"therefore, support vectors are a key component of model training."
1778,as for patients who have to stay longer a disjunctive hypothesis is used.,disjunctive hypothesis is used for patients who need to stay longer.
1779,"furthermore, an evaluation cannot be made in absolute terms.","in addition, the evaluation can not be made absolute."
1780,"secondly, i want to thank my brother lukas and my study colleague frederick for proofreading my thesis, even though they only had spare time because they were writing their own theses in the same time period.",the second one is my samurai brother lukas and my study companion frederick who were able to proofread my thesis on a limited time schedule whereas i was working on their own theses in parallel.
1781,"this would be, for example, listening to sad music when the user is feeling melancholic.","for instance, a user might listen to sad music when she is melancholic."
1782,"so, we had to get our algorithm to be able to pick the action for a certain state that grants the agent the highest q-value, for this we also wrote a function.",so we also wrote a function to enable our algorithm to choose an action that yields the highest q-values for an agent.
1783,in the battle phase each attack independent of its outcome will lead the agent to a new state therefore implying a new calculation of the state value.,"it implies a new computation of the state value to be used in the battle phase, independently of the outcome of the attack."
1784,"on the other hand, it would be a good way of embedding a complexity network if we have a large database.","in contrast, if we have a large database, this might be a good way to discretize the complexity network."
1785,an increasing number of classes in multi class classification usually decreases accuracy for each class label but only having three class does not provide enough precision to be able to order two teams which has same points.,"in multi-class classification, the accuracy of each class label is usually decreased, but merely having three classes does not offer enough accuracy to rank two teams with the same score."
1786,"first, we define the dimensions of the layers of the neural network, the input and output variables based on the task given.",first we characterize neural network s layers and the input and output variables as per a given task.
1787,therefore a combination of multiple to all health status columns will be considered.,"hence, the health status columns should be the multivariate ones."
1788,"even though that half of the testers indicated that use music to both supporting their current mood as well as changing it, there was a majority that would use music that relates to the same mood they are in.","although half of the testers indicated that they use music to support the same mood as they switch to another one, a considerable minority would use music that matches their current mood."
1789,for that reason further experiments in this setting will not be stated here.,"thus, we will not state further experiments using this setup here."
1790,"explanation for this; some states simply cannot be visited due to their position, or due to the position speed combination (it is simply impossible to arrive at the top of a hill with full speed in either direction).","this could be explained in the following sense; some states are simply not reachable due to their positions, or by the combination of positional speeds (a hill-top arrival simply can not be reached with full speed in either direction)."
1791,the metrics for our monitoring were simply stored in a python dictionary.,we simply stored the metrics to be monitored in a python dictionary.
1792,the function loads the dataset in batches and splits the dataset to train and test sets.,the feature loads the data on the fly and splits the dataset into training and test sets.
1793,"similarly, dai, liang, qiu, and huang use a transformer structure to learn a mapping function between an arbitrary input sentence and a stylized output sentence implying that this model structure improves upon the content preservation achieved by disentanglement approaches.","similar to dai, liang, qiu, and huang employs a transformer structure learning a map function for an arbitrary input sentence and a stylized output sentence, implying that the model structure preserves the content preservation achieved by the disentanglement approach."
1794,"to complete the model, the objective and the constraints need to be introduced and described, in order to explain why the variables are set in the way described in the optimal solution.",there is a need to introduce and describe the model objectives and constraints so that we may explain the motivations of set variables in an optimal solution.
1795,"with a fixed number of transactions, less and less transactions contain all items from a higher number item set, and with the increase of the support threshold, less and less item sets qualify.","the higher the number of items in the support network, the fewer and fewer transactions contain all items in the higher number of item sets, and the fewer and fewer items set are considered to be supported at the maximum number of transactions."
1796,the newly created ontology predicates contain a label and a comment for describing its meaning.,the new ontology predicates are given labels and annotations to describe their meanings.
1797,in the summary we can see how the number of parameters and the sizes of the output matrices change throughout our model.,we see that throughout our model the number of parameters as well as the output matrix sizes change significantly.
1798,"to identify how our neural network converges, we have performed two experiments by changing the learning rate and the weight decay separately.",we did two sets of experiments in which we varied the rate of learning and the rate of weight decay separately in order to observe how the convergence of our neural network is reached.
1799,the objective of this research question is to identify the machine learning approach that outperforms the others in terms of accuracy of predicting the health status of an individual.,the goal of this research is to identify the machine learning approach which outperforms others in terms of accuracy for predicting the individual s personal status.
1800,"on the left side of the equation, there is the sum of the decision variable whether to send request r externally ser and the sum over all lanes whether to send request r via lane l slr,l.","the upper bound of equation shows that the decision variable whether to forward a request to external sr and the sum over all lanes whether to forward a request to external sr, l are the same."
1801,"moreover, the general idea of using additional noise in the underlying data and thus building a more robust model has been applied in various settings.","we additionally use different settings to generalize the idea of incorporating more noise in the underlying data, and hence to build a more robust model."
1802,information gain is the amount of uncertainty reduced due to the split.,information gain is the amount of uncertainty that is reduced during the process of splitting.
1803,task: you want a learning mail program to classify emails as spam or ham.,task: you are looking for a mail learning program for spam or spammy emails.
1804,the way they evaluated the results can be used in other papers to compare the future results.,the way these results were evaluated could be used to compare future results in other papers.
1805,"it is one of the primary goals of these projects to set a relationship between emotions and music features (harmony, tone-color.).","the goal of these projects is to establish relationships between musical experiences and musical features (the harmony, the color, etc)."
1806,"in terms of referencing related work, the authors did very well.",the authors did well in terms of citing related work.
1807,"q-learning and sarsa were chosen, because these are easy to implement algorithms for a determined discrete environment.",the algorithms for the discretized environment of q-learning and sarsa were chosen because they are simple to implement.
1808,on the other hand it is shown that the method outperforms any other techniques so that the optimal parameter estimation can be a task for further research.,"on the other hand, the performance of this method is shown to outperform any other technique so that finding the optimal parameter estimation in a structured dpgn is left as a goal for further research."
1809,therefore also the amount of restaurants serving indian cuisine or street food made the majority of relations between restaurants and cuisine (see appendix d).,"thus, the majority of correlations of a restaurant or cuisine is induced by the number of restaurants serving indian or street food (see appendix d)."
1810,out-of-bag samples is compared with the accuracies measured from permuting feature k. the average decrease in accuracy of these permutations are averaged across all the trees that are built.,the errors are calculated using out-of-bag samples and permutation feature k accuracy decay is averaged across all the trees to be built.
1811,colorizing images is a well-studied topic but with a small practical relevance.,"as a well-studied and practical task, image colorization is well-established but has little practical utility."
1812,with their method the authors aim to overcome the problem by separating data clusters in the latent space and thus make latent space arithmetic more usable in a intuitive fashion.,the authors try to solve this issue by discriminating data clusters in latent space and hence to make the latent space arithmetic more intuitive.
1813,latter insight is most likely due to not removing any details through max pooling.,the latter observation is most likely due to a lack of detail removal by max pooling.
1814,"in addition, the td-bot seems to follow a more defensive strategy overall.","we also showed that overall, td-bot seems to adopt a more defensive strategy."
1815,the main task is to identify the overall health of a patient to decided when to release him from intensive care.,patient monitoring is a key task for determining the patient s overall health and deciding when to release the patient from intensive treatment.
1816,"however, decision tree is a greedy algorithm and only achieves the local optima and not the global optima and hence is not always the best algorithm.","however, the decision tree is a greedy algorithm that converges to the local optima but does not to the global optima and it is thus far not the best algorithm in practice."
1817,the resulting product is multiplied with a learning parameter alpha and added to the current weight.,the generated snr is multiplied by the learning parameter alpha and added to the current weight.
1818,"the formation of the average is not meaningful here, for the reason that face recognition predominantly does not return an unambiguous result (i.e.",the formation of the emtc is not relevant here as face recognition typically does not return an ambiguous result (to which we refer).
1819,"in addition, a report will be delivered which relates the data and the results identifying the features that lead to us opting for particular models.",we will also present a conclusion which links these data with the results and identifies the features that have led us to pick particular models.
1820,"the lighter the color is, the higher is the q-value.","the lighter the color, the larger the q-value will be."
1821,"determining number of clusters to determine the optimal number of clusters k to search for, several methods exist.",many techniques exist to find the optimal number of clusters to search.
1822,"however, even if they exercise, their hdl level will depend on the lipid modifying medication.","despite the fact that they are active, their hdl level will ultimately depend on the lipid modulating medication they are taking."
1823,this is the reason why the solution values in the box plots are presented in relation to the average value of the solution values.,this leads to the statement that the estimates of the solution values shown in the box plots are summed against the corresponding mean of the solution values.
1824,"to answer this question, we are required to choose models with high interpretability and thus resulting in less accuracy.","this means that we must pick models with high interpretability, which results in lower accuracy to answer this question."
1825,"because of the better performance in terms of accuracy, the chosen explainable model for this metric is the decision tree.",we chose to explain this metric with decision trees because they provide better performance on the accuracy.
1826,experimenting with the algorithm type was done by setting the eps start parameter to one of two states.,we experimented with the setting of the eps start parameter to one of the two states for the algorithm type.
1827,consider a single stock with price x(t) at time.,let us consider a single stock with a price of x(t) in the moment.
1828,"the evaluation of the proposed model is thorough and takes multiple aspects and measures into account, and the usage of certain measures, datasets and baseline models are well-supported and well-documented.","the evaluation of the proposed model takes several measures and aspects into account, and is well-supported and well-documented because various measures, datasets and baseline models are employed."
1829,"secondly, for the locality of the restaurants we used the predicate schema:areaserved, because it expresses more that we are talking about the neighborhood of the restaurant.","second, we used the schema:areaserved predicate to express locational awareness in the restaurant class as it expresses more the idea that we are addressing the restaurant neighborhood."
1830,the paper also includes subjective human evaluation to compare the model of the authors to the ground truth and the state-of-the-art.,the paper also includes subjective human evaluation for comparing authors models with ground truth data and state-of-the-art metrics.
1831,"sitting time and mortality from all causes, cardiovascular disease, and cancer.","those with all causes, vascular disease, and cancer are the most likely to be obese."
1832,further research directions as time was limited there were a lot of aspects in this project that were left unexplored.,"because of lack of time, there were many areas left open for further research directions."
1833,the colour of the points indicates which maximum they converged to.,the colourings of the points indicate the peak they converge to.
1834,"explainable model unfortunately, the explainable models were unable to distinguish the two classes for this metric.","unfortunately, our approximation metric did not distinguish between both classes of explainable models."
1835,"since the game is very stochastic, there are some cases where the random player obtains this presence and will thus win the game.","since the game is highly stochastic, there are some cases where the random player possesses a given location and thus wins the game."
1836,"to test the case, two different tests were made, one for the distance and one for the angle.","for this purpose, we have conducted two different analyses: one for distance and one for angle."
1837,"further, the agent will have a small chance of executing a random action (this is because the agent might get stuck at the very beginning and this can help him to progress).","furthermore, the agent can execute random actions at a very low probability (this is because the agent might get stuck at very early points and this can help him gain some direction)."
1838,"a big advantage of relational representation in the case of this task is that we can have separate tables describing the movies, the actors of the movies, the awards of the actors, etc.","the big advantage of relational representation with respect to this problem is that we can have tables for movies, actors, movies awards, etc."
1839,such a summary could be: the overall (in an average sense) feedback of enterprise x in time step t was positive.,such a synthesis could be expressed as: positive feedbacks over enterprise x in time step t were overall (in a mean sense).
1840,"to do this, we scrape early reactions about movies from the micro-blogging platform twitter.","this is done by scraping early movie reactions on twitter, a micro-blogging platform."
1841,"the environmental changes throughout the game were barely noticeable for most respondents, hence its effect on the player's mood or engagement was inconclusive.","most respondents found the environmental changes in the game negligible, so a causality of the environmental changes on mood and engagement is inconclusive."
1842,"during this project, various methods of gauging the levels of intestines will be experimented with.",different methods will be used during this project to characterize the ranges in the intestines.
1843,"to identify causality, a set of experimental designs can be deployed to obtain further insights.",we may deploy a set of experimental designs to acquire further insights into the causality.
1844,"this also stabilizes training, since the network is not being changed after every turn.","this also stabilizes the training, since the network is not changed from turn to turn."
1845,"kde represents the data using a continuous probability density curve in one or more dimensions.""","kde is a way of representing a data set using a continuous probability density curve with singularities or singularities."""
1846,"in the end, the results obtained from the open beta version of the project will be displayed, addressing and discussing the opinions gathered from our testers.","finally, we will exhibit the results obtained for the open beta version of the project, and address and discuss the opinions of our testers."
1847,"this could maybe add some more precision, but on the expense of memory, especially when representing it as a feature vector.","this may add some more precision, but at the cost of memory, primarily when representing it as a feature vector."
1848,"here, important features will appear more commonly in the trees, as they are meaningful for making a split.","these are the relevant features for the reason of separating hierarchies, which tend to appear more frequently in the trees."
1849,therefore the denominator is based on the values of all features while the numerator is only based on the feature corresponding to the weight that is currently updated.,"the denominator therefore looks at the weights of all features; the numerator, on the other hand, looks at the weights associated with each feature at a given time."
1850,"for each model, its posterior probability given the dataset is computed.",each model computes the posterior probability of its trained predictions for the given dataset.
1851,an important component of the freight transportation sector are logistic service providers.,logistic service providers are an important element of the field of freight transport.
1852,using different approaches allows us to explore different data and investigate which of them gives a better result.,it is easy to see that using different approaches allows us to explore different data and explore which approach is more useful.
1853,"in order to compare the bots to a certain standard, a random bot was implemented.",an artificial bot was implemented to compare bots to certain algorithms.
1854,it is important to mention that the solution values are generally lower the higher the delay allowance is.,it is worth noticing that the solution values are generally less if the delay-limit is larger.
1855,"as a result, we would randomly pick one song in the list of songs with the best score emotion label.",we then selected one song randomly from the list with the highest score sentiment label.
1856,"in order to find the right clusters, a python script was created which uses the jenks natural breaks optimization method to arrange the elo-ratings into different classes by reducing the variance within classes and maximizing the variance between classes.",the python script used the jenks natural breaks algorithm for finding the right clusters as a corollary to assign different classes of elo scores by reducing the averaging between classes and increasing the variance between classes.
1857,adapt your network from the previous part such that it learns to reconstruct colors by feeding in grayscale images but predicting all rgb channels.,a rgb adaptation of the network from previous section is to learn coloring in the fsi from feeding the grayscale images but does not predict all rgb channels.
1858,also the representation dimension as well as potential solution complexity of the multi-instance could be higher (think of shrinking it will exrepresentational to multi-instance as multiple chained left joins. plode:d).,a multi-instance may have a higher representation dimension as well as possibly higher solver complexity (think of shrinking as using multiple chained left joins.
1859,"one of the questions that arises with this is, how do we consider this into our recommendation system?","this raises the question, how should this be considered in our recommendation scheme?"
1860,but we also left a choice for cases where the users really liked or disliked a certain recommendation to indicate this.,"in other cases, we left it at the discretion of the user to indicate how much they really liked or disliked a certain recommendation."
1861,"this would suggest that if there is a single tweet about the enterprise, their stock rises.","this might suggest that when enterprises are singleton on twitter, their stocks rise."
1862,"rather than volume and weight, volumetric weight, which is a combination of volume and weight, is used to address capacity requirements.","a method to answer capacity-constrained questions is by using volumetric weights, which is a combination of both, rather than weight and volume."
1863,"on a second weight that the edges have, which could for example represent time.","a second weight that the edges have, which for example could represent time."
1864,the most important part is probably the subject and the text of the mail.,probably the subject line and email content are the most important ones.
1865,the weight decays prevent overfitting by reducing the magnitude of the variables.,the weight decays of the scnls prevent overfitting by reducing the magnitude of variables.
1866,this section covers one of many ways to gather additional insights through grouping metric variables.,this section covers one possibility for collecting further insights through clustering of metric variables.
1867,"in the best case, the scores should rise with an increasing number of features and eventually decrease when reaching features, which reduce the prediction quality due to high correlations.","it can be expected that with an increasing number of features the scores become better and eventually decrease as the number of features is reached, which diminishes prediction quality by generating a large number of correlations."
1868,"in this section, the rationale behind the manually created rules will be explained in more detail.",this section will give a more detailed explanation of the reasoning behind the manual rules introduced here.
1869,the missing values for each feature is estimated using the existing observations of all other features in the dataset.,each feature is estimated by using the existing observation of all other features in the dataset and using the remaining data to estimate the missing value for that feature.
1870,"but also applying multi join, several instances with same blood pressure, but highly diverging heart rate values, indicate patients, which have to stay longer.","we also apply multi join, which indicates that patients will need to remain longer in some instances that have the same blood pressure but have a highly diverging heart rate curve."
1871,"however, the hessian matrix will be used, so if there are few sampling points or other conditions, the hessian matrix may be singular and the normal method will fail.","however, when the sampling point is not very strong or a particular other condition is satisfied, the hessian matrix becomes singular, and the normal method will fail."
1872,the user-id gathered from spotify is hashed before stored in our database to also hide the users spotify identity on our systems.,"however, we do have the ability to hide the spotify user i d in our database, but not the user i d."
1873,we will use the test set from this twitter data as they are manually annotated.,"since these twitter datasets are manually annotated, we will use them in our test set."
1874,"to track the progress made towards winning the game, the number of troops available for each player after the end of every turn for all games played during the training procedure is collected.","the training statistics for each player are collected, and then the total number of soldiers available for that player at the end of each turn is compared to the final scores to track the progress toward winning the game."
1875,"of listens, country, artist bio, active years of the artist and tags.","we compare listener count, country, artist bio, active years of an artist and tags."
1876,this is because the learned information of the model is exactly what has to be predicted.,this is because the learned eigenvalues of the model are precisely the ones that are needed to be predicted.
1877,the parameters found by grid search were then used to built this model.,this model was then built using the grid search parameter.
1878,"in the visualization, the actual route the agent made in one episode is represented with a black line between the states (i.e.",the black border between the states (as the arrow indicates) is displayed to represent the actual route that an agent took in a specific episode.
1879,"this will also ease the task of implementing the facial recognition, since the reaction to a video or movie would lead to a complicated algorithm in order to determine the dynamic emotion of the user.","this eases the implementation of facial recognition, since a complicated algorithm to identify dynamic emotion in a user s expression would involve response to a video or video."
1880,"second, the reader is adequately informed by using easy and understandable language, given the reader knows machine learning techniques.","second, with the reader s knowledge of machine learning techniques, this article provides a concise and understandable explanation to the reader."
1881,"minimizes the distance, with respect to a time constrain.",minimizes the distance when there is a time constraint.
1882,"so here again, the linked entities were related to each other.","hence, the relates are linked again."
1883,each turn in the battle phase consists of three sub-phases.,the strategy involves three sub-stages of each turn in the conflict phase.
1884,"different measures for the shortest path, either the travel time or the travel distance.",different measures of shortest path travel time or travel distance.
1885,"this is a distinguishing feature of hierarchical algorithms because other clustering algorithms cannot provide this very useful feature, especially when there is no additional information available about the data itself.","this can be very useful for hierarchical algorithms, since other clustering algorithms have the same difficulty providing this useful feature, primarily because there is no additional information about the raw data."
1886,"by extracting these features and setting and average, we are able to determine the mood a song could be transmitting quite accurately.",we are able to obtain a fairly accurate mood estimate for a song by extracting the features and setting them and averaging them.
1887,also this method is sensitive to the learning rate as mentioned above.,"as we have mentioned before, this method is also sensitivity to the learning rate."
1888,"but it has to be taken into account, that while the two minority classes were merged for the explainable models, the complex models have been trained on all three classes.","the main difference is that the complex models are trained on the underlying three classes, while the two minority classes have been merges to construct the explainable models."
1889,after early experiments on the imdb movie dataset we noticed the release date information was often not applicable for our use.,we observed that the release dates information was often missing in our early experiments with the imdb movie dataset.
1890,"for each music object vertex, four types of attribute vertices emotion, chord, rhythm, and temp vertices are created and attached.","each music object vertex has four type attribute vertices, emotion, chord, rhythm, and temp."
1891,"an optimum state for as long as possible, rather than playing with the game dynamics.","rather than playing with the dynamics of the game, the optimal state is reached as long as possible."
1892,"but in the context of this project, using audio signals as input collides with our aim to playback song recommendations to the user.","however, in this project the goal of providing a user with song recommendation turns out to conflict with using audio signals as inputs."
1893,"what makes our recommendation model dynamic, is that we aim to track the feedback of each user given to the various recommendations, and take them into account for their future recommendations.",a key feature of our recommendation model is that we want to keep track of the user feedbacks with each recommendation and consider the feedbacks in future recommendations.
1894,motivate terms for the remainder of this section we motivate our choices for the chosen vocabulary terms.,we motivate our choice of vocabulary terms in the remaining part of this section.
1895,this is also the q matrix we deliver in the assignment and that is loaded by default.,we will also need the q matrix that we have as a q-solve and that we load by default.
1896,these support vectors are the hardest to classify as they have direct bearing on the optimum location of the hyper plane.,the most challenging class of support vectors is that since they hold the key to a perfect hyperplane placement.
1897,"so far, any setting of parameters used while working on this task resulted in convergence of the network.","the convergence of the network follows thus, regardless of the parameter settings used in the course of the work."
1898,"the focus of the project will be put on how is it possible to utilize the dynamic emotions expressed by the user in order to make a good, suitable music recommendation.","the main focus of this project is how to use the dynamic emotions expressed by the user to help build good, targeted music recommendation algorithms."
1899,style transfer success can then be evaluated comparing these statistics on model input and model output.,it is then possible to evaluate the success of style transfer based on the resulting statistics with respect to the input model and output model.
1900,adding weight decay adding weight decay puts the gradient of the original loss function in competition with terms that try to keep the parameters close to zero.,adding weight decay adds weight decay places the gradient of the original loss function in competition with terms that try to keep the parameter values close to zero.
1901,novelty: there are already other papers published describing the approach of dividing the image into smaller subparts and then combining them in a fusion module.,novelty: the approach of segmenting the image into smaller sub-pieces and then merging them as a fusion module is already documented in other papers.
1902,"for the following analysis of the test phase, we have two data sources.",two sets of data are available for the following testing phase analysis.
1903,and we display the cuisine of of the recipe where this ingredient is used.,we show when this ingredient appears in the cuisine of a recipe.
1904,is there a correlation between the size of the latent space representation and the error?,do the values of the latent space representation sizes correlate with the error?
1905,this indicates that the solutions found in this setting are global minima of the loss function.,this means that the solutions of our setting are the global minima of the loss function.
1906,to build a recommender system to provide personalised recommendation (recommend physical activity patterns for patients who falls in a nonhealthy class to a healthier one).,our approach is to train a recommender system which provides personalized recommendation (recommends patients whose personal activity patterns fall in the unhealthier group to the healthier group).
1907,explain the activation functions and their required in line with this they refer properties in order to be utilized in nn design.,we outline activation functions and properties needed to achieve this in nn design.
1908,"in this project, two common methods of hyperparameter tuning were used, namely grid search, and random grid search.","two popular approaches for tuning the hyper-parameter, namely grid-based grid search and random-grid search, have been used in this project."
1909,then we group the ingredients and count how many times they where used for indian recipes.,we then separate the ingredients into groups of indian recipes and then count the number of times these ingredients are used.
1910,it also shows that the sentiment variance is greater for movies with lower earnings.,this also shows that sentiment variance is more pronounced for low earnings movies.
1911,"the network could split up a facial image into several parts, which get processed and merged together with the overall representation of a face.",the network could segment a facial image into several parts which are then processed separately and then merged to form the complete fas representation.
1912,"in order to reuse the existing codebase for a faster implementation, we will use python with the mentioned approach and libraries below.","below, we will use the approach of using python with a library above for reusing the existing codebase in order to make the implementation faster."
1913,report on your results and reason about potential shortcomings of your network.,in this section we report our results and reason about potential shortcomings of the net.
1914,as stated above approaches to reduce uncertainty with other optimization procedures did not prove to be successful.,"as mentioned above, the approaches to reduce uncertainty have not been shown to perform as well as other optimization techniques."
1915,attributes might be given by the sender (e.g.,the sender may have attributes (eg.
1916,"this is due to the fact, that schema:restaurant is very expressive in its available predicates.",this is due to the fact that the available predicates for schema:restaurant are very expressive.
1917,"in the recommendation system, the factorization happens from massive user-song matrix to individual user and song matrix.",the factorization happens by shifting the massive user-song matrix and merging the user-song matrix into a vector involving the individual user and song information in the recommendation system.
1918,"note that for this part the images were normalized at the beginning, as this did enhance the performance in all of the following instances.","note that we normalized the images at the beginning of this section, since this indeed improved performance for all subsequent images."
1919,lime is utilised in this project to understand the impact of features on the predictions for a given outcome variable.,lime was applied in this study to understand the influence of features on the prediction of the outcome variable.
1920,this means that the number of steps a person takes on a day together with the amount of fat consumed on a day are the key indicators whether a person has an acceptable or non-acceptable cholesterol level.,"it means that a primary indicator of the cholesterol level in a person is how many steps a person takes every day, as well as how much fat is consumed."
1921,for us the learning performance was reasonable with respect to the tweaks.,we found the small refinements to be reasonable in terms of learning performance.
1922,"a tree is built using recursive binary splitting, a procedure in which the dataset is iteratively split using a feature.","a tree is built using recursive binary aggregation, a procedure that iteratively segments the dataset according to a series of features."
1923,"having the results of those simple models providing acceptable scores, helped us not to combine the minority classes and provide insights covering the three classes instead.",the fact that these simple models produced acceptable scores for our benchmarks also helped us to don't combine the minority classes and provide insights covering only the three classes.
1924,"these include all kinds of boosting and bagging algorithms, so algorithms that combine several models to make predictions.","to which we refer we include all classes of boost and bagged algorithms, that is, algorithms which combine multiple models to make a prediction."
1925,this will be used for performing experiments and a grid search for parameter tuning.,this can be used in experiments and in grid-research to tune the parameters.
1926,one of the biggest challenges for the implementation was the exploration of the ways we can interact with the environment.,exploring the possibilities of interactively manipulating the environment was one of the biggest challenges in the implementation.
1927,there are existing training tools that can be helpful to detect the micro expressions so that we could improve the accuracy of emotion recognition.,"in this work we tried to develop existing training tools for microexpression detection, so that we can improve the accuracy of emotion recognition."
1928,"moreover, we have played around with changing the number of episodes to train.","furthermore, we played with changing the number of trainable episodes."
1929,"this inclusion could lead to much better predictions, as that model would take temporal aspects into account.",this addition is expected to provide much better predictions because such a model takes temporal features into account.
1930,in this case study we will deploy our model on a subset of the to be collected data.,we will deploy our model on a subset of the data to be collected for this case study.
1931,"also, this will be respected during the resampling process.",they are also respected in the resampling process.
1932,"in the extension to the general model, a valid problem solution is an assignment of all requests to the three available options of the lsp given that all capacity constraints are met.",an lsp that is suitable to solve a problem such that all requests are allocated to one of the three available lsps given that all the capacity constraints have been satisfied is an extension of the general model.
1933,which of the various machine learning approaches outperforms the others in terms of predicting the value of each health metric with physical activity patterns as accurately as possible and how can the results and the accuracy be explained?,how can the underlying physical activity patterns be attributed to the predicted health metrics value and how can one explain the variation in performance and accuracy between the various machine learning approaches?
1934,"starting with the introduction, the paper in general is very easy to read, even to audiences not that familiar with the topic of computer vision, natural language processing or deep learning.","we start by making this paper easy to read in general, even to readers unfamiliar with computer vision, natural language processing or deep learning in general."
1935,for this project an unsupervised machine learning approach was chosen to derive additional insights from the maastricht study dataset.,the research dataset of the maastricht nl-dsbp was chosen as an unsupervised machine learning approach in this project.
1936,these are two hypothesis which could be learned by an ml algorithm.,the ml algorithm has two assumptions that can be learned from these two data.
1937,results predicting waist levels accurately were a challenge for both the explainable and complex models.,both explainable and complex models have had trouble in predicting the waist level accurately.
1938,"alternatively, the bot could learn a model of the game; for instance by generating the maximum likelihood markov model based on observed experience.","alternativley, the bot can learn a model of the game; for example, by generating a maximum likelihood markov model using the observed game experience."
1939,it shows the number of iterations needed until convergence and the cost of the nn when convergence is reached.,"we show how many iterations are required until convergence, as well as the cost to the nn after iteration becomes successful."
1940,"and because we did not design our recommender system to support thousands of users, we did not have to worry about run-time performance issues of mf recommendation recalculations.",we also did not have to deal with run-time performance issues of mf recommendation recalculations since we did not design our recommender system to support thousand of users.
1941,namely a computer inventing binary coding using a neural network.,which is a computer-assisted neural network-based neural network for performing binary coding.
1942,"thus, these models are underestimating similarity when synonyms are used.","thus, these models underestimate similarity when synonyms are used."
1943,"reason being, that the algorithm itself does not require any heavy python libraries or much logic.",this is due to the fact that in principle the algorithm does not require any heavy python libraries or heavy logic.
1944,while notably the latent space now had as much dimensions as the input the quality of images was enhanced and the loss reduced (roughly by a factor of two c.f.,"notably, the image quality improved and the loss decreased (by a factor of two cf."
1945,people who are on any one of the medications are more likely to have high waist levels.,high waisted individuals are more likely to be on any one of the above mentioned medications.
1946,"for the given graph, it is for example unlikely, that a recipe is of cuisine indian and contains meat of a cow (since most indians are hindus and thus the cow is a sacred animal).","for instance, there is a recipe for indian cuisine that contains cow meat, which would essentially mean the cow is sacred for that given graph."
1947,this allows to calculate their respective shares in the last two columns.,this leaves the last two columns to compute the respective shares.
1948,"a good example is the rating type, because these entities include the ratingvalue and the color of that rating.",a good example is the rating type as these entities include the ratingvalue and the color associated with that rating.
1949,"this dataset contains information about movies, such as release dates, gross incomes, genres, authors and actors, among others.","the dataset includes details about movies such as release dates, movie gross revenues, genres, authors and actors, among other information."
1950,the value of the solution is the sum of all costs to be paid by the lsp.,a solution is valued as the sum of all the costs that must be paid by the lsp.
1951,"this is unfair, and therefore a problem: ability should determine the outcome of a game, not the arbitrary factor of who gets to go first.","this is unfair and should concern us: the ability should determine the result of a game, not the arbitrary factor who gets to go first."
1952,while it performed as well as other state-of-the-art models in reading comprehension it was not able to perform better than random baseline in summarization tasks.,"however, it was found that it was not able to outperform the random baseline in summarization tasks, while it performed as well as other state-of-the-art models in reading comprehension."
1953,"pre-pruning is preventing the creation of a complex tree by controlling its parameters such as depth, minimum number of training samples required to split the dataset and create a node, and minimum number of training samples required to form a leaf.","pre-pruning prevents the emergence of complex tree structure by controlling the parameters of a cluster, such as the depth, minimum number of training samples required to separate the dataset and build a node, and minimum number of training samples required for forming a leaf."
1954,"another fact supporting this assumption is that all of the shipment request in the data set used for this research arrive on weekdays, which indicates that also the clients operations are restricted to workdays.","another fact supporting this conjecture is that all the delivery requests in the data set used for this research arrive on workdays, which also suggests that client activity is strictly confined to workdays."
1955,"although, we thought about this we did not integrate this in our code as this is not harming the performance of the training phase.","while this is a very interesting idea, we did not incorporate it into our code, since it does not hinder the training process performance."
1956,in the e-step the algorithm evaluates the probability of each of the datapoints to belong to a gaussian distribution.,the algorithm evaluates the probability that every datapoint be part of the gaussian distribution in each e-step.
1957,"for the deep q-learning approach, using simple features to describe the state space resulted in a well-performing bot already.",a well performing bot has already been trained by using a deep q-learning approach that uses simple features to describe the state space.
1958,"after, it will be also analyzed whether this is something a general user would be interested in.","afterwards, we will also investigate whether this is something a general user would be interested in."
1959,for the second part of this lab the rgb images were mapped to the ycbcr space.,the second part of this lab included slicing images of a rgb matrix to the ycbcr space.
1960,"we can also set the number of iterations; for example, for lower alpha values the convergence is smaller, so we need more iterations for convergence.","we can also vary the number of iterations; for example, a smaller alpha value leads to a smaller convergence rate; for this, we need to use the more iterations for convergence."
1961,"should learn a generally applicable theory of how to predict each class based on the training set, and perform well given a new test set.","should learn a general applicability theory of class prediction on the training set, and perform well on a new test set."
1962,the idea of experience replay is to re-use previous experience.,the concept of replayed experiences is to reuse previous experiences.
1963,"from the video stream input, we then use a convolutional neuronal network (cnn)",we then learn the convolutional neural network (cnn) from the input video stream via the split-residual network input.
1964,"practically, improving image colorization also improves the process of restoring legacy photos and allows to compress images more before in the latter case, a grayscale transferring them.","practically, they improve image color processing by restoring legacy images and making images more compressed before grayscale encoding is necessary."
1965,"however, with the assumption that the results and corresponding code are correct and clean, which we can not check because the code is not published.","we use the following assumption for the performance and the code, which we can not check since the code is unreleased."
1966,"t-shirts, shirts, jeans, socks, underpants, shoes, gloves, waistcoats, coats, and even other accessories), each with common attributes (color and pattern).","there are shirts, pants, socks, underpants, shoes, gloves, shirts, pants, coats, and even accessories (with common attributes such as color and pattern)."
1967,this makes sense as people who take glucose-lowering medication usually have a high glucose value.,this is reasonable as in most cases individuals taking the glucose-lowering drug have a high baseline glucose value.
1968,the right side of the inequality represents the volumetric capacity of the trucks going on route a in week w. it is expressed by the sum of scheduled and ad-hoc trucks times the capacity of a truck.,"the right side of this inequality shows the volumetric capacity of trucks plowed on a schedule in week w, which is a value equal to the sum of the scheduled and ad-hoc towed capacity"
1969,"values that are actually learned tend to negative values, due to the throughout negative reward, with a concentration around the valley.","the actual learned values tend to negative values due to the endless negative rewards, with a concentration around the valley region."
1970,"while we did not have the data for doing such modeling, now with the collected data we could extend the modeling of emotion to including sequences of emotions in the model.","when we did not have the data to carry out this modeling, now with our collected data, we can build a model that also integrates emotion sequences in the learning process."
1971,choosing av representation when choosing av representation instead of mi one needs to either summarize all the instances in one example into a representative instance or give all the individual instances the example label.,one needs to choose the av representation instead of mi and either re-rank all the instances in an example by its example identifier or assign each instance a representative instance identifier by its name.
1972,complex model complex models were able to predict this class to a satisfactory degree.,complex-model complex-model complex-model was able to predict this class to a satisfactory extent.
1973,"that punctuality of delivery is one of the main selection criteria by clients, when choosing a third-party logistics service provider.",this suggests that punctuality of delivery is one of the important criteria that clients consider in selecting a third party logistics service provider.
1974,"in addition to the search of predictive features, tools for representation of the game trees and a selection of features is developed as well.",we further developed tools to represent game trees in a model as well as to select features for prediction.
1975,proportion of army strength in comparison to all other armies on the board.,we compare our army scores with the rest of the forces.
1976,"multiple times in a summary, even though it is a single source of information.","the summary is repeated multiple times, even though it appears to be a single source."
1977,it requires a large amount of collaborative feedback in order to recursively improve recommendations for all users.,"we expect that if we recursively improve the recommendation for all users, the collaborative feedback process would require a large amount of collaborative feedback."
1978,"in the paper, it is not really clear how they optimized the network parameters like the learning rate, number of epochs, and the optimization algorithm parameters.","the algorithm optimization parameters of the network such as learning rate, number of epochs, and the size of data are not entirely clear in the paper."
1979,this plot shows the scaled average of every health metric for both clusters.,this figure shows the scalar average for each health function over the two clusters.
1980,"since they are outcome variables, imputing missing values will lead to introducing bias in the prediction.","since results are outcome variables, adding missing values will introduce biases to the predictions."
1981,these networks were again trained based on mse loss and adam optimizer.,mse-loss and adam optimization methods were again trained on these networks.
1982,another point is that you could add a section where you specify a possible point of research building up on yours.,another aspect is that one might add a section describing how one might want to build on the research of yours.
1983,"finding that the integral underlying this expectation is not calculable, numerical methods needed to be used to derive this quantity.",numerical methods to derive this quantity needed to be found as a function of a probability distribution.
1984,"they are consecutively meant for placing new troops, attempting to invade other countries and moving troops between countries.","can be thought of as placing new troops in its orbit, trying to invade another country and deploying troops across country."
1985,as a deep learning library we decided to use keras in python.,we used keras as a deep learning library and constructed a python version of it.
1986,they have the advantage that only a camera with the average resolution is required on the hardware side.,"these schemes have the advantage that, on the hardware side, only cameras with the average resolution are required."
1987,"problems on this level deal with operational problems such as assignment and scheduling of crew or services, often in real time.","those problems deal with responsibilities for the operation, such as assigning, scheduling, and often monitoring employees and resources in real time."
1988,"with vbgmm, we aim to identify a single most approximate model.",we aim at identifying a single most approximate model for vbgmm.
1989,"satoshi iizuka, edgar simo-serra, and hiroshi ishikawa.","hiroshi iizuka, edgar simo-serra, and hiroshi ishikawa."
1990,by just relying on boolean representation one would still be able to detect a spam email by just focusing on the content of the email.,"if one just relies on the boolean representation, one would still be able to detect a spam email by observing the email content."
1991,the game map consists of svgs and coupled with in-game features provide a delightful user experience to aid in playing the game.,the game map also includes svgs and when coupled with in-game features provides a pleasant user experience with respect to the game.
1992,"once the data sample is created, a new decision tree can be grown.",a new decision tree can then be generated based on the data sample.
1993,"to save the reader from a very long list, we will group the explanations by dataset and type.",the explanations are grouped by dataset and type to save the reader the trouble of reading a very long list.
1994,a broader answer was given though when it came to the goal that people pursue music when it comes to emotions.,"however, to the question of why people are driven to music by an emotion, a more general answer has been given."
1995,it is an iterative method divided into two steps: the expectation (e) step and the maximization (m) step.,it is a bipartite method divided into two steps: expectancy (e) step and maximization (m) step.
1996,"at each step, the decision tree selects the attribute with the maximum information gain to be a node and splits the data into two or more subsets.",the decision tree selects at each step the attribute whose maximum informativeness gains it to be the node and splits the data between two or more subsets.
1997,the simplest method would be to match the mood of the user with the mood of the song.,an approach would be to match user mood with song mood.
1998,predicting disease risks from highly imbalanced data using random forest.,a random forest method for predicting disease risks from highly disordered datasets.
1999,the results obtained with k-means may not be repeatable as the initialisation of center points are random with each iteration.,the initialization of the centre points becomes random at each iteration and can not be compared with the k-means results.
2000,"moving backward, we then update psi and find the layers gradient until we reach the last layer.","we then update the psi in a backward direction and find the gradient of the layers, from left to right, until we reaches the end layer."
2001,a categorical variable is a variable that has two or more categories with no intrinsic ordering to the categories.,"a categorical variable refers to a variable which lies between two or more categories, without any intrinsic ordering in the categories."
2002,the name of the function is same for both packages but the syntax is slightly different.,the functionality names are same for both packages but have slightly different syntax.
2003,"i am using this property to create a generator of outing reports, the generator input is a set of gaussian independent variables, the output the report quantitative variables that are distributed similarly to the real reports.","for ra, i exploit this property to create an outage report generator where the input of the generator is a set of gaussian independent variables and the output is a set of quantitative variables as in real outage reports."
2004,"reminder, please refer to their official documentation for more info:",we remark that these results are not official and should be referred to in their official documentation:
2005,you need to know how to work with github as soon as you can!,"in short, we need to know how to work as early as possible on github!"
2006,"even if we have good intentions and are developing sociotechnical solutions to address challenges, without having the right cultural and contextual insights coming from lived experiences, we risk creating more harm than good.","while we have good intentions of developing sociotechnical solutions to these problems, without the correct cultural and contextual insights, which arise from the lived experience, we risk creating more harm than good."
2007,"or it can be iterative: objects are generated and over multiple iterations, all objects affect all others.","alternatively, the process may be iterative: each object is generated at random and all the others are affected over several iterations."
2008,"if you want to get a career change to work at companies such as facebook, amazon, netflix, or google (aka by the acronym fang), there are many pre-requisites.","there are many pre-requisites for a career transition to work at companies like facebook, amazon, netflix, or google (often referred to as fang)."
2009,when we build a machine learning model we use a sample of data known as the training data set.,"when we train a machine learning model, we begin by training a sample of the data called the training dataset."
2010,"going forward, i expect that we will see many developments in how one can learn the optimal computational graph structure (both in terms of nodes and relations) given some data and tasks without relying on explicit supervision.",our future work expects to see a lot of developments concerning learning the optimal computational graph structure (both in terms of node states as well as relations) for some data and tasks without the need for explicit supervision.
2011,they are probably due to the high number of features used for the explanation.,this is probably because we used a high number of features in the explanations.
2012,this would mean that we need to develop methods to load and manipulate data using python (or r) all by ourselves.,therefore we would be left to develop methods for loading and manipulating data using python (or r) by ourselves.
2013,"the command to run is a bit lengthy, and the reason is that we must pass the necessary arguments:","the executable command is rather lengthy, and the reason is that we need to pass the necessary arguments in the following manner."
2014,"in short, it groups the dataset into clusters of rows with similar features.","brief, hscv clusters the dataset into row-wise clusters that show similar feature clusters."
2015,efficientnet: rethinking model scaling for convolutional neural networks,efficientnet: reframing model scaling in convolutional neural networks
2016,"prodigy and spacy are made by the same development group, making integration straightforward.","prodigy and spacy use the same development set, making the integration straightforward."
2017,in future articles we will delve into the details of the nine-step process and the different phases of the end-to-end governance.,we discuss the details of the nine-staged planning and different stages of end-to-end governance in future articles.
2018,"as companies invest in more specialized data tools, more and more organizations are realizing that metadata serves as a seamless connection point throughout your increasingly complex tech stack, ensuring your data is reliable and up-to-date across every solution and stage of the pipeline.","more and more organizations realize the importance of metadata, which provides a seamless connective tissue between solutions and the layers of a technology stack, to ensure that data is reliable and current in every pipeline stage."
2019,"at the beginning of the article, we mentioned that we rely on commodity hardware and the network to build the so-called big systems.",we have mentioned at the beginning of this article that our approach is based on commodity hardware and the world-wide-web to build so-called large systems.
2020,"to enter this as a column in a count summary is very tedious: scanning the summary to find the species, entering the count and then on to the next species.","the process of encoding this as a column in a count summary is arduous: scanning the summary to find a species, entering the resulting count, and then enumerating the next species."
2021,"if you want to add (or remove) a package to your environment, i would highly recommend you to do so by using the following command","i would strongly recommend that, if you wish to add (or remove) a package to your environment, you do so using the following command."
2022,"for example, two similar phrases from legal notes email with opposite sentiment.",the first is a cross-domain example with two similar phrases in legal note emails with opposite sentiments.
2023,"using plotly, i was able to make my first interactive plots to explore forecasts and trends.",i did my first interactive plotting experiments to explore forecasts and trends with the aid of plotly.
2024,investments in data professionals and artificial intelligence are also directed to french-speaking areas.,investments in data scientists and artificial intelligence are also directed towards french regions.
2025,or do governments have a role to play in trying to internalize some of the externalities that are generated by the systems?,or does the role of government in trying to internalize some of the externalities in systems itself play a role?
2026,we can see that the panes filled with information as expected.,we can see that the information filling panes are as expected.
2027,with the requirements defined we started an investigation to identify what stream processing technology would fit our needs.,"having defined the requirements, we started the investigation to find which stream processing techniques would best fit our requirements."
2028,"therefore, i made sure to select the model using a metric agnostic to the threshold, and only then tuned the threshold.","that is, in the threshold model, i used the metric-agnostic threshold function and tuned it only after this threshold is reached."
2029,recall from its definition the saliency map will show the strength for each pixel contribution to the final output.,"recall that the saliency map shows the strength of any contribution of the each pixel to the final output, defined as follows."
2030,"alternatively, we can also save the model weights and other necessary information once training has finished.","alternatively, once training has finished, we can save model weights and other useful data."
2031,row and column pictures are just two different ways to consider the system of equations:,"we consider the system of equations in two different ways, by row and column images."
2032,"however, it is really small and serves no purpose beyond the tutorial described in this article.","this implementation, however, is really small and serves no purpose other than the tutorial presented in this article."
2033,"due to this, it is important to always do proper research before jumping to conclusions when you see reports based on numbers and graphs.",this reason explains why when we see reports concerning both data and graphs we always want to do proper research before jumping to conclusions.
2034,that does not mean i needed to hear and say his name every day for three years.,this means i did not have to hear and recite the same name every day for three years.
2035,"these tiles can be aggregated upwards arbitrarily depending on areas of interest, such as in the case of movement range maps, which are aggregated metrics built from the number of bing tiles that facebook users visit over a given time period.","these tiles can be aggregated arbitrary degrees and directions, as in the case of movement range maps, which are aggregate metrics built from the number of bing tiles visited by a given number of facebook users during a time period."
2036,"it was especially useful to me because i wanted to publicly share some of the pictures, in this blog for example.","this was particularly useful for me, since i wanted to publicly share some pictures on this blog."
2037,"unlike the two ai strategies mentioned above, the expert strategy is closely associated with augmentation.","different from the two ai strategies stated above, the expert strategy is closely related to augmentation."
2038,"now, go back to power bi desktop and refresh the visuals.","now, return to the power bi desktop to refresh the visuals."
2039,"rather than invent an entirely new governance structure, process, roles and responsibilities we have adapted this model to apply for ai governance.","we have applied this model to ai-governed system rather than inventing completely new organizational structures, processes, roles and responsibilities."
2040,"moreover, the learners will also get access to a range of advanced tutorials, like decorators, serialization, regular expressions, generators, closures, and more, along with a couple of data science-related tutorials.","in addition, there are also several data science related tutorials that learners may encounter at the end of this presentation, including decorators, serialization, regular expressions, generators, closures, etc."
2041,"this entanglement of the two reasons for our output to change is a fact we have to live with, but there are ways to mitigate the problem.","this interplay between two causes of our output changes is a fact we must accept, but there are approaches to alleviate this confound."
2042,how can you train a model if you cannot collect and store the data to your local repository?,can you train a model if one can not collect and store data at a local repository?
2043,as i said before the human brain consists of billions of neurons.,"as stated earlier, the human brain is a large generating machine consisting of billions of neurons."
2044,"for simplicity of the article, set authentication to allow unauthenticated invocations.",we may also set authentication to allow unauthenticated invokers for the simplicity of this article.
2045,"iteratively, the model will continue to improve the value of the mean, using a cost function that minimises within cluster distance and maximises between cluster difference.",the model iteratively improves the mean value using a cost function that minimises within the cluster distance and maximizes between cluster gradients.
2046,performing extractive text summarization with bert might be tricky since it is not one of the tasks for which bert was designed to be a pre-trained model.,"when training bert, extracting textual summaries may seem like a tough task since this is not one of the tasks for which bert was trained as preliminaries."
2047,"so ida stands for iterative, distillation and amplification.","so, lda stands for the iterative, distillative, and enriching approach."
2048,a standard computer science approach to evaluate scalability is to measure an algorithm's computational complexity in terms of time or space requirements.,it is common in computer science to evaluate computational complexity via time and space constraints in a computing design that involves measuring the computational complexity of an algorithm.
2049,a regular expression is a sequence of characters that describes a search pattern.,a regular expression is a sequence of words that describes a search pattern.
2050,"the bonus is, once you get to actually build a true recommendation engine, you get a baseline to compare to and lots of data on click-throughs, etc.","bonus: once we actually start to build the real recommendation engine, we have a baseline against which to compare and loads of click history, etc."
2051,"the media often portrait data science as the cool kids next door, working on amazing technology like ai but behind every buzz word are hours of hard work and perseverance.","there have been incredible advances in data science, and even ai, a fascinating technology behind every buzzword, which is frequently depicted by the media as the cool kid in the neighborhood."
2052,"first, you can use custom tags, which allow you to sort the content into categories of your own design.","first, we can use custom tags, which can sort content into categories as per the user s design."
2053,"prior to train the model, we had to prepare the inputs:","the input was prepared a couple of days prior to model training: about one packet of rl, and some mp3."
2054,we can specify how many processes we want to split the encoder into by using the parallel parameter.,the parallel parameter allows us to define how many processes we would like to partition the encoder into.
2055,"while the background contrast has improved after histogram equalization, the face of the statue became too bright.","although histogram equalization improved the background contrast, the statue s face became too bright."
2056,we will use docker to containerize our app and run it on google app engine.,"in particular, we will deploy our app in containerize."
2057,who are the most over-performing and under-performing goalscorers in the squad?,a question which the most over-performing and least-over-performing players in a team are?
2058,"for most matrices, there exist two matrix factors which multiply together to give that same matrix, or one that is extremely close.","note that for many matrices, there exist two matrix factors which either can multiply to the same matrix, or yield several matrix factors which are very close to each other."
2059,"also, check out some great content on agi by prasanna devadiga:","notice also this excellent paper by prasanna devadiga, called agi s complete life cycle."
2060,"for more advanced queries, we generally just build upon the ideas of the basics.",we generally just build on the principles underlying the query for more advanced queries.
2061,"to generate longer text, just like with the markov chain model, we need to implement a loop.","let us use a loop model to generate longer text, similar to the markov chain model."
2062,this is a dataset from a website tracking their user logins.,this is data from a website which tracks user logins.
2063,"in the context of our scenario, the null and alternative hypothesis are thus:",so the null and alternative hypothesis converge in our scenario as follows.
2064,if the file is in the same directory as your notebook you can just use the file name as shown.,the simple solution is to use the files name if they are found in the same directory as your notebook.
2065,"the attention calculations then combine each word with every other word in the sequence, so that the attention score encodes a score for each word in the sequence.","the attention computation first combines each word with all other words from the sentence, such that the attention score encodes each word in the sequence."
2066,"hope you will have some of your straightforward questions answered quickly, and now you are ready to start the fun part of data science: solving problems and generating insights.","we hope that answers to some straightforward queries for you will be quick, and are now ready to begin the fun part of data science: solving problems and generating insights."
2067,"when things looked very optimistic, they roped in black swan, a uk-based artificial intelligence (ai) firm, to predict whether the movie would be a hit.","black swan, a uk-based artificial intelligence (ai) firm, was hired to give movie previews when the business looked very optimistic."
2068,"that being said, take my pros and cons with a grain of salt, and consider other options, like the ones below.","despite this, take my pros and cons with a grain of salt, and consider alternative design options, such as the ones proposed below."
2069,and you will get a script editor with the data as a pandas dataframe called dataset.,"then, you are given a script editor, with data represented in pandas dataframe as a dataset."
2070,"others are more obvious, additions to syntax or functionality that can change how we write our code.","another type is more obvious, adding anaphors or functionality that could change the way we write our code."
2071,"however, in the case of our classified business, things are not that well-defined.","these are not well-defined, however, for our classified case."
2072,we now summarize the drawbacks of the aggregation-based approach before we address them using the conversion rate-based approach in the next section:,"before focusing on the benefits of our aggregation-based approach in the next section, we summarize the drawbacks of our aggregation-based approach: mainly, the shortcomings of the sparsity-based approach"
2073,it is all about creating a data visualization tool to compare movies and movie databases.,we describe how to create a visualization tool to look at movies and movies databases from the perspective of a dataset.
2074,"since it is a surrogate key integer value, vertipaq applies value encoding, and the size of a dictionary is irrelevant.",vertipaq uses value encoding and the dictionary size is not considered as trivial since it is a surrogate key integer.
2075,"eventually, this will lead us to the correct value for each state.","this, eventually, gives us the correct value of each state."
2076,"occasionally, index might be used as reference in a pandas function and it would need to be correct.",a pandas function could occasionally use the indices as references and be required to be correct.
2077,"hopefully, you found this useful and they can help you grow your skills as a data scientist.",we hope that you found these insights useful and that they may help you grow as a data scientist.
2078,"despite its rather basic title, this book to me is even more valuable than the previous iteration by the same author.","although the title is rather basic, this paper is for me much more valuable than previous iterations of the same author."
2079,"as you can see, the classes are much more separated now.",the classes are now much more distinct as we can see.
2080,"therefore, the most vital thing here is to come up with a robust approach to generate good-quality product embeddings that lie at the heart of all products.","therefore, finding robust methods to generating good quality product embeddings, which are at the heart of all products, is of paramount importance."
2081,"most of the clients i was working with were from the automotive industry, sometimes from the chemical industry that was supplying the automotive industry.","most of the clients i dealt with, though, were automotive industry clients and some were also chemical industry clients."
2082,slicing a list will return a copy of that list and not a reference to the original list.,"a cut to a list returns a copy of the list, rather than a pointer to the original list."
2083,the reasons are worth mentioning here to understand the business problem deeply.,we recall here the motives that motivate the study of this business problem in depth.
2084,it could be a linear function or quadratic or some other function that we do not know.,"we may take it to be a linear function, or quadratic or some other type of function that we don't know."
2085,this is done with band-pass filtering (this passes frequencies within a certain range while rejecting frequences outside of that range).,this is done by applying bandpass filtering (it passes frequencies within a given range while rejecting frequencies outside the range).
2086,"the confusion matrix shows us the exact number of true positive, false positive, true negative and false negative in a classification result.","in a classification result we observe the exact number of true positive, false negative, true negative, and false negative scores within the confusion matrix."
2087,all the scikit-learn operations described in this tutorial follow the following steps:,all scikit-learn operations that are described in this tutorial follow the following steps.
2088,we then look in the agent's state value table and find the value of this state.,"then, we search the agent s state table and read out its state value."
2089,"afterward, you will need to retake the test to keep your skill level synced with the tensorflow package's recent updates.","afterwards, if your skill level has not yet been updated to the latest version of the tensorflow package, you need to retake the test again."
2090,"if a regularization terms is added, the model tries to minimize both loss and complexity of model.","so, in general, both loss and model complexity will be minimized if a regularization term is introduced."
2091,training performance is measured by the optimization metrics as part of the ml process.,the training performance is measured as a function of the optimization metrics applied to the ml process.
2092,"to see the code in a ready to run format, i prepared this jupyter notebook.",i prepared this jupyter notebook to show the code in the ready-to-run format.
2093,to reduce network requests can also be a cause for using caching.,"in addition, the use of caching can be motivated by trying to reduce network requests."
2094,check out this excellent blog and this live demo on zero shot classification by huggingface.,"the list of zero-shot classification posts by huggingface is also very helpful, check out their excellent blog and this live demo."
2095,we will then set up our express app by writing the following line of code:-,we then write a line of code to set up our express application as follows:--
2096,i write data science-related content intending to make it simple and accessible.,i write data science related posts in a straightforward and accessible way.
2097,"then, we use a set of env variables to control the behavior of the scripts.","next, we use the set of env variables to control the behavior of each script."
2098,"at this moment, artificial intelligence sparked my interest immensely, and i began my journey towards data science.",this is when artificial intelligence really started to ignite my interest and i began my career in data science.
2099,"very importantly, we learned that simply applying convolutions to the individual rgb channels may not be the best way to go.","most importantly, we realized that the best route to go is to simply apply convolutions to individual rgb channels."
2100,sigmoid and relu are the most commonly used activation functions.,the most commonly used activation functions are sigmoid and relu.
2101,here are a dozen of the most common sql interview questions you will see during an interview for a data professional role.,the following is a short collection of sql interview questions that you may encounter in your data professional hiring process.
2102,"in a sense, nmi tells us how much the uncertainty about class labels decreases when we know the cluster labels.","nmi, in a sense, tells us how much the class label uncertainty decreases after knowing the label of the cluster."
2103,follow me on medium for more high-quality stuff and check out my github to get the entire jupyternotebook for this post.,"i am also following medium, where you can find more quality material as well, and check out my github repository to get the full version of jupyternote needed for this post."
2104,"this way, we will be left with only one card (and one address) per customer.","thus, only one card (and single address) is kept per client."
2105,"i knew that my draft code was not optimal, but the rate of memory utilization was not making sense with the growth rate of my dictionary length.","we all know that my draft code is not optimal, yet the memory-usage rate that i was using did not make sense as my dictionary size increased."
2106,"i run many jobs on an hourly, nightly, or weekly basis for my team and only check the code when i need to make updates or a job has alerted me of a failure.",we only explore the code when i need to make a change or a job gives me a fault.
2107,"i am training using abstract paintings, but the resume option starts the training with the gan trained with landscapes.","i train using abstract paintings, but the resume option begins training starting from a gan that had been trained using landscapes."
2108,good for us that both our requirements are already fulfilled by the hash functions.,it is very good for us that the hash functions fulfil both of our requirements.
2109,kaggle api provides the advantage to download any published notebooks from kaggle to your local machine.,the kaggle api has the advantage of downloading any published notebook from kaggle to the local machine.
2110,it relies on a couple people to carry the team to the sales quota.,this relies on a few people being able to deliver items to the team sales quota.
2111,"these steps are data collection, data cleaning, data exploration, feature engineering, and modeling.","such processes include data collection, data cleaning, data exploration, feature engineering, and modeling."
2112,a computer movie simulating urban growth in the detroit region.,computer-generated videos simulating metropolitan area growth in michigan.
2113,pre-commit hooks are often used to make sure code is linted and formatted properly before being published.,pre-commit hooks are often used to make sure that the code is bounded by and formatted well before releasing it.
2114,the main drawback of this method is that the enhanced resolution may be a misleading description of the high frequency actual observations.,the main drawback of this method is that the improved resolution can indeed give a misleading description of the high-segment actual observations.
2115,interest in a group of ads: the ratio of number of distinct listings viewed by user to total number of listings viewed by that user.,interest in a cluster of ads: the ratio of the number of distinct ads viewed by a user to the total number of ads viewed by that user.
2116,it is a great combination for various smaller or mid-size projects.,this combination is ideal for a variety of small or mid-sized projects.
2117,"the google brain team demonstrated that this semi-supervised learning approach is very label-efficient and that larger models can lead to greater improvements, especially for low label fractions.","this semi-supervised learning approach has been demonstrated by the google brain team to be very label-efficient, and can also lead to larger model size, especially for low label fraction distributions."
2118,note that the advantage function may not always be the same as the td error function.,note that the td error function may not always be the advantage function.
2119,"instead, learning small chunks and absorbing the information with practice will help you build comprehensive data analysis skills.","rather, for more thorough data analysis techniques, practice will help by learning small chunks and then absorbing the information."
2120,"kaggle aims to provide you with useful codes and resources for you to start the implementation of your own projects from scratch, as well as provides you with large reserves of datasets and data for working on numerous project ideas.","kaggle provides a code-base and source code to start your own projects from scratch, and a huge repository of datasets and data to test many project ideas."
2121,the goal now is to return an image instead of raw data.,"the goal now is to return an image based representation, instead of a raw qos."
2122,plot styles instantly apply multiple stylistic elements to your plots and save some troubles.,"plot styles instantly apply different stylistic features to plots, saving some work."
2123,"if you are truly passionate about the field of data science, then even certain complicated topics will not be too much of a burden for you to overcome.","in data science, sometimes, even the most difficult topics will not be a burden that one must deal with, if you are passionate about the subject."
2124,"in the next section, we will split the data set into train and test subsets, then implement univariate and mutivariate feature selection (training) models on the train set, and evaluate the models on the test set using the roc-curve technique that balances false positive (fpr) and true positive (tpr) rates.","the next section consists of classifying the dataset into train and test subsets, after which we implement univariate and mutivariate feature selectors for the train set, and evaluate the models on the test set using roc-curve which optimizes both false positive (fpr) and true positive (tpr) rates for the test set."
2125,"we need to create a dataset for the plot, containing vehicle year and the number of parking violations for each those years.",in order to construct our plots we have to create a dataset consisting of vehicle year and number of parking violations for each of these years.
2126,"the authors converted the absa task to a sentence-pair classification task, enabling them to use bert for their model.","the authors transformed a sentence-parallel classification task, and then applied bert s model to theirs."
2127,"with topic modeling, it is actually essential to normalize the corpus text.",normalization of corpus text is actually essential for topic modeling.
2128,"diving further into the data, this project used climate information and historical wind power generation statistics to understand the operating capacity of the farm for a selected time period.",we delved further into the data by exploiting both historical energy harvesting and climate information to understand the operating capacity of a wind farm for a selected time period.
2129,"in the end, you will know what you have to know.","if you have the appropriate knowledge, then you will have it in the end."
2130,we could perform a segmentation on an item level but rolling up to categories has two benefits:,"we might perform item level segmentation, but the advantage of rolling over categories is twofold."
2131,"having learned a handful of research techniques under dr. jane doe of the research seminar in quantitative economics, i was nervous and excited for the opportunity to test my applied econometrics knowledge for the first time.","having previously had the opportunity to prove the effectiveness of econometrics in applied economics, i was nervous and excited for the first time to test some of the aforementioned research techniques with dr."
2132,"so, please be patient and read to the end to find out the others!",now please be patient and read the rest of the article to figure out the remaining ones!
2133,please note that we are allowed to make three different second-stage decisions for buying and selling for each scenario (yields are realized by the time we have to make these decisions).,note that for each scenario we are allowed to make three different second-order buying and selling decisions (the yields are obtained by considering the amount of time we need to make these decisions).
2134,"if they need some specific report, they can use the custom csv export of the data and run some excel magic over it.","if they need to run some excel magic over that data, they may simply run a custom csv export over it and run some xml magic over it if they want something specific."
2135,machine learning as a supportive tool to recognize cardiac arrest in emergency calls.,machine learning as a modality for supporting cardiac arrest recognition in emergency calls.
2136,"although being straightforward, the in operator can sometimes be mistakenly used in the problems implying the logic and.","although the in operator is quite straightforward, sometimes the logic and hash operator may also be misinterpreted in problems implying the in operator."
2137,"here we assume our data is supplied at the nodes of the fe model, but this restriction could be easily generalized by evaluating the residuals at any given spatial location via the fe shape functions.",we will assume that our data comes from a fe model node and can easily be generalized by evaluating residuals at a given spatial location with the fe shape function.
2138,"in addition to consulting, rod also enjoys public speaking, teaching, and writing.","rod enjoys the performance of public speaking, teaching and writing, along with consulting."
2139,matplotlib is a must-learn python library if you are a data scientist.,"if you are a data scientist and need python library to parse matplotlib, then matplotlib is one of the must-haves."
2140,typical visual transformers use the concept of a trainable vector called the class token.,the traditional approach of visual transformer is to use a trainable vector that is called a class token.
2141,"unlike integer values, where the bits simply represent the binary form of the number, perhaps with a single bit reserved for the sign, floating-point values also need to consider an exponent.","floating-point values also require exponents, unlike integer values, which can simply represent the number in the binary, possibly with a single bit reserved for the sign."
2142,"it takes a function as input and outputs another function ( wrapper , in this case).",it takes a function as input and outputs some other function (the wrapper in this case).
2143,"so you could say that mlops belongs under devops, but since ml adds new complexities to devops, mlops becomes a shared discipline.","therefore, one can say that mlops falls under devops, but since ml introduces new complexity into devops, mlops becomes a part of the same discipline."
2144,the output is a learned representation of size h for each input token.,the output is a learned representation of size h over the input tokens.
2145,here are some examples showing the slice objects used when using indexing syntax to slice a list:,some sample applications of index-based representations of list slicers are mentioned here.
2146,"to give each unique character an index number, we first have to find all the unique characters in the text file.","to assign an index to each unique character, we first have to find all the unique characters in a text file."
2147,"this is a simplified view, as the layers could be represented in many different ways however in a distilled form the pipeline can be thought of as ingest, processing and result layers.","this is just a simplified view, because there might be many ways to represent the layers, but in a distilled way, the pipeline can be seen as layers in ingest, processing, and result."
2148,"our intention was to modify this data pipeline by adding a step in parallel, that could send source data to the data lake and also to kinesis analytics to generate events.",our aim was to adapt this data pipeline so that each query step could send its source data both to the data lake and to kinesis analytics that generate the event information.
2149,she was interested in what it meant to be a software engineer within the company and what the day to day activities looked like.,the idea of her research interest was to understand what it meant to be a software engineer in the company and to observe how the everyday life of software engineering was conducted.
2150,the lottery ticket hypothesis is one giant step forward towards understanding truly how deep neural networks work.,the lottery ticket hypothesis is a massive step towards understanding how deep neural networks really work.
2151,building relations with people from businesses or managing projects is also expected.,are also expected to build relationships with business or project employees.
2152,"now, let us try to fit a linear model to this data and see the plot between residual and predictor.","now, let us attempt to fit a linear model to this data and observe a plot of the residual vs predictor."
2153,i was able to leverage a business problem to practice building a machine learning model on the job and use it as a talking point when i interviewed for my next job.,my main motivation in taking on this role was to be able to use a business problem to practice building a machine learning model on-the-job and use it as a talking point while interviewing potential employers.
2154,but we could also make this work a lot better by simply adding an inner constructor.,"however, the addition of an inner constructor to the combinatorics could also make this work much better."
2155,"most of us are familiar with the idea of a traditional dashboard, a compilation of key metrics and charts, displayed to provide useful information for decision-making.","most of us are familiar with the notion of a traditional dashboard, which is a compilation of metrics and graphs of interest to the user, and depicted to provide useful decision information."
2156,"based on this research, we built a model to infer playing positions based on those statistics which are characteristic of particular locations on the field.","based on these studies, we constructed a model of playing positions that uses the statistics characteristic of particular fields."
2157,we can take the log of each value by using the transform function.,"let us use the transform function, to perform a log for each value."
2158,"since the rows are filtered before the group by clause, we can use the where clause.","since rows are filtered out of a cluster by a clause, we can use the where clause."
2159,"but if i want to merge the remote changes into my local branch, i need to type:","however, if i want to merge the remote changes into my local branch i have to type: recurse merge."
2160,the where clause can be implemented in a select statement to apply conditions on the selected rows.,the where clause can be used in the select statement to apply conditions to the selected rows.
2161,"in this post, we went through how you can implement your own conversational bot using a pretrained model provided by huggingface.",we explored the method of using a pretrained model provided by huggingface to enable personalization of conversational bots.
2162,you might ask me how did i find the compressive strength in each of these experiments.,one may ask me how i achieved compressive strength for any of these experiments.
2163,"it allows for writing queries that can filter, manipulate, and transform the data stored in relational databases.","the DBMS can provide queries that can parse, manipulate, and transform data that is stored in relational databases."
2164,it also hosts competitions and has freely available notebook to explore and run data science and machine learning models.,it hosts a series of contests and provides a free-to-use notebook for exploring data science and machine learning models and simulations.
2165,use a clustered index to increase the speed of queries against a table.,this clustering index helps to speed-up querying against a table.
2166,we need to have the environment active for our python packages installations.,to deploy our python packages we have to activate the environment.
2167,"from a relativist position, language acts as the framework of cognition.",language acts as a cognitional framework from the relativistic view point of view.
2168,below is an example of the output using the same set of sample purchase propensity scores.,the results using the same set of purchase propensity scores are illustrated below.
2169,"however, a small minority of matches ended up in a draw.","however, a small minority of matches led to a tie."
2170,the reason i was forced to use the word might is because the nashville predators blue line also exists.,i used nashville predators blue line because of its presence.
2171,"i hope that during this process, i can help others understand them too.","i hope, in this process, that i may also help others to understand them as well."
2172,the main idea here is to pass our query text and the matches (containing the answer text and match scores) to the ranker to return a reordered list of matches based on the relevancy scores computed by finbert-qa.,"our approach is simple: pass a query text as input to the ranker, along with matching values (covering answer text and match score), and then return a reordered ranking order to the matchings computed by finbert-qa."
2173,"for a time i tried to create some games myself, but now i often try to understand research papers by implementing their systems.","once i tried to design my own games, now i try to understand research papers primarily through their implementations."
2174,one song that is dramatically under-rated is the song shadyxv from the album with the same name.,"the song shadyxv, from the album, which is similar to this topic, is a song that has a drastically underrated rating."
2175,"however, if we know a data point belongs to cluster a, it is highly likely that the point belongs to class a.","however, we know that if a data point belongs to cluster a, then it is overwhelmingly likely to belong to the cluster a class."
2176,"even when the skillset they have enables them to answer an infinitely vast array of questions, they remain focused on the most boring questions, lacking even the faintest attempt at creativity.","they continue to focus on the boring problems, despite the fact that their talent set enables an infinitely large number of queries, but does not have the slightest creative attempt."
2177,"firstly, we may ask ourselves: what is the fraction of positive predictions which are true positive?",we can first ask the question: what is the fraction of positive predictions that are actually positive?
2178,they will be happy to be able to visualize all projects and tasks in one place.,they will be pleased to have one point to see all their projects and tasks.
2179,this is achieved in the simple epidemic model below through expressing the agents social connections as a network with small-world properties.,this is achieved in the simple epidemic model below by treating agents social interactions as a network with small-world properties.
2180,a free short course on spacy can be found as following:,"a short course on pacs is available for free on the internet, and can be accessed as follows."
2181,you will need this to authenticate your databricks workspace to access the cosmos db account.,this is needed to authenticate the databricks workspace for access to the cosmos db account.
2182,the data set used in this dashboard is available on kaggle.,the dataset used in this data set is available on kaggle.
2183,"it is called forward as the uncertainty information flows from the input, through the model, to the output.",this is called forward as the uncertainty information is transferred from the inputs through the model to the outputs.
2184,"but wait, i would never ever have a table without indexes, and certainly not run a query on it!","but i would never have a table with an index, and certainly not have run any query on it!"
2185,"the best part, however, is once you are able to keep up spirits and work hard, you will earn decent incomes, and if you grow big, you can convert it into a full-time profession as well.","the best part is that once one is in a good spirit and puts in the work, you can earn decent incomes and as one grows big, one can turn it into a full time job."
2186,an overview of basic descriptive statistics can also be obtained from a data visualization.,visualizations can also provide information on the basics of descriptive statistics of a data set.
2187,companies hire data scientists with completely different backgrounds and sets of skills and ask them to do the same tasks.,"companies hire data scientists from completely different backgrounds and skill sets, and ask them to perform the same kinds of tasks."
2188,then ask your manager or a senior analyst for advice and explain why you came up that approach.,give some feedback from your manager or senior analyst and explain why you chose to follow this approach.
2189,"for each categorical feature, a countplot will be displayed to show how the classes are distributed for that feature.",the labeled feature is denoted by a countplot showing how the classes are distributed for that feature.
2190,for this simple exercise we shall try to find a way to eliminate (or least drastically reduce) the powerlines in the back.,"we will make the following simple exercise, to find a way to eliminate (or at least dramatically reduce) the powerlines in the backend."
2191,"the other dataset i worked with on this project was from hatespeechdata.com, which was a little bit more straightforward and it consisted of posts on reddit and gab that users classified as hateful or not.","the other dataset i used for this project was from hatespeechdata.com, which is a more straightforward dataset consisting of posts on reddit and gab which were classified as hate or not."
2192,"again, in the next section i will give some advice on how to practice your communication skills.",we will again give some suggestions in the next section about practical communication skills.
2193,now the data gets split across the multiple attention heads so that each can process it independently.,"the data is then distributed over multiple attention heads, and processing by each head can be done independently."
2194,the results are grouped by the product line and sorted by the sum of quantities.,the output is subdivided by the product line and sorted by the sum of the terms.
2195,"that is how we received ten search results, enough for a start.","we received ten search results, which is adequate for a starting point."
2196,"this is for good reason, as sklearn has a fantastic catalog of usable models, scalers, tools, and even encoders!","this is reasonable since sklearn provides an extensive catalog of tractable models, scalers, tools, even encoders!"
2197,"i had been following with the corner of my eye the fairness, accountability, and transparency workshop.","the fairness, accountability and transparency workshop was followed by me, with a corner of my eye."
2198,"in this case, implementing gridsearch only marginally increased our accuracy with our lr model.",it is in this case where the accuracy of our lr model increases only marginally for implementing gridsearch.
2199,"to add new user inputs to previous conversations, we can first do:",we can do this first by adding new user inputs to an existing conversation.
2200,"i am a fan of visuals so i will show you how to see the quantum circuit diagram of what you just coded, and to plot the results of our measurement.","i am a great fan of visual information, so i will present how to view the quantum circuit diagram of the quantum code that we just generated and plot the performance of our measurements."
2201,"because standards are high, a little bit of exaggeration can be forgiven.","as the standards are very strong, some exaggeration may be tolerated."
2202,contributions are more than welcome and details about how to contribute is also laid out here.,"contributions are more than welcome, and we provide details about how to contribute."
2203,copy the files project.toml and poetry.lock and place them in the root directory of the project.,copy project.toml and poetry.lock to the root of the project.
2204,"we are have learned hypothesis testing and how to reject or fail to reject the null hypothesis, but a question like this makes me think twice about statistical simulation.","we have trained how to test a hypothesis and how to either reject it or not, but a query of this kind leads me to rethink statistical simulation."
2205,"in other words, an ideal learning agent would choose the simplest function that fits the training data.","in other words, an ideal learning agent would choose the function which fit most accurately to its training dataset."
2206,"the applications range from texture analysis, image filtering, and even text extraction (a feature that can lend itself well to natural language processing).","the applications range from texture analysis, image filtering, and even text extraction (a feature that can be well suited to natural language processing)."
2207,"additionally, i used two strings to line up with the wedge.",we additionally used two axes to align the wedges with one another.
2208,the reason for this problem is one of the assumptions involved in linear regression.,the reason of this problem lies in one of the assumptions that is inherent in linear regression.
2209,"in this case, we will see if the classifier can build a proper decision tree to determine wins from the given team-stats.","let us examine how to build a proper decision tree for the win in the given team-stats, while keeping in view the win-rate."
2210,"you can find the companion jupyter notebook here, where all the presented analysis and results can be reproduced.","it is possible to reproduce here the jupyter notebook that is related to the discussion, where all the analyses and results presented are replicated."
2211,"this may be indicative of players making more experimental choices, whereas more skilled players have a keener sense of the best combinations of teammates.","this might be due to players making more experimental decisions, whereas more skilled players have a greater sense of the ideal pairing."
2212,"so is this level state-of-art really going to achieve a smarter point than the most intelligent species that we know in the universe, that is homo sapiens?","therefore, is this level of state of the art achievable smarter than the most intelligent species we know of in the universe, which is homo sapiens?"
2213,some of the concepts and topics covered might be fairly advanced for beginner-level users.,some of the concepts and topics discussed might be quite sophisticated for a beginner.
2214,regression is a supervised learning technique in which the target variable is continuous.,regression is a supervised learning technique where the objective variable is continuous.
2215,"take your time to understand this line, as we will use this structure many more times in the steps to follow.","this line of reasoning should be studied carefully, as we will use this structure many times more in the rest of this section."
2216,"this is for good reason, because the python ecosystem for just about anything is unmatched anywhere.","this is reasonable, since there is just no other toolkit for python that has such a comprehensive python ecosystem."
2217,"if you have any questions regarding this article or want to connect and talk, feel free to direct message me on linkedin.",direct messages to me on linkedin are also available for further queries and if you just want to connect and have a chat.
2218,"i also would be interested in the coefficients of the sepal length and width, since i am not expecting them to be very high and considerably less than the petal length and width.","as i don't expect that the values for the sepal length and widths of the plants should be significantly greater than those of the petal lengths and widths, i am also curious as to how the sepal widths and lengths are affected."
2219,here we use the input data to build our markovify model.,we describe how our markov model builds upon the input data.
2220,we recently learned what the reduce function does in a previous tutorial.,in a previous tutorial we learned the role of the reduce function.
2221,"finally, we can do an influence analysis of the network.","finally, we can apply network influence analysis."
2222,philipp: i mostly use kaggle to keep up with the latest developments; it is an excellent filter of new techniques that either work on practical and applied problems or do not work.,phillip: i usually use kaggle to stay up to date with what is new; it is a great way to filter out new techniques and methods which either don't work for practical or applied problems.
2223,"such examples include redis, amazon redshift, facebook presto, bigquery, and apache druid.","examples of such tools include redis, amazon redshift, facebook presto, bigquery and apache druid."
2224,"the main stars of the show are going to be recurrent neural networks, maximum entropy control algorithm, and soft actor-critic.","we will be highlighting the recurrent neural network, the maximum-entropy control algorithm and the soft actor-critic as the stars of the show."
2225,this means that we can continue implementing our training loop without any changes!,this means that our training loop is always intact and we don't need to modify it!
2226,one of the more advanced topics in image processing has to do with the concept of fourier transformation.,the notion of fourier transform is one of the more advanced concepts in image processing.
2227,"lars albertsson, founder of scling, described data mesh as one way to scale out large data organisations where data management and governance has become challenging due to the number of teams working in the data platform, in his interview.","lans albertsson, co-founder of scling, has described data meshing as one way to scale out large data-driven organizations where the number of teams that work on an data platform has become a challenge."
2228,"if you want to get extra fancy, you could even come up with a cookie cutter template to automate the structure of your git repositories on initialization.",we can even design cookie-cutter templates that automate the structure build-out of the git repositories at initialization if you are feeling extra fancy.
2229,"dividing learning types into supervised, unsupervised and reinforcement is the most common approach in the machine learning community when introducing the field.","the most common approach in the machine learning community when introducing reinforcement learning is to separate learning types into supervised, unsupervised, and reinforcement learning."
2230,"finally, we add a dense layer with a single unit for the binary output.","finally, we add a dense layer with a single unit for the binary outputs."
2231,the well-known hcm values of the level of service (los) represent the specific domain knowledge data for the traffic state estimation process.,"the well-known hcm and lan services (los) metrics, also called domain knowledge permutations of the traffic state estimation process, provide particular domain knowledge about the utility value of traffic states."
2232,efficiency can be increased by vectorizing operations that would normally be done in a loop.,operations that are normally performed on a loop can be vectorized to improve the efficiency.
2233,overfitting is when a model you develop fits so well during training that it even fits the unnecessary and not required training points like the outliers or noise points into your solution.,"overfitting is when the model you construct fits well enough during training that it actually fits the unneeded and unneeded training points, such as outliers or noise points, to the hm-based solution."
2234,"in reality, when we have no knowledge of what the underlying function looks like, this feature of active learning could really help us locate the most valuable samples to improve the model accuracy, thus driving down the overall model training cost.","however, this feature of active learning may be actually crucial to learning the true performance of a model, thereby reducing the total model training cost when we don't know the appearance of the underlying feature."
2235,"from an initial view, there are a few conclusions we can make about these plots.",we can derive a few conclusions about these plots from our initial view.
2236,"in simpler words, if one wants to arrange the time series data in patterns like monthly, weekly, daily, etc., this function is very useful.","the in-line filter is used for the purposes of classification, which is more generally useful when studying a time series data in patterns like monthly, weekly, daily, etc."
2237,guild integrates tensorboard as a visualization tool for runs.,the guild implementing visualization for runs is tensorboard.
2238,"apart from american universities, some canadian universities offer excellent graduate programmes and a prolific environment for data professionals.","although we don't focus on american universities, some canadian universities have excellent graduate programs and a prolific data science community."
2239,"for me, these problems provide are different point of view for linear regression.",these are interesting problems from the perspective of linear regression and in my opinion provide a new perspective on those problems.
2240,"as we can see, the for loop took less time to execute when compared to the reduce function.",we can see that the for loop has less execution time compared to the reduce function.
2241,"chart.js offers several other types of charts such as tables, bar charts, pie charts, scatter charts, and more.","chart.js also offers a range of other graph types such as graph tables, bar graphs, pie graphs, scatter graphs, and more."
2242,"while this seems like a highly contrived example, real cases abound in media.","while this may seem like an extremely contrived example, there are many real cases abounding in media reports."
2243,"by selecting a range like the one above, try to consider whether you need a lot of particular events or you want them to be a rare thing.",it is important to consider whether you need many unique events or prefer them to be rare events by selecting a range as above.
2244,"at the end of our analysis, what questions do we want to have answers to?","finally, what questions would you like to have answered at the end of our analysis?"
2245,"if we were to draw balls one at a time without replacing them, what is the probability of getting a black ball on a second attempt after drawing a red one on the first attempt?","if we can draw one ball at a time without replacing any of them, what is the probability of picking a black ball on the second attempt after drawing a red ball on the first one?"
2246,"registering for a free alwaysai account gives you access to different computer vision model types as well, so you can use the python interpreter to explore object detection, image classification, and pose estimation next!","we are working on improving object detection and image classification, and pose estimation, and we hope that the python interpreter can help you tackle these issues as well."
2247,but every situation is different and must be evaluated on its own terms.,"however, every circumstance is different and must be evaluated on its own."
2248,but i realise that many people get stuck on an infinite loop before beginning to work.,but i realize that many of us get stuck in the infinite loop before starting work.
2249,"because histogram-based boosters bin continuous features, this is a nice option.",this is a nice choice since histogram-based boosters do bin continuous features.
2250,"for those few edge detection algorithms that perform better than canny, they usually require more time and computational power, which make them poor candidates for real time detection.","for example, while canny and ssd are only a few edge detection algorithms which perform well, they typically require more time and computational resources, making them poor candidates for real time edge detection."
2251,"your duties include end-to-end (quality) controlling and oversight, working with automation tools, full integration into business processes, and providing the corresponding ai and machine learning support.","they are responsible for providing end-to-end (quality) control and control, working with automation tools, full integration to business processes and providing support in their development for ai and machine learning."
2252,"from the points stated in this article, we can figure out that it is not a compulsory requirement for you to pay money in order to master the essentials of data science.","following this paper, we have come to the conclusion that paying the fee to learn essentials of data science is not mandatory."
2253,"in this case, the action was not intended by the decision, but it happened due to a mistake.","in this case, the action was not intended but took place by error."
2254,"before diving deep into this tutorial, i recommend reading first the previous two articles: extracting rich embedding features from pictures using pytorch and resnext-wsl and manifold clustering in the embedding space using umap and gmm.","first i suggest first reading the previous two articles: extracting rich embedding features from images using pytorch and resnext-wsl, manifold clustering by use of umap and gmm before diving deeper into this tutorial."
2255,"there are several public datasets and competitions available for you to use, learn, and grow your career.","work on the cloud is now available through a variety of public datasets and competitions to learn, experiment, and grow."
2256,"to picture this problem, in a real setting, it is actually a giant data frame with hundreds of thousands of rows, so we definitely hope to have an automatic solution to achieve that.","if we picture the problem as a giant data frame of hundreds of thousands of rows in our real world setting, the auto solution that is guaranteed to be available to us would certainly be a dream."
2257,the simplest query is to view all the columns in a table.,the simplest query is to view all the rows of the table.
2258,"for infrastructure, you should understand how to deploy models, and how to make them available for business purposes.",one needs to understand the various deployment strategies and how to make these models available for business purposes on the infrastructure.
2259,"in this instance, there were many missing values for the location column because only a handful of twitter users have their correct location on their bio.",this is because only a few of twitter users having their correct location in their bio sentralities have a set of correct values for the location column.
2260,"it is generally recommended to use higher level apis, such as lightning, fast.ai or skorch.","higher level apis like lightning, fast.ai or skorch are generally recommended."
2261,"data science is a concept to unify statistics, data analysis and their related methods in order to understand and analyze actual phenomena with data.","the concept of data science is the attempt to unify statistical, data analysis and a host of related methods for understanding and modeling real-world phenomena using data."
2262,the flexibility of artificial neural networks can be understood by looking at the following properties:,we use the following properties of artificial neural networks to understand their expressiveness.
2263,"minimalfcparameters: contains a very small and basic set of time-series features (min, max, standard deviation, and so on).","minimalfcparameters: contain a very restricted and basic set of time-series features (min, max, sd, and so on)."
2264,the nice thing of open source is that there are many alternatives.,the nice thing about open source is that there are so many alternatives.
2265,"to execute a bash command, you will need to add the following code snippet:",let us add the following snippet of code to the bash command::s to execute bash.
2266,i know not everyone is a fan of mathematical proofs so i will try to convince you with a small simulation.,"because not every one is very fond of mathematical proofs, i shall try my best to convince some more with a small simulation."
2267,note that the data is printed (queried) in the same order as you inserted it.,note that the data (query) is printed in the same order as it was inserted.
2268,then i can do my assertions and checks as i mentioned before.,"then, as explained above, i can prove and check my statements and arguments."
2269,"(please note that i have renamed the folder to nuuk here, the one that will be downloaded will have some long alphanumeric name indicating the satellite, seeing period etc)","note that i have renamed the file type from nuuk here; the one which is downloaded will have some long alphanumeric label to indicate the satellite, the seeing period, etc)."
2270,"despite dozens of people that could testify to his alibi, including a police officer, a jury recommended a life sentence.","a juror has recommended a life sentence for the defendant, in spite of dozens of witnesses whose pleadings might support his alibi, including police officers."
2271,"collect data you need for the problems at hand and a bit more, put together a technology that solves the current problem and provide flexibility for future.",we collect all the data we need for our current problem along with a little bit more and build a technology that solves the problem currently and will allow flexibility for future work.
2272,"in excel, there is a build-in feature of combo chart.",combo charts are a built-in feature of excel.
2273,we simply start by taking a guess and plug the guesses for those values into the formula to get a price.,"if we want to obtain a price, we simply start with a guess and plug the guesses of those values into the formula."
2274,i view this advancement as a way to add previously elusive contextual and metaphorical understanding to an ai language model.,we regard this as an achievement that contributes a broader theoretical understanding of the ai language model by adding contextual and metaphoric understanding that was previously elusive.
2275,this is one of the only clustering metrics we can use as it does not require labels in the training data.,"this is one of the only clustering metrics we can use, since it does not require labels in training datasets."
2276,catboost is a boosted decision tree machine learning algorithm developed by yandex.,yandex developed a decision tree boosted decision tree (catboost) machine learning algorithm.
2277,i am going to walk you through the lens of social image ai.,i will take a look at the ai through the lens of social image representation.
2278,"i promise these next few episodes, the extended functionality that we will automatically obtain from building on this package is going to be worth it!",i promise that these next few episodes will pay off in the extension functionality that we will get as a result of building this package!
2279,"even though it is beyond my reach, i want to present a convincing factor that can govern a sustainable solution for the growth of urban areas in already choking cities.","however, i would like to present the convincing reason why this is incomparable to my goal, that urban growth is a sustainable growth solution that improves the already congested cities."
2280,"after running the sql code from the project, you should now have the following objects in addition to the initially created database objects:","after executing the sql code in this project, the object you need to consider is now the following addition to the originally constructed database object."
2281,"the most basic metric is accuracy, which gives the fraction of all predictions that our model got right.","the most basic one is precision, which is the fraction of all the predictions that our model is right in making."
2282,watch the last one only if you are interested in knowing how the indian education system works.,we watched the last one only for curiosity about the workings of bcn.
2283,"at each learning iteration, we label a new sample for which the current model is expected to make the largest prediction error.",we label the new sample that should give the largest prediction error to the current model at each learning iteration.
2284,"as you could see in the chart, we represent embeddings with a set of small colour coded squares for the sake of easy understanding.",we represent embeddings by a set of small colour-coded squares for ease of comprehension as shown in fig.
2285,to get the final score here is the code i developed followed by the result i received.,i am following the code i created with the result i got to get the final score.
2286,"moreover, we might not even know that we achieved this remarkable feat, either because the nature of ai intelligence will be too different from ours or because the ai might actually be too smart to let us know.","furthermore, we may not even know that our method has passed this step, either because it is inherently atypical for the ai intelligence or because our results might actually be too smart to be revealed."
2287,serverless is one technology that makes it easier to keep up.,a particular technology making it easier to scale is the serverless one.
2288,"as the saying goes, an image is worth a thousand words, and we should take very seriously how tools like this can affect misinformation spreading in the future, among other problems like how to recognize the value of training data of this kind of algorithms, like shown in the tweet below.","one might think that tools like the one shown in this case are worth a thousand words, and we should carefully consider how such tools will affect misinformation propagation in the future, among other challenges such as how to recognize the valuable features of training data of such algorithms as was shown in the tweet below."
2289,"i may have not covered some low-level details of this paper since that would make this article quite long, but i hope that you got a high-level overview of the intuition behind it.","some low-level details have not been covered here, as this could make this article rather long, but i hope that one can get a high-level, general, understanding of the intuition behind it."
2290,tensorflow lite deals with the first two methods and does a great job in abstracting the hard parts of model compression.,tensorflow lite follows the former two methods and does a good job of abstracting the hard parts of model compression.
2291,an exhaustive list of resolution definitions can be found in the following table.,the following table has an exhaustive list of resolution definitions.
2292,"the rationale for this selection is that in the center, the features show similar behavior between the selected areas and the non-selected areas, while in the sides, either a high or a low value is observed, making the distinction between them obvious.","this choice is justified by the fact that in the center of the set, the features seem to behave similar to the selected areas and the unselected regions while the selected regions show either high or low values, making the distinction between the two obviously."
2293,"again, leveraging all of the work we had done in applied ml, how do we make it really easy and really friendly to be able to break down the predictions of the algorithm by groups, et cetera?","again, given all of our work in applying ml, how can we make it really simple and really user friendly for groups to break their predictions, et cetera?"
2294,"but, much in the same way that unit tests alone are insufficient for software reliability, data testing by itself cannot prevent broken data pipelines.","however, data testing alone can not prevent broken data pipelines, as unit tests alone are insufficient for software stability."
2295,"i have only included the date, close, volume, and symbol columns.","i only included row counts, closes, volumes, and symbol columns."
2296,"before i start throwing code snippets at you, i wanted to walk through what we are trying to accomplish and how we are going to make it happen.",i wanted to briefly outline what we try to accomplish and to explain how to achieve it before i start throwing code snippets at you.
2297,"in the right image, we can see the joint density associated with ability and difficulty for a sampled person-question pair.","we can see that for the sampled person-question pair, the joint denseness is correlated with capability and difficulty in the right image."
2298,"combining all this in a function that essentially populates the n x m matrix with option values, and returns the option value v , the times t and the stock prices s .","such a merge function essentially enumerates the choices that occur in the n x m matrix, and returns the vs of each option value, timest and stock prices s."
2299,"in the final plot above, we can see only the eeg channels that have color associating the signals with their sensor locations.",we can see only the eeg channels that have color associating the signals with their sensor positions in the final plot above.
2300,"the meal for the algorithm is ready, and this is the salt at the end.","we are now ready to serve the meals to the algorithm, which serves as the salt."
2301,this way we can make sense out of data with simple and powerful tools before getting ourselves busy with any model or more complex tasks.,"to do so before getting bogged down in some complicated model or more sophisticated job, let us look at some simple and powerful tools that help us make sense of the data."
2302,we often place a positive reward value for the state that we want the agent to get to and place a small penalty (negative reward) for each extra step taken by the agent.,we often place a value of positive reward on the states which we want the agent to get to and place a small penalty value (negative reward) for every extra move the agent makes.
2303,following rules (whether programmed or learned) is at the lowest level of competence for dreyfus.,the basis of competence for dreyfus is the following rules (when written or learned).
2304,"however, tuning a model is pretty much trial and error.","however, model tuning is quite much a trial and error process."
2305,"now, there are two types of generative network architectures possible depending on the procedure they use to perform the task.",to now we note that the various processes used by various generative network architectures can produce two types of generative net architectures depending on what they handle.
2306,decision variables: the variables that are used as input to decide the final output are known as decision variables.,decision variables: decision variables are variables that are used as inputs to decide the final output.
2307,many tools you will use during your studies and career are available through ml libraries and frameworks.,ml libraries and frameworks offer many tools that one would want to use during his or her studies and career.
2308,"using the k-d tree, the complexity is reduced to o(dnlogn), which is significant improvement when n is large.","then, the complexity is reduced to o(dnlogn), a significant improvement when n is large."
2309,"after the party, he goes home with high hopes and implements the concept he had in mind.","after the party, he heads home with high hopes and implements the concept he had envisioned."
2310,"the whole model can be wrapped, or you can wrap certain layers that you want to.","any whole model may be wrapped, or you may want to wrap specific layers."
2311,the indirection tells dbt how each step is related to other steps and allows you to run any subset of that transformation pipeline with dbt taking care of the execution order defined by the dependencies.,"this indirection tells dbt how each step is related to other steps and allows one to execute any subset of a given transformation pipeline, with dbt in charge of determining the order of execution, defined by the dependencies."
2312,"new addition taylor hall is projected to do a lot of good for this team, which is awesome.","it is hoped that taylor hall, our new addition, will do a lot of good for this team, which is excellent."
2313,"assume we are comparing three countries, a, b, and c. we need to apply a t-test to a-b, a-c and b-c pairs.","assume that we consider three countries, a, b, and c, and our testing methods are t-testing on the a-b, b-c, and b-c pairings."
2314,the best solution is to overcome them and do the best of your abilities.,"then, overcome the blockages and bring out the best of one s abilities."
2315,"many thanks for your time, and any questions or feedback are greatly welcomed.",i thank the referees for their time and any comments or suggestions are welcome.
2316,the objective is the quantitative measure of system performance that is to be minimized or maximized.,the objective is to provide a quantitative measure for the system performance that must be either minimized or maximized.
2317,they work well with context managers (with blocks) because we must remove the hook after using it.,"their arguments have worked well with context managers (with blocks), but we must remove the hooks after we use them."
2318,"common sense dictates setting up a local (cpu based) environment, with a small subset of training data, in which you verify, to the furthest extent possible, that everything is working as expected.",good common sense entails setting up a local (cpu-based) environment that contains only a small portion of the training data so that it is as exact as possible.
2319,"(well even though it has become a toy dataset now, it is diverse enough to show the approach.)","it is well-founded because now that the dataset has turned into a toy, it is diverse enough to illustrate the approach."
2320,"also, visit the resources page on my website, a place for great books and top-rated courses, to start building your own data science curriculum!","for a start on your own data science curriculum, see my resources page, which features the best book recommendations, and top-rated courses!"
2321,maybe even a macro to grab the data and put it in ms excel would be clever and useful.,perhaps it would even be a smart and useful idea to create macros for grabbing the data and putting it in ms excel.
2322,an experiment is a process of observation where the output cannot be predicted with certainty due to random effects.,a pilot experiment is a process in observation where the output can not be predicted with certainty due to random effects.
2323,the above code (if called in a context where frame is a fitdatamessage object of message type record and has latitude and longitude data) will produce an output something like:,"the method outlined above is defined (where a frame is defined as a fitdatamessage object which has the latitude and longitude information) and produces an output which is something like: """
2324,"first, movement range maps measure mobility at the level of administrative units.","first, mobility distribution maps measure tuple-level mobility in an administrative sector."
2325,the work procedure and stress involved in this cycle may not be suitable for everyone who is planning to work on data science in the future.,we emphasize that this cycle can be stressful and not suitable for everyone planning to work in data science in the future.
2326,tying all these terms together gives us the expected reward for a state-action pair:,so we can formulate the expected payoff when a state-action pair is connected through the interplay of all these terms together:
2327,"and you need the whole source code of this project, here is the link:","for complete source code, see the following."
2328,"nevertheless, i tried out other methods as well, but not mentioning here to keep it short.","nevertheless, i tried a number of other methods but i will not mention them here for brevity."
2329,"once i understood all the problems at hand, i began assigning different people the issues to tackle.","once i understood all the problems at hand, i began assigning the problems to different people."
2330,these functions need to take a dataframe as input and return a dataframe.,such functions need to accept an input as a dataframe and return the result as a dataframe.
2331,"peng has a very unique style of writing that is both direct, but also containing style.","pengs writing style is very different from all other languages: its writing is largely written in a direct, but also containing style."
2332,you can skip this section if you are in a hurry to draw the graph :).,"if you need to draw the graph in a hurry, skip this section:)."
2333,first thing to do is spin up a conda env and load it up with everything we need (from the anaconda prompt):,"the first thing to do is spin up a conda env, and load all the elements we need to prepare the image (from the anaconda prompt) to the image."
2334,"you agree with your client to have a prototype; that is, the code to preprocess the data and to train the model together with a document summarizing your analysis.","if you want to share a prototype with your client, that is, the code to preprocess the data and to train the model together with a summary of the analysis, then they should be offered to the client."
2335,a modern data lake architecture expects compute resources to be supplied by external sql query services.,the state-of-the-art data lake architecture expects the compute resources to be supplied by external sql query services (sqlqs).
2336,recommendation systems are certainly one of the main success stories of machine learning in practice.,recommendation systems are clearly one of the most successful applications in practice of machine learning.
2337,"this situation can be slightly improved by the random selection of features, not completely solved though.","a random feature selection approach can slightly improve this situation, but is not entirely sound."
2338,"it means it makes sure that the data which is being passed is valid, if not otherwise it returns an error.","in other words, the data passing is made sure to be true if it is not otherwise it returns an error."
2339,"sharing a web interface to an internally hosted model can surpass all of the above problems, allowing others to test a model without needing to access datasets, reproduce training, replicate preprocessing steps, or debug versioning and environment mismatches.","sharing the internal model s web interface over-rides all the problems of the above, allowing others to run tests on their own datasets, reproduce training errors, reproduce preprocessing steps, or debug version re-preparation and environment mismatch."
2340,"however, i want to start the new year with a lot of optimism and euphoria.","nevertheless, i want the new year to begin with much optimism and positivity."
2341,"before we begin the analysis, we will first active the r packages that we will need in this example:",we first activate all the r packages that we will need in this example.
2342,"our goal is to fetch that data, store the data in a database and then schedule that script to be re-run automatically every year.","our approach is to parse that data, store data in a database, and schedule this script to run on a regular basis throughout the year."
2343,"after you come up with an idea, specifically search for a dataset.","when a story idea is generated, one should specifically go to the dataset and look up datasets."
2344,i previously wrote about how i first entered the data science field.,i previously explained how i first entered the field of data science.
2345,recall represents what proportion of actual positive cases are identified correctly.,recall metric is a measure of the proportion of correct estimates that relate to actual positive instances.
2346,"these factors can cause fluctuations in price given the same conditions, this means that houses with the exact same features (same size, same location) can possibly be priced differently depending on the year sold.","different conditions could cause price fluctuations, meaning that houses having the same features (bigger lot, same place) may possibly have different prices depending on the year of sale."
2347,"when talking about explainable-ai, you can be sure that somebody will come out with this plot:","when discussing explainable-ai, it is almost guaranteed that someone would come out with this plot:"
2348,"before coming to details, i will first create a sample dataframe.",let us first construct a sampled dataframe before coming to details.
2349,"in the following analysis, i am going to use the online retail data set, which was obtained from the uci machine learning repository.",in the following analysis i intend to use an online retail dataset obtained from the uci machine learning repository.
2350,it means that you watch some youtube videos or online courses or read blog posts or arxiv papers and then try the things out yourself.,"in other words, if one is interested in online learning or watching youtube videos or reading blogs and arxiv papers, one can make a first attempt at implementing it yourself."
2351,depth images contain the depth values of a scene in the form of distance from the camera in meters for each pixel in the image frame.,depth images describe the depth values of the scene in the form of the camera-to-camera distance in meters per pixel within the image frame.
2352,you can see a web version of this sample project here and check out another article on how to deploy code with streamlit in the link below.,we share the web version of the sample project listed there and link to an article that explains how to deploy code with streamlit.
2353,"therefore, they have proposed the much faster leiden algorithm which guarantees that communities are well connected.","he proposed a much faster leiden algorithm, which guarantees that the communities are well connected."
2354,"taken individually, each tiny project might not feel super important to me.",each little project might not seem super important when viewed in isolation.
2355,the fact that this has happened suggests that i should probably weight my regressions based on ice time or games played in the future.,this situation suggests i should probably weight my regressions using ice time or future games.
2356,"the code here should help you to quickly get started mining your own text documents, and you can go to the project repo here for some additional plotting functions and to see the data we extracted!","here are a few additional plotting tools and the raw data we extracted, in case you want to jump right into text mining, our code is in the project repo!"
2357,"here is where things get messy, because there are two parts to this process: learning the graph itself and learning the parameters of the graph.",this is where things get tricky since this step requires two steps: learning the graph as a whole and learning the parameters of the graph itself.
2358,"the applications of such analysis include marketing influence maximization, fraud detection or recommender systems.","these analysis techniques are applied to applications such as marketing influence maximization, fraud detection and recommendation systems."
2359,this is a problem that sql query engines are trying to solve.,this is the problem that sql query engines try to solve.
2360,"however, the correlation coefficient you make if you call df.corr() is saying something subtly more specific that what i mentioned above.","however, the correlation coefficient that is produced when we call df.corr() makes it say something less explicit than what we have discussed above."
2361,"to solve this issue, we can use a tool with an interface.","to address this question, we can turn to tools that are interface-based."
2362,what you need is a semantic search on top of the retrieved images with tags.,the most important one is to perform a semantic search on top of the retrieved images with a set of tags.
2363,this tokenizer is very flexible since it is agnostic of the base tokenizer that was used to generate the tokens.,this tokenizer is very flexible since it is agnostic of the core tokenizer used for generating the tokens.
2364,i think we have started the new year with a lot of optimism and euphoria,i do believe we started the new year in a very positive and optimistic fashion.
2365,"first, we will install fastapi by running the following command: pipenv install fastapi","first, we start the command pipenv install fastapi to create a bind with the following statement."
2366,"additionally, it allows creating environments in python, which contain different versions of your python packages.","furthermore, it provides an easy method of creating python environments that have various versions of the python modules."
2367,"network security can be looked at from various dimensions, such as:",network security can take place from the perspective of different dimensions such as: a view of the system from the following perspective
2368,"keep in mind that the first number corresponds to the coefficient on u, the second corresponds to the coefficient on v.","note that, while the first number corresponds to the coefficient of the utm, the second one corresponds to the coefficient of the vtm."
2369,"when working on more complex projects and or product within the area of data analytics, engineering and science an agile methodology is the way to go.","an agile methodology is beneficial when working on more complex projects, or products that are of data analytics, engineering or science focus."
2370,all of these similar attention calculations are then combined together to produce a final attention score.,"then, all these similarity computations are combined to generate a final attention score."
2371,"remember, the map function will return a map object, which is an iterator.",recall that the map function returns an iterated list containing maps.
2372,"since i created this model, i am obviously biased, but to me, this does seem like a coherent and easily interpretable topic!","since i started this model, i am probably biased, but to my knowledge this is a coherent and easily interpretable topic!"
2373,:) shoutout to david chong for reviewing this article.,a shout out to david chong for reviewing this paper.
2374,one way we can can remedy this is by making use of use of the homography matrix.,exploiting the usefulness of the homography matrix is one way in which we can rectify this.
2375,"to connect with me or find more content similar to this article, do the following:",the following will help you connect to me or find more articles in the same category.
2376,we can feed this data set into an algorithm such as decision tree to represent this game.,"we can use this dataset to train an algorithm such as the decision tree, which can represent the game."
2377,"either you might be buying new stocks, selling what you already have, etc.","either you are buying new stocks, or selling what you already own, etc."
2378,"in this case, we have selected same or very close mean values for each group.",we selected for each cluster mean value that is either identical or very close to it.
2379,make sure you know your market value and a good time to convey your expectations.,tell them the price at which they expect to trade and the time they expect to sell.
2380,"in this case, the yearly temperature is viewed as a function in time and every observation corresponds to a function, which describes the yearly temperature.",we are allowed to consider the temperature as a function of time and each observation corresponds to a function that describes the temperature in that year.
2381,"what we might not look at, even though this information is present to us, is other less relevant attributes, like eye colour or speed of reflexes.","the other, less relevant features, such as eye color or reflex rate, are what we might not use, even though the information is there."
2382,"if we plot this function, we end up with a curve that is undefined on the y-axis.","if we plot this function to the y-axis, we end up with a curve that is not defined."
2383,"they are a great resource to learn more about machine learning in general, and they have lots of useful tutorials on how to implement nlp and other machine learning pipelines.","they are an excellent starting point for learning more about machine learning in general, and have lots of helpful tutorials on how to implement nlp and other machine learning pipelines."
2384,one theme you may notice here is that teams in the north division are more likely to make the playoffs than teams outside of the north division who are projected to earn a similar amount of points.,we note one of the themes here: teams in the north division tend to make more appearances in the playoffs than teams outside the north division which are predicted to gain similar amount of points.
2385,"in a previous post, i spoke about the importance of profiling the runtime performance of your dnn training sessions as a means to making the most of your training resources, accelerating your training, and saving money.","in an earlier post, i proposed profiling the runtime performance of dnn training sessions as a way to make the most of its resources, accelerate training processes and save money."
2386,"however, it would be interesting to see how the price range of these apartments vary with respect to the locality.","however, it would be interesting to see how the prices for these apartments change based on the locality."
2387,choose a license and provide a readme file for your project.,choose the license and provide a readme file as part of your project.
2388,"you will know when your next call is and can come to the gathering with different topics, questions, and more.","so, when your next call is, you know exactly when that is and can bring different topics, questions, and more to the meeting."
2389,"however, it has its own drawbacks, which as mentioned earlier mostly boil down to the choice of prior.","however, like mentioned before, priors have their own inherent drawbacks."
2390,you can actually specify multiple frames for each slider step that will all be cycled through when the slider is moved to that step.,you can actually specify for each slider step multiple frames that will cycle through all frames until the slider moves down that step.
2391,the first step is to break-down the image in multiple patches and flatten them.,"the first step is to separate the image patches into multiple patches, and smooth them."
2392,"developing strong sql skills will allow you to take your analyses, visualizations, and modeling to the next level because you will be able to extract and manipulate the data in advanced ways.","obtaining strong sql-first skills will enable you to take advanced way of handling the data and taking analysis, visualization, and modeling to a next level."
2393,"this issue brought me to sqlite, a built-in, lightweight database for python.","this question led me to sqlite, a robust, lightweight database development tool in python."
2394,"on the other hand, classification problem concerns with finite, discrete categories, such as predicting whether a satellite imagery is experiencing any rainy event or not.","on the other hand, classification issues concern finite, discrete categories, such as predicting if a satellite image experience rain or not."
2395,"as a concrete example, we have customized a catalog to support external information analyzer data rules as a new asset type, and run a script to import all external data rules to our catalog.","for instance, we customized a catalog to represent the extrinsic data rules as a new asset type, and run the aggregation script that imported every external data rule into our catalog for a concrete example."
2396,"the struggles, victories, and journeys, will be different for each individual.","the process of struggling, winning, and traveling will be different for each of us."
2397,"so, from within workbench, we can go ahead and create our first schema and tables.","therefore, from the workbench we can create our first schemas and tables."
2398,"it contains chapters on linear algebra, matrix decomposition, and probability theory and distribution.","section includes lectures on linear algebra, matrix decomposition, and probability theory and probability distributions."
2399,the model.score is then run which just goes to show exactly what this library function does and how it works.,the library function is then executed using model.score which just goes on showing exactly what the library does and how it works.
2400,"despite these critiques by marx, emerson, snow, and others, proponents of this philosophy of science might have defended its validity on the basis of its practical successes in terms of technological applications.","we may speculate that despite these critiques by marx, emerson, snow and many others, the proponents of this philosophy of science have defended its validity due to its practical success for technological applications."
2401,"in this post, we will go over the above concepts and as well as the concept of bootstrapping to estimate the sampling distribution.",we first review the above concepts and then add the bootstrapping notions to estimate sampling distributions.
2402,"as mentioned earlier, if the recaptcha service suspects a bot is trying to interact with a website, it will present a test to confirm you are human.","as explained before, if a recaptcha service suspects that a bot has tried to interact with some page, it shows a test which guarantees you are a human."
2403,"to deal with some of the anomalies mentioned above, engineers in academia and the industry came up with isolation levels.",engineers in academia and industry have formulated isolation degrees in order to deal with some of the above mentioned problems.
2404,"to create a cartoon effect, we need to pay attention to two things; edge and color palette.",we make a cartoon effect by paying attention to two things; the edges and the colourings.
2405,your fellow learners will be as motivated as you are and everyone has a common goal.,"the motivation from each learning group is same as yours, and everyone has the same goal."
2406,"starting last summer, i focussed more and more on the journey of becoming a better data scientist.",i started last summer concentrating my attention to my own path of becoming a better data scientist.
2407,"often touted as a method to learn concepts quickly and thoroughly, i further believe that the feynman technique is the perfect method to help you write better data science articles.","the feynman technique is, at the same time, a well-proven method for data science articles, and has been highly touted as a means to learn concepts in a speedy and thorough manner."
2408,"for example, the microtubules could be in a quantum superposition of different states and they could even be entangled with other microtubules, possibly spreading the quantum state across the human brain.",the microtubules in our model could be in different quantum states or it could be co-entangled with others to spread the quantum states in the human brain.
2409,you have to write a small function to match the names between the two.,a small function to map between the two terms must be written.
2410,"at this time, we have four possible states with equal amplitudes and equal measurement probabilities.",we have four possible states with equal amplitudes and equal measurement probabilities at this point in time.
2411,"to call this api you need to have a key, which is a unique id that is automatically generated against each new user by the census bureau.","this api needs a unique i d of the new user, and it is generated automatically from the census bureau for each new user to call."
2412,this enables us to perform super fast searches on the reviews text.,the results enable us to perform very fast search on review text.
2413,there are definitely more about how one can go from the fundamental gp to more advanced versions and achieve fascinating analysis.,"in fact, gp-based approaches can certainly lead to more sophisticated versions resulting in fascinating analytical results."
2414,"before your friend called, how strong was your belief in her commitment to dinner plans?",how strong was your belief about her commitment to dinner plans before she called you?
2415,"in this data source, government responses across countries are classified into different groups and quantified by the number and stringency level of measures taken.",this dataset categorizes the policy responses by country into different categories and quantifies the number and the stringency of policies taken by these countries.
2416,below are some examples of the high-level calls that the shutil module provides for some basic file operations:,some examples of high-level functions that the shutil module has in order to perform some basic file operations are given below.
2417,constructing a decision matrix is the best method to help in the selection of a software program.,constructing a decision matrix is an effective tool for helping to select a software program from a data.
2418,"data engineers, ml engineers, data scientists, and many other specialists can and should always have the advantage of choosing the right tool and the right approach for the process at hand.","the advantage of this approach is that it has the potential to and should always give the advantage to data engineers, ml engineers, data scientists, and many other specialists in choosing the right tools and approaches for the task."
2419,"intuitively, we can say that the p class is a problem for which there are fast algorithms to find the answer.","intuitively, we can say that the p class is a problem for which fast algorithms exist for finding a solution."
2420,there are two main reasons why you should invest your time in learning about logistic regression before going further.,"before going on to discuss statistical recurrences, there are two main reasons why you should invest your time to learn logistic regression."
2421,"spatial info: an irish bar in denver, colorado","spatial information: an irish bar in denver, colorado"
2422,"next, we create an instance of the basemap class, passing a large group of parameters.","next, we create an instance of the basemap class, passing through a large parameter set."
2423,the green curve shows the true data while the red curve describes the expected (average) predicted of the model over all datasets.,"the green curves imply the true data, while the red curves imply the typical predicted values of the model over the different datasets."
2424,z(u) can represent the ph of a soil for instance or temperature in the air.,"for example, z(u) can represent soil ph or atmospheric temperature."
2425,we can use the reduce function to find the sum of an iterable object.,we use the reduce function to find the sum of the iterable graphs.
2426,"the decoder reverses the process, turning the vector into an output item, using the previous output as the input context.","the decoder then reverses the process, turning the vector into an output item, using the previous output context as the input."
2427,it helps reduces bias where policy is still chosen according to the values obtained by the current weights.,this approach helps reduce bias when the policy is still chosen according to the value of the current weights.
2428,"please follow my narrative below, so you can understand what it means,","we shall now explain, following the following account, what I mean."
2429,"this diagram is nice, but it looks more amateur than professional.","this graph is interesting, but looks more amateur than professional."
2430,the conversion rate from impression to quantities ordered with fast-shipping increases as s-value increases.,"the s-value increases with the s-value, and the conversion from impressions to fast-ship quantities becomes higher."
2431,we create a pandas dataframe to store all the distances.,we initialize a pandas dataframe to store the array of all distances.
2432,"azure cosmos db free tier makes it easy to get started, develop and test your applications, or even run small production workloads for free.","azure cosmos db is free in the core data store, providing a great deal of power for starting and development of applications, and for running small scale production workloads."
2433,here is how we can create a scatter plot in tableau:,we show in fig.
2434,"whether or not to put contour, and deciding on the color and width of the contour is up to you based on the aesthetic detail you want to include in your word clouds.","it is personal preference, and whether we embed a contour or not, and also choose the contour s color and width based on the aesthetic detail you wish to include in a word cloud."
2435,"due to the lack of viable alternatives, the earliest adopters of the modern data stack and most large tech companies resorted to building their own in-house solutions.","the early adopters of the state-of-the-art data stacks, along with most of the giants in the technology industry, have turned to developing their own in-house solutions due to lack of feasible alternatives."
2436,"if we zoom in on where multiple of the robotic companies converge, they have a lot of different capabilities and almost always some overlap with related systems.","it is clear that many robotic companies have a wide range of capabilities and almost always some overlap with other related systems, if we zoom in on the location where they converge."
2437,"data science is a broad field and it overlaps with many established fields like computer science, statistics, mathematics, engineering, etc.","data science can be considered as a broad field, and has overlapping relationships with many well-established fields such as computer science, statistics, mathematics, engineering, etc."
2438,"over time, the generator and the discriminator compete against each other, both becoming better and better.","the generator and discriminator compete over time, making both of them better and better over time."
2439,"days after our initial attempt, we were still struggling with bugs related to kfdef and kustomize manifests.",we still struggled with bugs related to kfdef and kustomize manifests days after our initial attempts.
2440,"and indeed, if we cluster the different age groups of the subjects, we see this:",this is indeed what we observe when clustering the different age groups of subjects as follows.
2441,the algorithm definitely picked up a feature set common to all mushrooms of the agaricus genus.,it would appear that an object that has most similar features to mushrooms from the agaricus genus was spotted by the algorithm.
2442,"so, how can you advance and solve real-life data problems without achieving perfection in every python command?","so, without achieving perfection for each python command, how can one advance and solve real-life data problems?"
2443,why is cross-entropy chosen as the cost function for multi-class classification?,why choose cross-entropy as a cost function to perform multiclass classification?
2444,note: i defined the convlayer and convblock as subclasses of nn.sequential.,note that i have defined convlayers and convblocks as subclasses of nn.sequentials.
2445,"to solve this problem, the team at google has developed an open-source package, causal impact on r, using bayesian structural time series.","google has developed an open-source tool, causal impact on r, which uses bayesian structural time series to solve this problem."
2446,"the metadata.name field is important as we have to specify this in a later stage, so be sure to remember it","this is important, because we will need this in later stages, so be sure that we have put it in the metadata.name field."
2447,"reach out to barr moses or the rest of the monte carlo team, and attend our next data observability webinar.","for more information, contact barr moses and the rest of the monte carlo team, and attend our next data observability webinar."
2448,this is a very valid question and before actually jumping to any concrete code you should be very clear about what algorithm you want to use and if that really is the best option given the dataset and the problem you are trying to solve.,"this is a valid issue, and one should be very clear about which algorithm is being used and if it indeed is the best possible option based on the data and the problem you want to solve."
2449,"to explore this, i made a bunch of twitter api calls to enrich the already very valuable dataset at the trump twitter archive.","so to explore this, i implemented a number of twitter api calls to enlarge the already-very valuable set of twitter tweets in the trump tweet archives."
2450,"as you might expect, you can index symbols of the oddframe to call keys in the lookup dictionary:","as one might expect, symbols in the oddframe can be indexed to point to keys in the look-up dictionary."
2451,"loss function, in this case, is a sum of gravitational potential energy between each pair of particles and potential energy due to the elasticity of particles that are in contact with each other.",the loss function is used here to calculate the sum of gravitational potential energy between each pair of particles and potential energy due to elasticity between particles in contact.
2452,"but lately, the deep learning revolution have shifted a little bit of focus to the tabular world and as a result, we are seeing new architectures and models which was designed specifically for tabular data modality.","however, the attention of the deep learning revolution has shifted quite a bit recently to the tabular domain, and consequently, we are able to see a whole new architecture and models designed for the tabular data modality."
2453,"there are few alternatives to solve this problem, e.g., descriptive revenue comparison before and after the campaign or experimental hypothesis testing.","a few ways to overcome this issue exist: descriptive revenue comparison before and during an ad campaign, as well as experimental hypothesis testing."
2454,this property of memorylessness is the main characteristic of a markov process.,the main markov process property is this memoryless property.
2455,"when i open my json theme file in notepad++, i see the current settings for my theme:",now i can see the current configuration of my theme file when i open the json theme file with notepad++
2456,"in contrast to matplotlib, seaborn is a high-level interface that would make our life much easier by alleviating the pain and freeing us from writing a lot of boilerplate codes.","rather than a matplotlib for bss, seaborn provides a high-level interface that makes our development much easier by alleviating some of the pain and removing many boilerplate bss."
2457,"personal transportation with cars needs to be reduced and replaced by public transport, cycling, or walking.",the demand for personal transport with a car can be reduced and can be replaced by public transport or bicycling or walking.
2458,"the drive for self-efficiency to produce effective information out of business intelligence tools has risen to need self-service business intelligence, an arsenal of available bi tools that make the company's data readily available to managers and other non-technical personnel.","there has been a need for self-service business intelligence, an arsenal of readily available bi tools to bring the company information readily to managers and other nontechnical personnel to make their own informed decisions to produce effective data from business intelligence tools."
2459,"as we saw the birth year column has year values are impossible or at best unlikely, so it makes sense to restrict our analysis.","as we have already observed, the birth-year column has values that are in fact either infeasible or at least unlikely, so restricting our analysis is reasonable."
2460,the website also offers basic datasets and solutions to some example problems.,the website also contains the basic datasets used and a set of examples solved by the simulations.
2461,now we can call this python file for compilation while also providing the necessary parameters easily from bash.,the compilation is now straightforward in passing over the parsing parameter without any extra bash and calling back the python file.
2462,"as you can see above, this out of the box prophet has made a very basic linear regression as a prediction.","as can be seen, this out-of-box prophet uses a very simple linear regression model to make its prediction."
2463,"but most importantly, you can add colored bars, which represent your feature levels of the given sample.","but most importantly, we can add colored bars that represent the feature degree of each given sample."
2464,"of course, one could represent banking data in a graph database and one could represent social network data in a relational database management system, but whether or not it is wise, efficient, and cost effective to do so requires good judgment about data architecture.","obviously, one can represent bank data in a graph database and one can represent social networks data in a relational database management system, but whether it is wise, efficient, and cost-effective to do so requires good judgment on the data architecture."
2465,missing values in this variable should be expected in our company-employed dataset as they are instead covered by company policy.,our company-employed dataset seems to have missing values for this variable since these values are instead covered by company policies.
2466,"in the same vain you could also drive your car, as many of us do, without the faintest idea of how an engine really works.","similarly, one could drive your vehicle, as many of us do, in a different setting with absolutely no idea how the engine works."
2467,having a mentor or coworker that can provide insight into where you can improve is a valuable way to understand what is going well and what is not.,learning what work is going well and what is not is useful for having mentors or coworkers who can point out where one can improve.
2468,"to keep things simple, we will write a simple method in our quicksample.py file to be called after importing.","to keep things simple, we embed the import method into our quicksample.py file in order to simply call it when it arrives."
2469,"for more understanding, i have also provided exact location of the mumbai airport and naval dockyard.",we also provided exact locations of mumbai airport and naval dockyard to give more understanding.
2470,this blog will speculate on how enterprise knowledge graphs (ekgs) will evolve to contain specialized functions and specialized subgraphs.,we speculate here how enterprise knowledge graphs (ekgs) evolve toward having specialized functions and specialized subgraphs.
2471,"if you have the programming skills, you should feel free to scrape your own data from the internet!","if you are a programmer, you may feel free to read and manipulate your own online data!"
2472,"in a previous article (linked above), i share a few issues that i encountered when deploying my app.",i discuss briefly some issues i encountered while deploying my app in previous articles (links cited above).
2473,"so in some ways, congress, when it really wants to be quick, it can actually be quite quick.",we can therefore conclude that congress can indeed be quite fast if it wants to be.
2474,now that we are on the same page as far as notation.,we now put our notation on the same page.
2475,one reason that you might think that chinese internet companies have a ton of data is because china has more people.,"one possible explanation is that china is more populous than other countries; thus, you might think that chinese internet companies have a lot of data."
2476,we have designed the dataset so there is an interaction between experience and degree and between performance and sales.,we designed the dataset such that we get correlations between the experiences and epsts and between the performance and the purchases.
2477,"sql: in addition to what we have seen up to this point, the order by clause is added at the end to sort the results.","sql: instead of counting the query occurrences up to this point, we add the clause ordering at the end of the query to order the results by clause."
2478,"while different models process this table in different ways, they all share a common input structure.","although these tables are processed by different models in different ways, they share the same input structure."
2479,"once the application went down, team members were no longer able to look at analytic issues in a matter of minutes.","this means that if an application goes down, team members would be unable to check their analytic problems in minutes."
2480,"random events happen in life all the time such as, which of the five people in the drive-thru will have the same order as you do or what are the chances that a store will have your size of the sneaker?","random events happen all the time like, for instance, how likely are five people at the drive-thru to place their clothes in the same order as you do or how likely are shoppers to find their size-appropriate footwear?"
2481,"on the other hand, one should try to structure the project forcing it to grow modularly.","on the other hand, it is reasonable to try to organize the project so that it grows in a modular manner."
2482,xgboost is an ensemble model based on decision tree which uses gradient boosting to reduce errors.,xgboost is an ensemble model based on the decision tree that uses gradient boosting to reduce the error.
2483,"as one can see, the weekly sales data is not automatically larger if the week is a holiday week.",one can observe that the weekly shopper data is not automatically larger because holiday week falls on a Monday.
2484,"in early phases, there is one team or a few tightly collaborating teams that use a single data platform, where the core component is typically a data lake combined with batch processing pipelines, potentially complemented with stream processing capabilities.","early on, there might be a single team or some closely connected teams using a single database platform; the core component is usually a data lake unified with batch pipelines, and perhaps augmented with streaming capabilities."
2485,"by dedicating a column to this topic and casting a greater spotlight onto these stories, we hope to further one of our core beliefs at tds: that data science can provide insight into urgent social, environmental, and political challenges.","we hope to further deepen one of our core beliefs at tds: that data science can help uncover the insight behind pressing social, environmental, and political problems by dedicating a story to these themes and shedding more light on their stories."
2486,"also, the example in the end will ensure a deeper understanding of its usability.","in addition, to make this approach more approachable, we ensure the use of an example at the end."
2487,"unlike other contrastive learning methods, byol achieves state-of-the-art performance without using any negative samples.","in contrast with other contrastive learning methods, byol is able to achieve the state-of-the-art performance without using negative inputs from the testing set."
2488,"as the goal is to demonstrate the various approaches for parameter tuning, i am not doing exploratory data analysis, preprocess, feature engineering, and other works that typically are performed in a machine learning project.","we don't perform exploratory data analysis, preprocessing, feature engineering, and other work that are routinely performed in machine learning projects, as our main objective is to illustrate our different approaches to parameter tuning."
2489,our model also picked up the background color from the monroe diptych.,we also used this monroe diptych for picking the background color of our model.
2490,"sometimes things do get tricky, and stackoverflow might not have all the answers, but remember every struggle and minute spent honing your craft leads to mastery.","each try and each minute spent honing the art leads to mastery, and while stackoverflow may not always have the answer, it may have some lessons."
2491,"error measures, instead, express how much spread out the data points are with respect to the regression fit.","instead, error measures express the degree with respect to the regression fit of the data points."
2492,you can use the submit() function to pass the tasks you want to be executed in parallel.,a query is passed to the submit() function which passes the job which should be executed in parallel.
2493,"(also, note that only looking at the next immediate reward is very similar to a greedy algorithm.",note that the greedy algorithm merely looks at its immediate reward.
2494,these equations are then solved over time to understand the dynamics of the disease.,these equations are then solved in time to understand the evolution of the disease dynamics.
2495,it is a way to provide identities to the services and the cloud resources.,it allows for security protocols to extend identity to the service and the resources of a cloud.
2496,"one important point to note about the new, discounted, state values is the following:",let us note the following important observation regarding the new discounted state values.
2497,pytorch official website: www.pytorch.org,pytorch is now available on the official webpage at: www.pytorch.org.
2498,so the post with the highest score must have been a reply that would have been helpful to others.,"hence, the post with the high score has to be a response that helped at least one other person."
2499,read more herethe kmodes cuts the number of clusters because it is telling us that it can't make sense of the data we are presenting it.,we read more here the kmodes cuts the number of clusters because it tells us that the data we present does not make sense.
2500,this part is to develop a model to predict which individuals will respond to a campaign.,our goal in this section is to develop a model to predict which individuals will react to advertisements.
2501,"here i explain what exactly is this approach, what is the dead end i hit and what are possible continuations of this research program.","here i detail precisely what is the exact problem, what is the dead end i hit, and what are possible avenues for continuations of this exploration procedure."
2502,"typically, multiple questions will be asked about a single scenario, ranging from simple to hard.","typically, one scenario will have multiple queries varying from simple to hard."
2503,note: we can get better performance with the reduce function by passing in operator functions instead of lambda functions as an argument.,"note that by passing the operator instead of the lambda function as the argument, we can gain better performance for the reduce function."
2504,you should treat the colon with equal space on both sides of it (see examples below),consider a colon which is equal to the distance between the two ends (see examples below).
2505,"therefore, by setting cor = true, the data will be centred and scaled before the analysis and we do not need to do explicit feature scaling for our data even if the variables are not measured on a similar scale.","so by setting cor = true, the data is deconvolved and scaled to a pre-assignment level before analysis, and we don't need to do explicit feature scaling for our dataset even when the variables don't scale up equally to similar scales."
2506,"if you like this article, follow me on medium, thank you so much for your support.","i would like to thank ron d thu, my supporter on medium, if you enjoyed this article."
2507,"specifically for arabic, spark nlp offers an arabic lemmatizer, a stop words cleaner and word embeddings.","to further support arabic, spark nlp offers arabic lemmatizer, pause words cleaner and word embeddings."
2508,"however, most charts i see are overworked to look beautiful in the client's eyes.","however, most of the graphs i see are overly processed to look gorgeous from the client s perspective."
2509,"consider that while distance and angle give us a good sense of the likelihood of shot resulting in a goal, we did not take into account where the goalkeeper is positioned, if the shot was taken with a weak foot or strong foot, shot height at point of contact, the game state, home field advantage, if there are many bodies between the goal and the shot, etc.","although the shot probability gives us a sense of distance and angle, we did not account for the position of the goalkeeper, shot height at the contact point, game state, home field advantage, numbers of body positions between a goal and a shot, etc."
2510,focus on courses within your area of expertise or where you are lacking knowledge.,focus on the courses that are within your expertise or for which you lack a sufficient amount of knowledge.
2511,"the code below iterates through the list of messages, calculates their polarity scores, and appends the scores for each sentiment class to separate lists.","the code below iteratively goes through message lists, computes sentiment scores for all of them, and adds scores for each sentiment class into separate lists."
2512,"note that you will get billed for running instances, so make sure you stop them when done.",note that running instances are billed so make sure to terminate when they are done.
2513,"for me, the criterion to select the resources has always been the reliability of the source, that is: who are the authors, how many people recommend the content, how influential is the resource, etc.","i always consider reliability as a ranking criterion for content selection, for instance: who are the authors, how many people recommend the content, how authoritative is the resource."
2514,"there are various other methods available to calculate other metrics, as well as methods to adjust or modify the data, such as by adding or removing points, splitting segments, smoothing values, etc.","other metrics, and also some ways of configuring and modifying the data, such as adding or removing vertices, splitting segments, smoothing values, etc."
2515,significance level represents our tolerance level of an outcome before we decide to reject the null hypothesis.,our significance bound consists of determining the threshold of a response before rejecting the null hypothesis.
2516,"surprisingly, the computing student that i am had never used sql before, so downloading and opening up the file on sqlite was a new experience for me.","it was quite surprising for me to use sqlite in a first-hand setting, which made it new to me to download and open an sqlite file."
2517,katib is so far the only hyperparameter optimization system that comes so naturally to the cloud-native world.,so far katib is the only hyperparameter optimization system that is so natural for a cloud-native system.
2518,next point is to set the learning rate of our model as well as a schedule to adjust it during the training for the sake of the better performance.,"our next goal is to set the learning rate of our model, and schedule an adjustment in training to improve the overall performance."
2519,order by and group by are two more essential methods for sql queries.,two essential approaches in sql querying are sorting by and grouping by.
2520,the idea is to take only the average of each channel for each feature map.,the idea is to only take the average from each channel for each feature map.
2521,"in the user-based approach on the left, alice is considered similar to our target user (in reality, we normally identify a group of similar users), because they both like watermelon and strawberry in their consumption behaviour.",the graphical representation of the user-node interface (to the left) shows that alice is consistent with our target user (actually we identify a subset of similar users) because both of the users are fans of watermelon and strawberry in their consumption behaviours.
2522,"as seen above, the f-strings come in handy when formatting strings.","as can be seen, f-strings have their benefit in string formatting."
2523,they put into comparison the aircraft capacities in order to understand how much retardant or water can be dropped by each type of aircraft.,the amount of retardant or water lost by each type of aircraft is evaluated and the capacity of the aircrafts is compared.
2524,"therefore, i will be using this article to analyze the league season so far of the club i support i.e.","hence, the purpose of this article is to analyze the recent league season for the club i am supporting, which is eb."
2525,"finally, we will evaluate our model in the test sts benchmark dataset.","finally, we evaluate our model on sts benchmark dataset."
2526,"i had heard that integer joins vastly outperform string joins, and i was worried about degrading join performance as our data grew.","i had heard that integer join outperforms string join by a huge margin and i was concerned that as the dataset grows, join performance will become progressively worse."
2527,"for instance, we may want to see both the number of observations in each group in addition to the average charge value.","for example, we might want to see in addition to the average charge value, we want to see the number of observations per cluster at every given time."
2528,"although all three methods give the exact same conclusion when using the same data and the same significance level (otherwise there is a mistake somewhere), i also presented my personal preferences when it comes to choosing one method over the other two.","whereas at this point all three methods could give the exact same results when used with the same data and the same significance level (otherwise there is some error somewhere), here i presented my personal preference for one method over the other two."
2529,google cloud platform (gcp) colab is a customized jupyter notebook image appearing as a cloud service in the gcp framework.,the jupyter notebook image that appears in the cloud as a service in the google cloud platform (gcp) colab has been customized by Google s colab project.
2530,"code is here, an interactive version of this article can be downloaded from here.","we provide the code, the interactive version of this article can be downloaded from here."
2531,"when training a survival model, each row in our training dataset would is a unique loan and the columns are specified as follows:","we have described a set of columns, and we have trained a survival model for this type of instances, where each row of the training dataset is labeled as a unique loan."
2532,the matching criterion is the position in terms of row and column.,the criterion for matching is its position in terms of the row and column.
2533,"however, convolution, pooling, and fully connected layers are the most important ones.","notably, the most relevant ones are convolution, pooling, and fully connected layers."
2534,professor blitzstein uses the spirit embedded in the quote above to teach probability and statistics in harvard and to the wider world.,"blitzstein has become a leading lecturer in probability and statistics at harvard and in the greater world, using the spirit of the quote above."
2535,"from this heat map plot, we can clearly see that though customer a has the highest probability to join the vip club, and customer c has the most potential revenue to bring, we want to reach out to customer b first!","it is easy to see from the heatmap plot that while customer a has the highest probability to join the vip club and customer c has the highest potential earnings to bring in, we would like to first reach out to customer b!"
2536,"in our implementation of a data warehouse, we will be using a local postgres server to store all our data in.",we will use a local instance of postgres to store all of our data in our data warehouse implementation.
2537,"we glean information from one review to the next, each one rendering a more precise representation of the product.","the information is gleaned from one review to the next, each renders a more complete representation of the product."
2538,"when trying to model the outcomes of this likert scale on the independent variables age and gender, it is best to use ordinal regression.",ordinal regression is the best choice when attempting to model the events in this likert scale from variables of independent age and gender.
2539,"yet again the inputid and label arguments are quite straightforward, but we take a third approach to the choices argument here.","again the inputid and label arguments are straightforward, but in this paper we adopt the third approach in the choice argument."
2540,the insertion sort algorithm works similarly to the deck of cards example described above.,the insertion sorting algorithm works very similarly to the deck of cards example above.
2541,hakim ziyech is arguably one of the best creative players in the current chelsea squad and this justifies my earlier point that the best creators will not always have a negative xadiff.,"hakim ziyech is arguably one of the most creative players in current chelsea squad, which justifies my earlier observation that the top-quality players of the league are not always xadiff negative."
2542,everything i could find on the web contained only some of the questions you need to ask.,"however, i only found a few answers to questions that were not answered on any web resource i could find."
2543,nothing wrong with that if you are genuinely creative and good at drawing.,"if you are genuinely creative and a good artist, there is nothing wrong with that."
2544,"furthermore, i began looking at my graduate courses in the context of data science.",i also took a look at the courses i took during my graduate education in the data science setting.
2545,the two key components to creating a markov chain is the transition matrix and the initial state vector.,the transition matrix and the initial state vector are two central components for constructing a markov chain.
2546,"i will utilise the methods of the past to promote the positive, good, and ethical choices of the future.","i used the methods in the past to promote the positive, good and ethical choices of the future."
2547,"unfortunately, our agent in unable to beat rule-based player, even the rule-based player is not using chopsticks at all!","unfortunately, our agent can not beat the rule-based player at all, even when the rule-based player does not use chopsticks at all!"
2548,"in some ways this is a bonus, especially if you are competing against people who have gone to school for data science or a similar field.","this is indeed a bonus in some ways, especially when you are competing with people with data science and similar degrees."
2549,we obtained similar results with bart and causal forest on estimating the treatment effect in terms of rescaled percentage of increase in sales.,we also obtained similar results with bart and causal forest for approximating treatment effect via rescaled percentages of increase in average number of selling sessions.
2550,"after that, we can catch the gradient by put the image on the model and do the backpropagation.","then, we can start backpropagation and place the image in the model to recover the gradient."
2551,here is the final version of the dashboard in my tableau public profile.,here is the final version of my tableau public profile.
2552,the answer is in object-oriented programming which is the foundation of python.,answer set programming is based on the object-oriented programming language that is the basis of python.
2553,"it contains information about the number of passengers, trip fare, tip amount and the start datetime of the trip.","this dataset includes information like the passengers number, the trip fare, tip amount, and the start datetime of the trip."
2554,an unexpected change that performs highly divergent attitudes from other observations in a time period can be represented as abnormal behavior.,abnormal behavior can be defined as a sudden change that significantly varies the attitudes of another observers in a time frame.
2555,one way to solve this problem is to oversample the examples in the minority class.,one way to overcome this problem is by oversampling examples from the minority class.
2556,the models will be loaded using the hugging face library and are fine-tuned using pytorch.,our models are loaded using the hugging faces library and refined using pytorch.
2557,"for groups with strict service level agreements (slas) around inference time, grpc can be a life saver.",grpc can be a lifesaver when the scheduler has strict service level agreements (slas) around the inference time.
2558,"then expand the sites the root set links to, which is the base set.","next we expand the sets the root sets link to, which are the root sets."
2559,"however, typically we will have complex problems requiring billions of neurons.","however, we usually face complex problems that require billions of neurons."
2560,click the heroku postgres link and navigate to the settings tab.,"in order to start the process, you need to click on the heroku postgres link and navigate to the configuration tab."
2561,once the machine code is generated it can be cached and also executed.,"once the machine code has been generated, it can also be compiled and executed."
2562,"whatever the possible transformations or corresponding distance functions and maximum distance, we always reason about some neighborhood around the original input.",we always reason about some neighborhood around an original input despite the possible transformations or corresponding distance functions and maximum distance.
2563,"similar to elmo, bert processes sequences bidirectionally, which enables the model to capture context from left to right, and then again from right to left.","similarly to elmo, bert processes sequences bidirectionally in a way that allows the model to capture context from left to right and then back to left."
2564,you can learn further about it on the official fastapi website.,further details can be found on the fastapi official website.
2565,in a nutshell: talk about other aspects close to the model that could be necessary for a complete solution.,short version: discuss other aspects that are close to our model and that are likely to be required in order to produce a complete solution.
2566,in this post we will be coding the entire linear regression algorithm from absolute scratch using python so we will really be getting our hands dirty today!,"so we are really going to get our hands dirty today in the following post, where we train a complete linear regression algorithm from absolute zero using python."
2567,"after we understand the signal sampling frequency, some time entries may be missing.",we will notice that some time entries may have been missing after we have grasped the structure of the sampling frequency of the signal.
2568,it will take you to a form where a couple of questions will be asked about your organization and the project you are planning to implement.,the connection will lead to a form which asks a series of questions concerning your company and the project you plan to pursue.
2569,seeing how the team relied on such an application drove home the point that an application must have a reliable and stable codebase.,seeing how the team relied on this application drove home the important point that an application needs to have a reliable and robust codebase.
2570,"the separation of compute and storage conveys several operational, technical, and financial benefits.","separation of computation and storage carries several operational, technical and financial benefits."
2571,"the best formula to calculate movie rating is provided by imdb, which is articulated clearly here.","imdb provides a very good formula for movie rating computation, which we present in a clear form."
2572,the eval function allows for manipulating or modifying a dataframe by passing an operation as a string.,the input of an eval function allows manipulating and editing dataframes by passing an operation as a string.
2573,"even with some margin for error, the numbers aligned with the low-cost expectation everyone had on serverless.","these numbers coincide with the low-cost expectations everyone had when they tried serverless, even with some error margins."
2574,most of the methods are apart of the class cytonboard in the openbcistream.py and many of the methods have been simplified for your use (including a socket handler in case the application wants to broadcast the data via the internet to other application).,"for the most part, these methods are included in cytonboard class within openbcistream.py and most of the methods are simplified to be included in the stream."
2575,"and yes, the following lines are what you need to train this new model starting by training just the decoder and then unfreezing all layers and training for another cycle with a lower learning rate.","indeed, this means that one should train this new model by training just the decoder, unfreezing all layers and then training the second cycle using a lower learning rate."
2576,"if you put these scripts together with the html template above, you will have a working web page.","if these scripts are put together with the html template provided above, you have a working web page."
2577,"for that purpose, the average value within the selected areas and non-selected areas, as well as the ratio of those average values are utilized as features.",these feature vectors consist of the average value of the selected regions and those of the non-selected regions and the ratio of the two.
2578,"the map uses data from this crowd-sourced spreadsheet of black-owned stores, restaurants and services in the boston area.","we apply these guidelines to the map by drawing the dataset from this crowdsourced spreadsheet of black-owned stores, restaurants, and services in the boston area."
2579,"it is like testing the water by gradually evaluating public reactions and pandemic situations, which reduces the risks, allows for adjustments, and helps the population with a smooth transition.","the methods are similar to a testbed: firstly, the public will have to wait, in a predictable fashion, until a steady state emerges to evaluate the public reaction and a pandemic scenario."
2580,"long before the war, polish mathematicians had solved the enigma using mathematical approach when britishers were still trying to solve it linguistically.","rather than a mathematical approach, polish mathematicians solved the enigma long before the war, even when britishers were still trying to do so linguistically."
2581,"markov chain models the future state (in case of text generation, the next word) solely based on the previous state (previous word or sequence).","markov chains model future states (for instance in text generation, new words) solely on the basis of previous states (in either the previous word or the past sequence)."
2582,"overall, this seems a promising strategy to debug, harden, and generally improve models.","overall, debugging, hardening, and generally improving models seems to be a promising strategy."
2583,see the below code snippet defining the randomforestmodel class and revel in its simplicity.,"let us observe the code snippet characterizing the class of randomforestmodel, and revel in its simplicity."
2584,we need to subset df to filter out records with invalid data.,"to filter records with invalid output, we must subset df."
2585,"the question was, how the neurons decode this information and is this reflected in the parameters of the neural network.",the questions were whether such information could be decoded by the neurons and is that reflected in the parameters of the neural network.
2586,"if you want to understand more about how sayn works, go through our tutorials which are good starting points.","to learn more about the operation of sayn, visit our tutorials which are good starting points."
2587,"he wanted to know if i was interested in staying an individual contributor, leading a team, progressing into a management position, or becoming a technical fellow.","we asked the reader whether i was interested in being a recurring contributor, team leader, progressing in a managerial role, or becoming a technical senior."
2588,"the highest and smallest quantity of the substance to analyze that can be measured with a defined accuracy (trueness + precision), respectively.",the maximum and minimum values of an underlying substance that are measured with a defined accuracy (truth + precision) are the same as those computed with accuracy.
2589,"and it is very tempting to conclude that the more variables you control for, the better.","it would be tempting to conclude that the bigger the number of variables we control for, the better."
2590,"the financial impact to an organization can be measured in lost energy production due to chronic underperformance, lack of visibility into availability losses and finally the complete lack of awareness of asset health and maintenance needs.","this can be measured in lost energy production due to chronic underutility, visibility to outage costs, and finally the complete lack of awareness of asset health and maintenance requirements."
2591,one of the easiest elements to segment for this type of approach are grayscale images.,grayscale images are one of the easiest components to segment in this class of approaches.
2592,"the data in this blog comes form the mach-iv questionnaire by christie and geis, which provides a measure of machiavellianism.","this blog post reveals data from the mach-iv questionnaire developed by christie and geis, providing a measure of machinimism."
2593,wind power is generated by using large turbines to harness the kinetic energy of wind.,wind energy is generated by using large turbines to harvest energy from the wind.
2594,your interviewer may ask you to use other methods than control flow.,"any other method besides control flow might be used, as questioned by an interviewer."
2595,"reading is the first step when it comes to learning (in this case, also listening to the courses).","reading is the first step in the learning (in the case of courses, also listening) process."
2596,definitely not bad for a non-parameterized model and very close to our desired prediction accuracy.,"indeed, our nonparametric model is very close to our desired prediction accuracy and clearly not too bad."
2597,when generating this mapping function the model will use a set of assumptions to better approximate the target.,the model is expected to use a set of assumptions on this mapping function to better approximate the objective.
2598,"we have seen some countries that imposed compulsory testing on international arrivals have either nearly crashed their health-care system, like germany, or had explosive community spread, such as iceland.","it is interesting to note that some countries have imposed compulsory testing for international arrivals and they both have either crashed their health care system, as in germany, or their communities were explosively propagated as in iceland."
2599,fast.ai coded a complete set of jupyter notebook tools.,fast.ai is a completely integrated version of jupyter notebook tools.
2600,most of the previously mentioned pandas tutorials already show a couple ofmethods to analyze your data and answer various questions.,many of the previously mentioned pandas tutorials already demonstrate at least a few methods for doing analysis and answering various questions.
2601,"then, we say that y is a random variable that follows a binomial distribution.",we then present a general formulation of y such that y is a random variable whose distribution is binomial.
2602,datatypes for that constructor are then placed below it with returns being the syntax for separation between these parameters.,"is next placed below the constructor, with returns being the syntax for separation between these parameters."
2603,it can either be run in standalone mode in a python environment or run as part of the jupyter notebook to generate the user-configurable widgets.,the generator can be either run as a standalone command in a python environment or run as a plugin within a jupyter notebook for generating user-defined widgets.
2604,demosaicing algorithm is then used to obtain a full-color image where the surrounding pixels are used to estimate the values for a particular pixel.,"the demosaicing algorithm generates the fully-colored image, with the surrounding pixels used as estimating the values for each particular pixel."
2605,these types of decisions are categorized as optimization problems in which the goal is acquiring the best solution; might be the minimum or the maximum and the optimization process is the art of finding the best answer to existing situations.,"the type of decisions can be classified into optimization problems where the objective is to obtain the best solution, which may be minimal or maximal."
2606,these fake samples are fed into the discriminator (without the real samples this time).,these faked samples are fed back into the discriminator (against the actual ones).
2607,"this free class includes resources like lecture videos, written material, and loads of practice exercises.","the class contains resources like lecture videos, annotated training materials, and loads of practice tasks."
2608,visit your serveless function by clicking the visit button.,the serveless function can be visited by clicking on the visit button.
2609,"stewardship of data means acting in accordance with a set of rules, which maintain the benefits of all parties with access to the data.",data stewardship is one act that follows a set of rules ensuring that all parties involved in the data access are benefited.
2610,"this article will discuss these recent advances, using as an example the development of a distributed generative adversarial network (gan).",we will discuss these recent advances using as an example the emergence of distributed generative adversary network (gan).
2611,"i fit the model on gaussian naive bayes and plotted the contour, i got a clear non-linear decision boundary.","i fitted the model on gaussian naive bayes and plotted the edges, and i received a solid non-linear decision boundary."
2612,"furthermore, you might get the opportunity to create meaningful solutions that will positively impact many individuals and communities along the way.","in addition, the potential can be leveraged in order to construct meaningful solutions that will positively influence many individuals and communities along the way."
2613,"currently, it is the principal document database and the leading nosql database.",is currently the leading document database and the leading nosql database.
2614,"however, owing to a variety of technical and system issues, the location data that is finally returned to it may have a lower precision than requested due to the gps not being available (indoors), battery conservation, etc.","unfortunately, the location data finally returned to a gps may have lower precision than requested due to gps not being available (outdoors), batteries not being conserved, etc."
2615,"these usually work on concepts such as natural language processing, machine learning, and deep learning.","typically, these are related to concepts such as natural language processing, machine learning, or deep learning."
2616,the parameters of pandas functions are highly important as they make the functions more powerful and versatile.,this parameterization of the pandas functions is vital since it makes the functions richer and more versatile.
2617,"to get a language prediction for the input text, we simply perform a forward pass through the network.",we then simply perform a forward pass over the network to derive a language prediction for the input text.
2618,so i get that these could be seen as roadblocks to greater data democracy.,so i see that these could be seen as roadblocks towards more data-driven democracy.
2619,"however, it's always great to see innovation and new ideas.","nevertheless, innovation and new ideas are always a welcome sight."
2620,"the above picture shows the docker file for our titanic use casein the docker file, i have installed the libraries such as tensorflow, scikit-learn, keras, etc.","the docker image shows the docker files for our titanic use casei have installed various libraries such as tensorflow, scikit-learn, keras and others in the docker file."
2621,"so, it is helpful to have a cheat sheet or guide in hand.","hence, having a cheat sheet or instruction at hand is handy."
2622,the goal of this very first step is to offer to the end-users of our recommender system a catalog of popular movies from which they can choose their favorites.,our first objective is to provide an unsupervised movie catalogue that we recommend as user inputs to the recommender system that she finds to be her favorite.
2623,"we now see that the two series are more comparable visually (as well as statistically), and is one of the reasons why time series across countries are often log-transformed.","we see now that graphs appear to be visually more comparable (both statistically and asthetically), one of the reasons that time series across countries tend to be log-transformed."
2624,"however, this is no problem since we can just take these unnormalized probabilities and divide them by their sum, then they will add up to one.","however, this does not matter as we can just take these unnormalized probability distributions, divide by their sum and then add them up to one."
2625,"as data scientists, the impulse is to show the raw model results but often we need to transform the output into a form stakeholders can understand.","while the impulse as a data scientist is to present the raw model results in their original form, often we need to transform them into a form which stakeholders can understand."
2626,you need to understand what is happening to take the best solution.,"to identify the best solution, we need to understand what is happening."
2627,"there are situations that midway into a project a mistake is discovered, forcing us to start (almost) over again.","there are situations in which a fault is discovered midway through the execution, forcing us to re-start (almost) the task."
2628,"this time, we will not extract artist objects from the line plot we just drew.",he is not going to extract artifacts from the line graph we just drawn.
2629,"as a result, although a standard pandas pickled dataframe may work in testing on your local machine, deployment to a server is another story.","while working on a local machine is an interesting way to test a standard pandas pickled dataframe, it is a different story when deployed to a server."
2630,what i want to see is what percentage of the time it accurately predicts the right dataset.,we want to see how well these rules predict a good dataset within a certain amount of time.
2631,"with respect to data science, coding is simply a tool to help you convey and apply your domain-knowledge to a specific problem.","for data science, coding simply entails using the tools that make it easier to convey and apply domain knowledge to a particular problem."
2632,"by copying your requirements in isolation, docker will instead only reinstall dependencies in this file (or files) when you update the files themselves.","rather than recompiling requirements in isolation, docker only recompiles dependencies within a given file (or set of files) when updates itself."
2633,"in its turn, he subdivided the principles into axioms and postulates.",each of these then subdivides the principles into axioms and postulates.
2634,each one will be covered in greater detail using the example dataset below.,below we illustrate each one in more details using the example dataset.
2635,"of course, there is more to it than that, but that is the gist and this the kind of data scientist that i will have in mind for the rest of this post.","there may be more to it than that, of course, but this is the gist and this is the kind of data scientist i will use for the rest of this paper."
2636,the variability in statistics is used to measure the extent to which the data has been spread out.,we use the data variability measure to measure the unevenness of the statistics.
2637,before starting i highly recommend first have a look at vision transformers,it is strongly recommended to first consider vision transformers before starting on this problem.
2638,"by gareth james, daniela witten, trevor hastie, robert tibshirani","gareth james, daniela witten, trevor hastie and robert tibshirani."
2639,"your api implements required functionality), while the latter is used to test non-functional properties of your api (e.g.","the former is used to implement the required functionality of a user interface), while the latter is used to test nonfunctionality of the api (e."
2640,the fact that the models could learn patterns in the training set that would be useful to predict relatively different patterns in the test test is incredible!,it is quite remarkable that these models are able to learn patterns from the training set such that they may be useful for predicting fairly different patterns in the test set.
2641,going beyond what type of movies we want to see to what type of world we want to live in.,we are taking a step beyond what kind of movie we want to watch and how much of the world we want to live in.
2642,policy-based: learn directly the stochastic policy function that maps state to action.,policy-based: learn the stochastic policy function that maps the state to the actions directly.
2643,the majority of the information covered in this post is very well explained in the blog of yfinance.,"most of the information in this blog post can be easily understood by reading about yfinance, their blog."
2644,"simply read the data you want to update into a dataframe and, manipulate this dataframe with your updates.",we simply read the data you want to update into the dataframe and then manipulate the dataframe by applying changes of your own.
2645,"if not, you can check out one of the myriad tutorials, like the illustrated transformer.","if not, one can try out some of the myriad tutorials like the one shown with the circle transformer."
2646,glob (short for global) is used to return all file paths that match a specific pattern.,glob (short for global) returns all paths in a file that satisfy a given pattern.
2647,i had no idea what sieve of eratosthenes is and find this website quite useful (link).,"i did not know what sieves eratosthenes are, and found this website quite informative (click)."
2648,"with all the datafication, classification, and clustering that netflix had done on its customers, the show was recommended to the right cluster of customers.","we can see that, having trained netflix on all the datafication, classification, and clustering we did in a given time slot, the show suggests the right cluster of accounts to start a new one."
2649,the geometric mean or known as g-mean is the geometric mean of sensitivity (known as recall) and specificity.,"sensitivity (or recall) and specificity are also measured by geometric means, or g-means."
2650,"a number of states have now opened mass vaccination sites in an effort to get more people inoculated, cbs news reports .","several states have now opened mass vaccination sites in an effort to get more people immunized, as reported in cbs news reports."
2651,"in this section, we will add a regression line and confidence band.",we will add the regression lines and confidence bands in this section.
2652,reviews and the number of helpful votes it got) and the target feature is the number of stars attributed.,"the target features are reviews and the helpful votes they received), and the objective feature is the number of stars that it was assigned."
2653,"none of the time, effort and budget invested in building a cloud data lake will yield any returns if the data stored in the data lake is not made immediately available to analysts.","if the data stored on the data lake is not immediately available to analysts, then none of the time, effort, and budget spent in developing a cloud data lake can be beneficial."
2654,"i used a make shift transparent portafilter (aka kompresso), and i put some coffee in it.",i used the shift transparent container filter (also referred to as kompressor) and put some coffee in it.
2655,i really enjoyed myself learning while summarizing above resources into a reading list.,my experience of aggregating above resourses into a reading citation list was extremely enjoyable.
2656,you might need to use the rotate button next to the hierarchical relationship button to get the root of your tree to appear at the top.,"so for the tree root to appear at the top, it may take a rotation by pushing the rotate button adjacent to the hierarchical relation button."
2657,"but at its core, moving window analysis can be summed up as simply as the mean of neighbor elements.","nevertheless, the moving-window analysis can fundamentally be summarized as the mean over neighboring tiles."
2658,"like many psychology students, i learned how to collect, analyze, and interpret data.","i learned how to collect, analyze, and interpret data as a psychology student."
2659,the sad truth: numbers alone are not sexy to the average person.,the sad reality: numbers alone are not interesting for a common person.
2660,"this is a problem for sentiment analysis with simply joined lexicons: messes of high value words can produce a very normal sum or mean sentiment score, which is only revealed by the deviation.","this approach elucidates the problem of sentiment analysis with the simple joined lexicon: odd words from very rich texts can produce a very normal sum or mean sentiment score, which can only be seen through its deviations."
2661,i would suggest trying both approaches when building your model and selecting the one that works best for your data.,"i would suggest that, when building your model, try both approaches, and select one that works best with the data."
2662,"however there was no unique movie identifier across the two sources and as such the only option was to merge the dataframes using the movie name, i.e.","however, no unique movie identifier was provided across these two sources, so our only approach was to merge the movie dataframes using a movie identifier."
2663,"if you like my work, feel free to browse my other articles :)","if you find my work interesting, feel free to browse my other articles:) : )"
2664,"furthermore, these massive neural networks are often used to model phenomena a lot more complex than birds in a zoo, like the behavior patterns of millions of users or the distinguishing features of thousands of faces.","in addition, large-scale neural networks have also been used to model more complex phenomena than the birds of prey in a zoo, such as the behaviors of a million users or the distinguishing features of a thousand faces."
2665,"third, and finally, we dived deep into the mathematics of the problem and derived an exact and general solution for the probability distributions.","third, finally, we descended deep into the math to prove approximate exact generalized solution to the probability distributions."
2666,"if you have to apply to hundreds of jobs to only get a few interviews, you will quickly run out of jobs to apply for or the energy to keep applying.","we are concerned that if the worker attempts to apply to hundreds of positions and only receives a few interviews, then there will be very little left for ml to apply for and little energy to apply."
2667,"now, we train use a model that predicts whether two images are of the same breed.",we train the model to predict whether two images of the same class are of the same type.
2668,within your python application to make it more robust and leverage the rich functionalities of the sdks.,the architecture is one of development code which integrates within python applications making them more robust and leveraging the rich set of features available within sdks.
2669,"as a refresher, it is a fantastic non-linear model for predicting continuous features that is very commonly used.",we recall that they are one of the most widely used nonlinear modeling methods for continuous feature prediction.
2670,i began my journey with a learning track on edx taught by microsoft.,i started my career with the edx learning path taught by microsoft.
2671,"the default reclaim policy is inherited from the type of persistent volume, so it is good practice to always specify it in the yml file.","the default trash-recovery policy inherits from the persistence volume type, and so it is a good practice to always explicitly specify it in the yml file."
2672,"if you look at the rankers on jina hub, the levenshtein ranker uses the levenshtein distance to recompute the match scores.","for example, a levenshtein ranker exploits the levenshtein distance to derive match scores for data points on the jina hub."
2673,"the curse of dimensionality refers to certain behaviours or effects that appear when analysing or playing with data in high dimensions (with many features), which do not appear when the number of dimensions is low.","curse of dimensionality refers to certain behaviors and effects that occur when dealing with high-dimensional (many-feature) data, but don't occur when the number of dimension is very low."
2674,"this function will take two arguments, our json and the iterator value that will serve as our index number for our json array.",the main key elements of this function are the json object and the iterator value to which we give index numbering for the json array.
2675,we got the mae and rmse values shown in the table below for the test data.,we calculated the mae and rmse values on the test data of fig.
2676,"after choosing the learning algorithm and model architecture, a second step is the hyperparameter optimization.",the second step is the hyperparameter optimization after choosing the learning algorithm and model architecture.
2677,"in that case, probably transitioning into an analytics translator is the best for you.",this suggests that transitioning to an analytics translator is probably the best decision.
2678,"that being said, the actions you could potentially can take knowing that the parameters values are limited and very complicated.","being aware of the limited and extreme flexibility of the parameter values, one may wonder what actions should be taken."
2679,"it is supported for a wide range of programming languages and runs remarkably on most platforms such as windows, linux, and macos.","it is supported by a large variety of programming languages and runs strongly on most platforms such as windows, linux, and macs."
2680,this pie chart of the customer attrition indicator represents the portion of the data set associated with attrited customer vs.,this pie chart of customer attrition measures the fraction of the data set to be the result of attrition of customers relative to the sim.
2681,data set used: for this work we have used triplet data to train and validate.,"dataset used: we have used, for this work, a triplet dataset for training and validation."
2682,country conversion is done using the coco converter library and a demonym csv file available on github.,the conversion is carried out using coco converter library and demonym csv format available through github.
2683,"(okay, tko was a jt song, my bad.)","it was tko, i know, it was a jt song, but my bad."
2684,this is incredibly promising and will likely benefit the fields of data science and machine learning greatly.,this is a remarkably promising approach that will certainly have major benefit for the data science and machine learning communities.
2685,specifics of each role are beyond the scope of this guide but this blog post summarized it nicely.,"the full specifics of each role go beyond the scope of this guide, but we found this blog post a nice summary."
2686,our model outputs a dictionary that contains output values for content and style information:,we produce a lexicon that contains output values for the content and style information of our model: of.
2687,we can see that there are a lot of steps to ensure our measure of psychological traits has degrees of validity.,we can see there are several steps in ensuring that our measure of psychometric traits has degree-validity results.
2688,"a mathematical method conceived in the aftermath of wwii as a means to automate planning procedures at the us army air forces, linear programming has since evolved into a mature field with widespread applications in transportation, manufacturing, finance, health care and many other domains.","linear programming is a mathematical technique that was originally developed in the wake of the wwii years to automate planning processes within the us army air force, with vast applications in transportation, manufacturing, finance, health, and many other domains."
2689,"if i worked at kaggle, i would be keen to see this kind of comparison.","if i had a job at kaggle, i would like to see such comparisons."
2690,"there are significantly fewer results showing how to apply shading to well log plots, which generally have their longest axis along the y dimension, or to the y-axis in general.","the results are largely lacking as they show how to apply shading to well log plots, which are typically segmented along the y-axis, or on the y-axis in general."
2691,"you can try out my wine recommender by downloading the whole zip file and running filters.py, where i took these boiled down lists and compared them against dictionaries for common descriptors of sweet, savory, earthy, fruity, floral, and bitter wines.","download the full zip file and run filters.py which took these boiled down lists, together with their descriptors for sweet, salty, earthy, fruity, floral and bitter wine, as well as the descriptions of typical wine lexicons."
2692,"the idea here is to avoid the convertion of each row data in to pandas.series, whose the time foot print can be seen above, e.g.","a key idea behind this paper is to avoid configuring each row data into a pandas.series, whose footprint can be seen above as the frame in which it occurs."
2693,the best way to gain experience is to do projects or join competitions.,doing projects or participating in a contest is a very good way to learn.
2694,determine whether a cat or a dog appears in an image?,how do we detect whether a cat or a dog appears in an image?
2695,this article is a simple example of how to apply the linear optimization technique to cricket to pick the best players.,the following proposition is a simple example of how the linear optimization technique can be applied to cricket s rank selection problems.
2696,"here in this article, i am going to show you how this amazing api can be used to solve different nlp based ai use-cases.",in this article we show how the ai can be used to solve various nlp-based use-cases.
2697,and on the basis of this additional information you have refined not really your underlying preferences but their expression.,"also, through this extra information, you refined not really the expression of the preferences but rather the expressions of the preferences."
2698,"if you want to support this: like, comment, or reach out!","you may like, comment or reach out to others who are interested in supporting us!"
2699,after importing the required library you created an app instance and created your first route with a decorator.,"after importing the required libraries, we created an app instance and created our first route using a decorator."
2700,"my aim was to be consistent for each metric, but some times the granularity was difficult and affected the final score.","we tried to keep the data consistent across metrics, but some times the granularity has made the calculation difficult, affecting the final scores."
2701,this is of course a very valid question but not very easy to answer as it depends on where you are now.,"this obviously remains a valid question but it is hard to answer because it depends on where you are in the time, and therefore not very easy to do."
2702,one possible application of detecting logical fallacies is to use it as a filter for discerning fake news.,implementing it in our framework for detecting logic-warranting fallacies might lend itself well as a filter to identify fake news.
2703,the number of parameters involved with each layer and the dimension of the layer outputs can be viewed with the summary() method.,"then, one can view the summary() method by knowing the number of parameters involved in each layer as well as the dimensionality of the layer outputs."
2704,work complexity is all about determining whether or not an activity has clearly defined rules and routines.,"work complexity is simply about deciding whether an activity is well-defined, with well-defined rules and routines."
2705,the pytorch operator is the implementation of pytorchjob custom resource definition.,this pytorch operator is used to perform custom resource definitions for pytorchjob.
2706,"after grouping the data, use the graph objects library and a second add trace with a for-loop.","if the data has already been grouped, the first option is to use the graph object library and to add the trace to the for loop in the terminal."
2707,"in other words, your whole app can now make use of this blueprint to catch and handle otherwise uncaught errors wherever they may crop up.","more precisely, using this model means that your entire app can now focus on catching and handling otherwise uncaught errors where they may arise."
2708,"instead of barrels of thick crude oil, we have folders of blurry images to refine.",we shall be given folders of blurry image files to refine instead of barrels of thick crude oil.
2709,"a function is a block of code that takes zero or more inputs, performs some operations, and returns a value.","a function is a chunk of code which receives zero or more inputs, performs some operations, and returns a value."
2710,"tmp is easy, np.percentile() function do all the stuff for us, we just use a list comprehension to iteratively get the final tmp array.",it is straightforward to use tmp since the np.percentile() functions do all the heavy lifting for us; we just use list comprehension to iteratively obtain the final tmp array.
2711,the image below shows the need of converting the geographic coordinates to image coordinates:,a simple example illustrates the need to convert location coordinates into image coordinates: the following map demonstrates this.
2712,recall from above that panel data is often synonymous with longitudinal data.,notice that we used the reference number above to emphasize that panel data are often synonymous with longitudinal data.
2713,the best part about these podcasts is that you can listen to them any time and anywhere.,the best part about podcasts is that they can be listened to anytime and anyplace.
2714,"again, we have to initialise an empty dictionary at the beginning.","again, we start with an empty dictionary."
2715,the bottom-right graphs show comparisons between the groups a and b.,the bottom right figures show comparisons between groups a and b.
2716,"the assumptions are as follows: often, many organizations will have a graph in their database which is either a sample of a much larger graph or is representative of such a larger graph.",the assumptions are as follows: often organizations have a sampled graph in their databases that either is a subgraph of a much larger graph or a representative of that of a larger graph.
2717,"the fact that both of these models are non linear means that we add another element of adaptability to our model, because it can now predict classes that do not have linear decision boundaries or approximate non linear functions.","for both models to be non-linear implies to incorporate an adaptive feature, as our model can now predict classes whose decision boundary is linear or approximated by non-linear functions."
2718,notice how it printed the keys of the dictionary and not the values?,notice that this application prints the keys of the dictionary but not its values.
2719,following are a few resources that you can use for your preparation.,the following few links provide useful preparation materials.
2720,a model that can handle all of these requests is a more valuable model than one that can only guess a singular time frame,a model that can handle all these queries is more valuable than one which can only guess a single time bound.
2721,"i use tidymodels for the demonstration, including rsample for splitting data, parsnip for modelling, workflow for bundling the process, tune for tuning, and dials for parameter management.","our experiment includes the following parts of tidymodels: rsample for data splitting, parsnip for modelling, workflow for bundling, tune for fine-grainedness, and dial for parameter management."
2722,both of them have phd in applied mathematics with a statistics background and machine learning algorithm knowledge.,they have a joint phd degree in applied mathematics with a background in statistics and machine learning algorithms.
2723,any file in json format can be stored in mongodb as bson.,mongodb can store any json file in a bson format.
2724,"i listed three values each for mtry and trees, generating nine combinations (three times three).","for mtry and trees i put in the same three values, and generated nine arrays of three values each (for mtry and trees, respectively)."
2725,"by taking the online course, you can find out what data scientists are doing.",the online training course gives an insight on the job of data scientists.
2726,naive bayes model is easy to build and is particularly useful for dealing with smaller data sets.,the naive bayes model is easy to build and particularly well suited for dealing with small data sets.
2727,"if that is the case, it is time to refactor your code.","if this is the case, it is time to rewrite the code."
2728,"you are an agent of the men in black (mib), a secret agency responsible for protecting human beings from aliens that are disguised as humans.","we imagine that you are a member of the men in black (mib), a secret spies organisation that protects human beings from assassinated spies."
2729,"(you can try to explore other network visualization tools such as gephi , pyvis or graphchi).","other network visualization tools like gephi, pyvis and graphchi may also be explored."
2730,"i played around with various ways of visualizing this data, and i came up with the following method:","i experimented with a few visualization methods for this data, and developed the following method."
2731,for some games frodo learns to provide target returns close to v-trace (e.g.,frodo learns the target returns close to those of v-tilings for some games (eg.
2732,"by setting the width and height parameter in columns, we have complete control over how we want to organize our elements on the page.","when setting the width and height parameters in columns, we have full control over how we want to arrange the components on the page."
2733,the above image shows the rgb composite image of sundarbans data before and after stretch applied.,the image depicts the blended image in rgb of the sundarbans data before and after stretch over.
2734,your goal is to start to understand what the core skills are for your dream role.,a goal is to begin to understand what the key skills are that your dream job requires.
2735,so the typical use case is that you want to add a new column that is derived from other columns using some transformations.,a typical usage case is therefore when we need to add a new column to an existing column by means of some transformation.
2736,the main reason for choosing tensorflow over other deep learning frameworks is its popularity.,popularity of tensorflow is one of the main reason why people prefer it over other deep learning frameworks.
2737,you can also schedule scraping times to keep your data up to date.,lon can schedule the times of scraping so that the data are kept up to date.
2738,then i used beautiful soup to do web scraping and get reviews for each restaurant.,"then, i used beautiful soup to do web scraping and gather reviews for all restaurants."
2739,"i have said before that i think understanding clean data, how statistics work, and how to manipulate your data is going to be the most valuable asset as a data scientist.","we have said before that understanding clean data, how statistics work, and how to manipulate data are going to be the most valuable assets for a data scientist."
2740,"although we might not be directly involved in this particular scenario, we as ml practitioners need to consider the bigger picture and ponder how the tools we develop can be used for harm.","although we may not directly deal with this particular setting, as ml practitioners we should consider the grand scheme of things and wonder if the tools we develop can help to prevent harm."
2741,notice that both experience and sales have a positive relationship with bonus.,note that the bonus appears to have a positive relationship with both experience and sales.
2742,the main bit to focus on is the model block which is where we define the priors and likelihood.,the main bit that must be made clear is in the model block which defines the priors and probabilities.
2743,i think the way to think about why is ida aligned is a sort of mathematical in-depth style argument.,a kind of mathematical in-depth style argument about why the points are ida aligned seems a helpful way to think about this question.
2744,using techniques like principal component analysis (pca) you can reduce your original input features to just those actually helping in getting to the desired answer.,"we can reduce the original input feature sets to simply those which are actually helping in obtaining the desired answer, by employing techniques like principal component analysis (pca)."
2745,"in theory, many physical clothing retailers act as a rotating store by shifting their displayed inventory to match the seasons.","theoretically, physical clothing stores act as a revolving display, changing their presented items as the seasons change."
2746,"in real life, this is when you tie back your data science problem to the real underlying business problem.",this is where the data science problem becomes closely related to the real world problem.
2747,this statistical methodology builds up the essentials of multivariate data analysis that uses an orthogonal transformation to apply a set of observations of probably correlated variables into a set of values of uncorrelated variables in a linear way.,the fundamentals of multivariate data analysis consist in using an orthogonal transformation to regress a set of observations of probably correlated variables as a linearly arranged set of values of uncorrelated variables.
2748,this article will look at information theory with the goal of developing useful intuition for some concepts and their applications.,"we will discuss some details of information theory, with the goal of developing a useful intuition for some concepts and their applications."
2749,here is a diagram of what the end to end project ultimately looks like and what you should expect to achieve after following this article.,the following is a sketch of what is ultimately expected from the project and what is achievable after reading the article.
2750,"while it is possible to evaluate it using a simple statistic, the challenging part is to confirm whether the event actually affects the result.","although the difficulty lies in confirming whether an event directly affects the result, one can evaluate this using simple statistic."
2751,the first component has the maximum variance and the last component has the least.,the upper case of each component has the maximum variance and the lower case has the lowest.
2752,"after several years of using conda, here are a few of my observations on conda as a package and dependency management:",here are some of my observations on conda as a package and as a dependency management system after a period of several years of using conda.
2753,a hypernym is a higher level category for a given word.,hypernym is a more general category than hyper-nym is a term.
2754,take some time to look at the numbers and to make sure you understand how the calculations work to get the final output with the same image size as the input.,it may help to take some time to look at the figures and to understand the calculations that are performed to obtain the final result with the same size as the input images.
2755,"and while it may be easy to spot the issue here, in contexts like scientific research it can be much harder to identify that this may be happening in your experiment.","while this may be easy to spot in this context, it may be more difficult to recognize that this may be occurring in a context like scientific research."
2756,"unfortunately, compute costs tend to be highly variable, which makes forecasting budgets challenging.","unfortunately, compute costs tend to be highly heterogeneous, making forecasting budgets challenging."
2757,"this step takes time, patience, dedication, commitment, perseverance and motivation.","this process takes time, perseverance, commitment, persistence, motivation and effort."
2758,"firstly, in case you are not familiar with linear algebra, there are a few ways to multiply two arrays.","first, there are a few ways of multiplying two arrays in linear algebra, in case you are unfamiliar with linear algebra."
2759,the best platform for data scientist to showcase and exhibit their skills with their unique problem solving ability and innovative thinking is kaggle.,kaggle is a great platform for data scientists to showcase and exhibit their unique problem solving abilities and innovative thinking.
2760,"so i took this class with tenenbaum and i found this combination, like human cognition on the one hand and ai on the other to be really captivating.",i took this class alongside tenenbaum and found it really captivating as it makes connections between human cognition and ai.
2761,"for example, it can integrate with google-developed kubernetes and other apache products such as hadoop, cassandra, mesos and hbase.","the new development allows to integrate google kubernetes along with other apache products like hadoop, cassandra, mesos, and hbase."
2762,"naturally, no qualitative analysis can ever be complete without a word cloud :) here we can see the most representative words for each topic.","naturally, word cloud analysis is useless without a word map:) here we see the most representative words for each topic."
2763,as the index of our dataframe contains our depth values we can create two new variables miny and maxy that are equal to the minimum and maximum index values.,"as the depth value of the index of our dataframes are absolute and constant, we can define two new variables miny and maxy equal to the minimum and maximum values of the index."
2764,the whole class was completing to see who could write the fewest bits to represent the files; we were trying to get as close as possible to the true kolmogorov complexity.,our goal was to complete the entire class to see which class could write the fewest bits representing files; our objective was to approach the true kolmogorov complexity as best possible.
2765,"i have worked with cowboy coders and scrum masters, with people who have adopted agile as a way of life, and others who would sooner quit than participate in even one more standup meeting, with people who capitalize their function names and others who would deem such a practice a capital offense.","have worked with cowboy s programming and scrum masters, people who have adopted agile as their way of life and those who would rather quit without attending even one more standup meeting."
2766,"if they begin with a small letter, then they are private variables, only accessible in your file or scope.","if they begin with a small letter, then they are private variables only accessible within the context of the file or scope."
2767,"as shown, tidymodels breaks down the machine learning workflow into multiple stages and provides specialised packages for each stage.",tidymodels splits the machine learning workflow into multiple stages as shown and provides tailored packages for each stage.
2768,the aim will be to compare the performance of the rnn on the source domain vs. target domains.,we aim at comparing the performance of rnn for source and target domains.
2769,"if you'd like to place them side-by-side, specify stack = false.","if you want the two to lie side-by-side, specify stack = false."
2770,i send out a monthly newsletter if you would like to join please sign up via this link.,"i send out a newsletter every month, if you are interested in joining, sign-up here."
2771,"gosh, that would certainly help us to identify our key employees from an information flow perspective.",this will certainly help us identify our top performing employees from an information-flow perspective.
2772,k-means is a well-known clustering algorithm that is frequently used for unsupervised learning tasks.,k-means is a well-known clustering algorithm widely used in unsupervised learning tasks.
2773,"we use the shortened abbreviations false positive (fp), false negative (fn), true positive (tp) and true negative (tn).","we use the abbreviations false positive (fp), false negative (fn), true positive (tp) and true negative (tn) as shortened abbreviations."
2774,"creating systems for organization is something i like to do for every facet of my life, and i have found this to be overwhelmingly beneficial when it comes to organizing my code.",this is something i like to do in every area of my life and i found this process to be overwhelmingly beneficial when it comes to organizing my code.
2775,"using movement range maps, it is possible to conduct a quick validation step.",the quick validation step can be performed using movement range maps.
2776,"in a world where the null hypothesis is true, p-value is the probability of observing the conditions that satisfy the null.","for the world where the null hypothesis is true, p-values are the probability of observing a condition that is satisfiable by the null hypothesis."
2777,"instead, most people just take the familiar route of using an sql database to store information.",but most people have just kept the standard track and used a sql database for storage instead.
2778,one example that often comes in handy is setting the environment variables.,"one example, which comes in handy, is in settings where environment variables are defined."
2779,hypothesis testing is just the nerdy term to describe the scene between jimmy and his professor above.,hypothesis testing is just the nerdy term to describe the scene above with jimmy and his professor.
2780,"remember that the formula for the t-stat is different depending on the type of hypothesis test (one or two means, one or two proportions, one or two variances).","notice that the t-stat formula is different according to the type of the hypothesis test (either one or two states, one or two proportions, one or two variances)."
2781,we now have everything we need to start monte carlo pricing.,we now have the information we need to start monte carlo pricing.
2782,first we must convert the non numeric variables (discrete variables) into factors.,first we have to convert the non-numeric variables (discrete variables) into factors.
2783,those are the only attributes necessary to perform the needed action once the model is reloaded.,those are the only attributes that are required in order for the useful action to be performed when the model is reset.
2784,"if the string we pass in is equal to its reverse, then the expression evaluates to true, and true is returned.","when we insert a different-function (send) then the expression is evaluated to true, and true is returned."
2785,we need to send the detected body joints from pose estimation to the gesture recognition module.,we need to send detected body joints from pose estimation to the gesture recognition module for calibration.
2786,"in this case, we can observe that for both the friends, the dominant strategy is to reach the central part(first row, first column).","we observe that the dominating strategy for the two buddies in this case is to reach the central zone (leftmost row, center column)."
2787,the probability of event a is denoted as p(a) and calculated as the number of the desired outcome divided by the number of all outcomes.,the probability of a given event is denoted as p(a) and the value of the desired outcome is multiplied by the number of all outcomes.
2788,"sentiment analysis (also known as opinion mining or emotion ai) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.","sentiment analysis (also known as sentiment mining or ai) is a branch of text mining that systematically identifies, extracts, quantifies, and studies sentiment and subjective information in a textual context, employing, and adapts from natural language processing, text analysis, computational linguistics and biometrics."
2789,"one way to do this is by having the federal government develop a risk assessment framework, similar to what the canadian government created when measuring risks for ai systems that will be deployed in the public sector.",a good idea is to have the federal government develop a risk management framework similar to the one developed in canada for ai systems to deploy in public sector.
2790,"although this works, you might discover that the output is not ideal.","although this method works well, one might find that the output is not ideal."
2791,"from their website, we can aggregate all potential locations of current partners and plot it on a map.","we can aggregate all the potential location of the current partners through their websites, and map them."
2792,"as mentioned, data camp has a tutorial on generating a wordcloud from this same dataset and how to put it in some internet-downloaded image through python.","as previously mentioned, datacamp has a tutorial how to generate a wordcloud from this same dataset and how to embed it in some on-line image through python."
2793,use the tips below to stand out from the crowd in most data science applications piles.,"the most common data science stacking tasks provide the same opportunity to stand out, so apply the tips below."
2794,"steiner argues that language is not the vehicle of thought but rather its determining medium; that is to say, it is language that influences human thought.","steiner showed that language is not the mode of thought, it is merely the tool of thought; in other words, it is language that is influenced by human thought."
2795,these nascent ml frameworks had to work around a fundamental difficulty in distributed computing: the leap from a shared memory model (smm) to a distributed memory model (dmm).,one of the fundamental issues in distributed computing was that the jump from shared memory model (smm) to distributed memory model (dmm) is too large to handle without these nascent ml frameworks.
2796,"some of the main differentiators for questdb are columnar storage, low memory footprint, the use of the relational model for time-series, and scalable schemaless ingestion.","columnar storage, low memory footprint, use of relational model for time-series, and scalable schemaless ingestion are some of the main differentiators of questdb."
2797,"heroku is a cloud platform as a service (paas) supporting ruby on rails, java, node.js, scala, clojure, python, php, and go.","heroku is a platform-as-a-service (paas) that supports ruby on rails, java, node.js, scala, clojure, python, php, and go."
2798,"however, if you tried to explain to someone how you do it, it would be very difficult.","however, it would be challenging to explain the process of design to someone."
2799,"when you associate more accuracy with less error, it seems unrealistic that your boss blames you for a model with less error and cheers you for a model with a higher error.",having the manager blame one model with a lower number of errors is naive and cheering on the other for the model with a high number of errors seems to be unrealistic.
2800,this means showing how the project evolved through time to where it is now and the plans to steer the project in the future.,this means presenting a timeline of the project until it gets to where it is today and creating plans to steer the project in the future.
2801,imagine a case where comparing any two items in a list is not so simple.,"suppose, instead, that there is a case where comparing any two items of a table is not very simple."
2802,this could be the header that keeps being inserted in the middle of sentences.,this could be due to the fact that sentences are recurring inserts of headers.
2803,"this old faithful geyser data app will appear, which contains a slider widget on the left and a histogram on the right.","we get a glimpse of the old faithful geyser data app, which has a slider widget on the left and a histogram on the right."
2804,"boosting is an ensemble learning technique that, like bagging, makes use of a set of base learners to improve the stability and effectiveness of a ml model.","boosting is a combination of several ensemble learning techniques, which, like bagging, makes use of a set of baseline learners to further enhance the stability and effectiveness of an ml model."
2805,"it is important to notice that the number of subsets as well as the number of items per subset will be determined by the nature of your ml problem, the same for the type of ml algorithm to be used.","note that the number of subsets will depend on the nature of the ml problem, just as the number of items per subset depends on the type of ml algorithm that will be used."
2806,"no code change required, just change the catalog entry as follows:","no change of code is necessary, just alter the catalog entry to be as follows."
2807,this will allow you to learn one technique and be able to memoize any recursive function with immutable inputs.,this allows a single set of techniques for memoizing any recursive function with immutable input.
2808,the code the generate a confusion matrix in matlab is shown below:,the code to generate a ambiguity matrix in matlab is as follows.
2809,"once you have processed enough data, you can apply different techniques to understand the importance of the features.","after having processed sufficient data, one can apply different techniques to understand the importance of a feature."
2810,you will get to know the meaning and usage of different data types and how they can be represented in different applications.,we will get acquainted with the meanings and usages of different data types and how they can be represented in different applications.
2811,on the left you can see the calculations performed inside an lstm cell.,the calculations performed in the lstm cells can be seen from the left hand side.
2812,the roc curve is drawn by plotting the true positive rate (tpr) (aka recall) against the false positive rate (fpr).,our roc analysis plots the true positive rate (tpr) (also referred to as recall) against the false positive rate (fpr) over the time series.
2813,our sample image is a collection of small flowers on a plain brown background.,our sample image is a collection of small flowers with a simple gray background.
2814,recall under scenario two that the selection of items was weighted by their demand.,we recall that the selection of items in scenario two was weighted by its demand.
2815,"in fact, this concept has now evolved out from the technical to the product management side.","in fact, csi has evolved from the technical point of view towards the product management."
2816,spatstatis certainly the most successful package when it comes to spatial analysis and have plenty of good functions for fitting point process models but also to describe the point pattern.,"spatstatis without a doubt the most successful package for spatial analysis, as it provides a wealth of good features not only for fitting point process models but also for specifying point patterns."
2817,"in this example, i used a larger filter and tamped down with the filter on top.",in this example i was using a larger filter and tamping in with a top filter over.
2818,"while we are able to get a lot of information quickly, there are a couple of points which could be improved:","although this allows us to acquire a lot of details quickly, a few points can be improved on."
2819,"metrics and measures of success need to be agreed, designed and tracked from the beginning.","let us agree, design, and track success metrics from the beginning of the process."
2820,"however, in many instances of telehealth use, patients have not been the ones to decide whether conventional medicine or telemedicine fits their needs better, or understand how their concerns are incorporated into the technologies.","however, in many of the instances of telehealth, the patient does not make the decisions about which version of medicine or telemedicine best fits her needs, or understand the integration of these technologies."
2821,"then, a neural network learns through repeated adjustment of these weights.",we then observe that the weights are learned by neural network through successive modifications.
2822,you could jump on it without a tutorial and things just make sense and take less time to implement.,"it seems that it makes sense and is less time consuming to jump in and out without the need to re-learn a tutorial, and it actually makes sense."
2823,"after the data have been shuffled, it is time for us to split them into train, test, and validation labels and data by importing the necessary libraries as shown below:","when we shuffle the data, it is time to divide the data into training, test, and validation datasets by importer-dependent library as detailed below."
2824,"yet, the advent of small-data in deep learning might bring change.","nonetheless, the advent of small-data sets in deep learning will bring changes."
2825,trends keeps records of the popularity of google search terms over time.,trends keeps track of how phrases in google searches are popular over time.
2826,"we want the agent to take random actions at first, but once it starts getting the hang of things we want it to play to win.","initially we wish the agent to adopt random actions, but once he starts to get a handle on the game we want it to play a win-win game."
2827,"if you have any questions, please comment on the comment section below; i would love to help.",i would be delighted to help any of you; just leave a comment on the comment section below if you have any questions.
2828,"it may prompt for additional updates, as you can see that mine did in the screenshot below.","as can be seen by looking at the below, this process may prompt extra update."
2829,the cross-entropy loss and accuracy metric will be accumulated per epoch in order to inspect the model performance dynamics.,"to observe the dynamics of the model performance, we first compute the losses of the model, per epoch, and the error metric of the model cross-entropy."
2830,integrating the mask at our original rgb picture isolates the body of water.,we isolate the aps from the rest of the water by applying the mask to our original rgb image.
2831,"in this post, we have explicitly named the container in the docker-compose.yml file, so you can refer to that as well.","we refer to this as container, and explicitly state it in the docker-compose.yml file in this post."
2832,"in c++ apps, they are received as a native c structure.",they are returned as native c structures in c++ applications.
2833,we see that this is a tremendous improvement from our previous method.,we observe a dramatic improvement compared to our previous method.
2834,"hcm defines six levels of service for road segments based on driving speed values, from a to f, with los a representing the best driving conditions and los f the worst.","hcm defines six services in which the operating modes of the roads are ranked according to the velocity values, ranging from los a to los f, with los a the rated conditions and los f the rated conditions."
2835,"if you have read the previous articles in this series (links at bottom of page), you should have built a dnn class completely from base principles.",if we follow the previous articles in this series (links at bottom of page) then we would build our class as the complete version of dnn.
2836,"therefore, it is usually made of several layers of content, according to data journalism and visualization with free tools:","in general, data journalism or visualization using free tools consist of many layer content as follows."
2837,what if we want to test many different data in a given space?,what if we want to test multiple items of interest in one space?
2838,"therefore, the estimated dv is biased and will lead to inaccurate inferences.",the sv estimate is therefore biased and will lead to inaccurate inferences.
2839,this addition makes it easier to programmatically eliminate some proportion of features.,"the latter adds a useful extra feature, and allows us to eliminate some percentages of features programmatically."
2840,"yet, how to know if your organisation is really ready to dive into the data mesh?","nevertheless, how do you know if your organization is truly ready to jump on the data mesh?"
2841,"for a number of reasons, you cannot necessarily measure the patterns and trends across the entire population.",the study of patterns and trends on the entire population is not necessarily meaningful for several reasons.
2842,"deepfm is a mixed approach between fm and a deep neural network, that both share the same input embedding layer.",deepfm combines both fm and deep neural network whose input embedding layers share the same input embedding layer.
2843,"a static method is a regular method, placed inside a class.",a static method is a regular method that is bound in a class.
2844,"on the second graph, a schematic example of a tree and a plotted forest is shown with red-colored lines out abnormal data point existence while blue ones are normal ones.",the second figure shows a tree schematic and a forest plot with red-colored edges that denote abnormal data point existence while blue points that are normal.
2845,"kaggle is one of the best free, learning resources for data scientists.",kaggle is one of the best free and open learning resources available to data scientists.
2846,"if you have any question or if you believe i have made any mistake, feel free to contact me!",feel free to comment if you have any questions or believe that i may have made a mistake!
2847,"from my experience, arduino is definitely one of the best ways to get started with your robotics dream, as it is comparatively easier to use than other micro-controllers.","arduino seems like a great way to get started in your robotics dreams, since it has the advantage of being simpler to use than the usual microcontrollers."
2848,the predicted bonus tends to increase for all employees but at a slower rate for those with lower performance ratings.,"the predicted payoff increases for all workers, but decreases for a smaller fraction of employees."
2849,"two datasets were used to train, validate and test all networks and can be found on github here and here.","all networks were trained, validated and tested on two datasets, which are available on github here and here."
2850,the latter is a desired probability for dealing with fuzzy situations in presence of overlapping clusters or outliers.,the latter implies the desired probability to handle fuzzy settings with overlapping clusters or outliers.
2851,"hence, the blue channel can be derived from the other two.","consequently, the blue channel can be derived from the other two."
2852,"to address this problem, the goals of the current tutorial will be: (a) to build a cnn model to classify bird images w.r.t.",our current tutorial has been written with the following objectives: (a) constructing a cnn model for bdw image classification.
2853,an example of binary outcome could be asking customers whether they liked a particular product.,it is easy to imagine that customers were asked how much they liked a certain product as a binary outcome.
2854,"if someone has cancer but is tested negative, the patient will miss the best timing for treatment.","if someone has cancer but is tested positive, the patient will miss out the best treatment timing."
2855,"this code is included in index.html, rather than javascript.","this code can be found in index.html, instead of in javascript."
2856,"therefore, while interpreting the risk, relative risk, and odds ratio, it is critical to define the logic of the problem or the study.","in other words, determining the logic of a problem or an experiment is important when interpreting essential probabilities, equivalence of risks, and odds ratios."
2857,"a good picture book has good visuals, but it also has an engaging and powerful narrative that connects the visuals.","a good picture book has good visuals, but also an engaging and powerful narrative that connects all those visuals."
2858,"the concept of an artificial general intelligence (agi) is controversial, and chomsky as the founder of linguistic universality, has often expressed skepticism that artificial neural networks are capable of mimicking human cognition.","artificial general intelligence (agi) is a controversial concept, and chomsky, the father of linguistic universality, has often spoken about doubts that artificial neural networks can realistically emulate human cognitive behavior."
2859,"finally, we will use plt.imshow() to display the wordcloud object.","finally, we want to display the wordcloud object by calling plt.imshow()."
2860,the cfs dataset again had lower mae and rmse scores than the pca dataset.,"again, the mae and rmse scores of the cfs dataset were lower than that of the pca dataset."
2861,most of the data science projects (as keen as i am to say all of them) require a certain level of data cleaning and preprocessing to make the most of the machine learning models.,the data science job (as fervent as i may be to say it is all) still requires some level of data cleaning and preprocessing in order to perform well on machine learning models.
2862,"it is caused by confounding variables, and we have to include the missing variable in our analysis.","this is because the problems can arise when confounding variables are present, and in our analysis we must introduce missing variables."
2863,"so those are the most manual phrases to be extracted, what performance do the usual topic model workhorses give?","then, how does the usual topic model workhorse perform when these are the domains in which most manual phrases have to be extracted?"
2864,you will notice that the code below has expanded significantly compared to the code above.,notice that the size of the code generated below is significantly larger than the code described above.
2865,"in a future post, i will be sharing actual examples of data and python demonstrating what i have described.",we will publish real-world examples of data and python demonstrating the concepts we have introduced in future posts.
2866,the training and test can be obtained from the tatoeba translation challenge data page.,training and test data sets can be obtained from the translated tatoeba problem dataset.
2867,"however, we need to be careful about them especially when working on multiple projects.","however, these results must be careful, especially when working with multiple code branches."
2868,my project to count passing traffic would be a lot easier if i had terrific photographs such as the one above.,"for example, we could count passing traffic if i had a fantastic photo collection such as the one in the top row."
2869,we can solve this by adding a vertical line at the x-coordinate of every reference date.,we are able to resolve this problem by fixing a vertical line at the x-coordinate of each reference date.
2870,"tabnet is very quickly rising among data scientists; almost all of top-scoring competitors in the mechanisms of action kaggle competition, for instance, incorporated tabnet into their solutions.",tabnet has gained tremendous popularity among data scientists; almost all of the top contenders in the action kaggle mechanism-based learning competition have implemented tabnet in their solutions.
2871,"i have written extensively about gradient boosting, the theory behind and covered the different implementations like xgboost, lightgbm, catboost, ngboost etc.","i have written extensively about gradient boosting, the theory behind it, and the different implementations that come along in the literature, such as xgboost, lightgbm, catboost, ngboost etc."
2872,"system relies on the same data source, the failure can go unnoticed.","if the system has the same data source as source, failures in it may go unnoticed."
2873,"however when one is faced with very large data sets, containing multiple features, the simple distance calculation becomes a source of headaches and memory errors.","nevertheless, performing simple distance computation becomes an exercise in headache and memory error when one is faced with huge datasets, which have a multitude of features."
2874,"another thing that could be improved upon is looking at different methods of recording loss; when training our model, we only used mean absolute error, but it could be that the model performs better when very incorrect guesses are weighted more heavily like with mean squared error.","we look for other loss functions, also consider different weighted sensing methods; in training our model we used mean absolute error but the model would perform better if the very incorrect guesses were weighted more heavily as was the case with mean squared error."
2875,"using a true folder structure, management tasks (e.g.",the management tasks (eg.
2876,"while reading took up most of my time, i also used to carve small boats from wooden logs.","however, when the time was spent reading i would do the same; i used to make small boats from solid wood."
2877,"additionally, the angular documentation is very helpful for those that prefer to get more in the weeds.","also, for those who like to get really deeply involved in the weeds, an angular proof is a big help."
2878,setting up the contracts on how to ingest the data is probably one of the more challenging things of the data mesh implementation.,one of the more challenging steps in implementing data meshes is setting up the contracts for how data will be ingested.
2879,"especially since the big providers like google, amazon and microsoft link services like databases and data warehouses with machine learning services, it is no longer necessary to integrate the data into other platforms or systems.","for instance, as data warehouses and database implementations are interconnected with machine learning services via big companies like google, amazon and microsoft, integration is no longer necessary for data migration to other platforms or systems."
2880,we can generate simple random uniform variables using a pseudorandom number generator.,we can use pseudorandom num generators to generate simple random uniform variables.
2881,i then use a brita filter before pouring the water into my kim express.,i then fill the water using the breton filter and pour it into my kim express with a fine-tuning agent.
2882,apart from these you may also be expected to know the basics of agile software development principles if you work for a company that follows the principles.,"on top of that, if one works for an organization that practices agile software development principles, one would also expect to know basic agile software development principles."
2883,three issues came up when i switched from pip to conda that took a bit of time to figure out.,when i switched from pip to conda three issues cropped up that took some time to figure out.
2884,"it is generally considered inappropriate for a recommendation system to disclose private information, even for a single user.","typically, one feels uncomfortable with a recommendation system disclosing private information, even to a single user."
2885,one defining aspect of continuous data is that the same data can be represented in different units of measurement.,one feature of continuous measurements is that the same data can be modeled in different metric units.
2886,i have created a pytorch lightning based longformerfinetuner class to perform the training and validation.,the training and validation process was performed using the pytorch lightning-based longformerfinetuner class.
2887,we want to see the average order amount of customers from each location.,the goal of our analysis is to learn the average order volume of each location of the consumers.
2888,"the good news is that the core functionality is there, so if the developers of this app can really optimize their ui, i think this app could shine even more than it already does.","the good news is that the core functionality of the app is still available, so i think this app can shine even further if the app developers could actually optimize its ui."
2889,there are almost as many products as customers in the data as well.,we found that the data contain almost as many products as customers.
2890,"multiple linear regression is the same as simple linear regression, but now we have a regression coefficient for each of the regressor variables, as shown below.","the main difference from simple linear regression to multiple linear regression is that we now take each regressor variable as a function of the regression coefficient, as shown below."
2891,"first, we specify the layers that our neural network will have.",we begin by stating the number of layers that our neural network will have.
2892,"over time, it led to a situation where airflow.contrib got so large that dependency management, as well as planning and testing of the next releases, have become challenging.","this condition led to the situation when the airflow of contrib got so big that dependency management became challenging, including planning and testing the next release."
2893,what this really comes down to is not seeing value and the potential prosperity that could be uncovered.,it really means that the value and potential prosperity that can be discovered are not being seen.
2894,democrats are far more concerned with illegal immigrants than they are with our great military or safety at our dangerous southern border,the democrats take far less concern for the safety of our country s good military and for our dangerous southern border than for the safety of our great police forces or the safety of our nation s population.
2895,"consider a different problem, like whether or not a visitor will click on an ad on our webpage.",consider another problem such as whether a visitor clicks on a certain ad on our webpage or not.
2896,"the more you understand data science and machine learning, the clearer it will be that these are tools for efficient science, not replacements for scientists and scientific thinking.","understanding the nature of data science and machine learning will become even clearer, showing that both areas are tools to facilitate science rather than replacing science, or presenting a future to scientists."
2897,"in my day job as a machine learning engineer (mle), i juggle quite a few balls.",i play a lot of other games than that of my day job as a machine learning engineer (mle).
2898,"after executing the code, you should see an upload button like this:","once the code is executed, a upload button like the one in fig."
2899,"while the previous work mainly considered on-policy rl agents, kirsch et al.","while previous works have only considered on-policy rl agents, kirsch et al."
2900,"as lists are mutable, python needs to allocate an extra memory block in case there is a need to extend the size of the list object after it is created.","since lists are mutable, python must allocate an extra memory block whenever a new object of a list needs to be created."
2901,a lot of companies which hired droves of data scientists in search of data nirvana were ultimately disillusioned and at a loss to understand why analytics has not delivered the promised impact.,"many big pharma companies that had invested millions of dollars on a team of data scientists in search of data nirvana later fell victim to their own failure, leaving them left with little understanding why analytics never delivered on its promise."
2902,"data testing is often our first line of defense against bad data, but what happens if data breaks during its life cycle?",data testing is often our first line of defense against bad data but what if data breaks during its lifetime?
2903,"there were times, however, where i wished that i had studied software engineering or statistics in undergrad in order to be more well-equipped, but as we will see below, there are other ways to learn additional, yet specific facets of data science.","however, i have had times when i wished i had studied software engineering or statistics in my undergrad, but as we shall show below, there are other avenues for learning additional, but somewhat specific, aspects of data science."
2904,"on the other hand, there are tons of free or low cost resources that can provide you with an excellent foundation in data science.","furthermore, an excellent beginning of data science is to find a lot of information online which may be either free or low-cost."
2905,"personally, the more i have studied this field the more passionate i have become.","personally, the more i have explored this field the more passionate i have become."
2906,"for instance, if revenue is the goal, we could choose it over maximizing engagement assuming the negative impact is acceptable.","if revenue is a goal, we could choose to maximize revenue over engagement, assuming that the negative impact is acceptable."
2907,"six months later, when the work began, the stakeholder exploded in a meeting about why we were so behind.","when our work started, a stakeholder burst exploded in our meeting six months later about why we have fallen behind."
2908,"in my past roles, i have used my combined data science and social science skills to explore and build solutions for complicated problems for which the typical ways of doing things within the organization have not worked.","i have used my combined skills in both data science and social science to explore and develop methods to tackle complex problems, for which the conventional methods at a company could not work."
2909,"as discussed, the above function calculates the total number of zeros without the break command.","as discussed, the resulting function computes the total number of zeroes without a break command."
2910,we can apply z-score standardization to get all variables into the same scale.,"if we want the subvariables to scale equally well, we may resort to z-score standardization."
2911,"despite the simplicity of this approach, it had instantly failed due to many reasons.","but due to numerous reasons, this approach had instantaneously failed, even though it could have been very simple."
2912,in my case i looked on meetup for any local data science related groups.,my case was a local data science related group on meetup.
2913,"while each framework has its advantage in a particular sub-discipline of deep learning, excelling in tensorflow with keras api is the soundest option.","we note that excelling in tensorflow with the keras api is a sound choice, but each framework has its strengths in a specific sub-discipline of deep learning."
2914,hits uses hubs and authorities to define a recursive relationship between webpages.,hits recursively uses hubs and authorities to define the relations among web pages.
2915,"it involves learning as much as possible about the data, without spending too much time.",as much as possible to learn from data without consuming too much time.
2916,"in this example, i will show how to create a bn only using expert knowledge.",let us now illustrate how to construct a bn using only expert knowledge in this example.
2917,"we can also add multiple datasets to one graph, which helps depict more trends.","we can also consider a multi-grid system, which helps to see more trends."
2918,"however, you can check my github repository to access the code that produced the figures in this post (implemented in matlab).","however, to get the code responsible for the figures produced in this post (implicitly produced in matlab), i recommend that you check my github repository."
2919,"at this point, you might be wondering, what is the relevance of these trends with adele?",one might wonder why the trends in adele are of any interest at this stage of the analysis.
2920,"after splitting the data into train and test samples, we fit the model.",we fit our model after partitioning the dataset into test and train samples.
2921,"the pods folder will also be the home to other pods that we will need, which will also be defined using yaml files.","other pods that we will need, which will also be defined using yaml files, will reside in the pods folder."
2922,the tool also asked people about the level of enjoyment they derived from their work.,we also asked people how much enjoyment they received from their engagement in our tool.
2923,note that this chart will work only in jupyterlab and not in jupyter notebooks!,note that this figure will work in jupyterlab and not in jupyter notebook!
2924,"similarly, all python libraries also have multiple versions, work with specific versions of python and most of them depend on other packages to run, this is known as a set of dependencies.","the same is true for libraries: most of them work in a different version of python and most rely on other packages to run, it is called a dependency set."
2925,i found that this task really helped me understand the power of neural networks and deep learning.,i find that this task was really helpful for better understanding the power of neural networks and deep learning.
2926,this prompted me to utilize early stopping within keras to stop the model from training further when loss begins to increase.,this motivates me to incorporate early stopping within keras to delay the model from learning any further when the loss increases.
2927,"for our open-ended recommendation model, we chose to use the knnwithmeans classifier from the surprise package.",we have chosen to use the knnwithmeans classifier obtained from the surprise package for our open-ended recommendation model.
2928,the relative risk (rr) can be used to define how higher this risk is.,a measure to define how high this risk is can be is called relative risk (rr).
2929,we first drop the column added in the previous step and then insert the customer id column as the first row.,"then, drop the column added at the previous step, and insert a column with the customer id as the first row."
2930,"in caret, one function preprocess covers all pre-processing for numerical features, including imputation, centring, scaling, and power transformation.","all preprocessing operations in caret cover all the preprocessing operations to be performed on numerical features, including imputation, centrifugation, scaling and power transformation."
2931,let us see what are the consequences of using one over the other.,we see how to use one over the other.
2932,have you ever wondered what is the difference between a serial if block and anif-else block?,have you ever wondered what the difference between a serial if block and an if-else block is?
2933,"now that linear modeling and error has been covered, we can move on to the most simple linear regression model, ordinary least squares (ols).","now that linear modeling and error are considered, we turn to the most straightforward linear regression model, ordinary least squares (ols) model."
2934,"using that, we can compute the size of all building footprints available.",this allows us to compute the size of each building footprint available by taking the size.
2935,"the more you learn, the more there is left to learn.","the larger the area left to learn, the more it can be learned."
2936,caveat: the thing with counterfactual explanations is that it is applicable only to supervised classification tasks.,"note, counterfactual explanations only apply to supervised classification tasks, which is a problem."
2937,"in case you are joining, mid quest, you can always catch-up on the whole series here.","if you join mid quest, you can always catch up here on the whole series."
2938,this entire process of gathering the right data is called data mining.,this whole process of selecting the right datasets is called data mining.
2939,"running it as a web application enables you to work from any location, anywhere in the world, and using any medium (even your ipad).","running it as a web application enables you to work from any location, anywhere in the world, and from any type of medium (even your ipad)."
2940,"well, we managed to get a partly working website at hacktheurban.space which managed to meet some of our targets, but not all of them.","finally, we made a partially working web presence for hacktheurban.space which meets some but not all of our objectives."
2941,our knowledge base also helps us understand the sentence and infer that it is happy!,we also understand the sentences in our knowledge base and infer their happy conditions!
2942,"there was a breadth of protest-related literature available on the internet, covering a scope of topics including whether or not protests are effective, what mass protests around the world have in common and the way in which the media portrays them.","many works have been written on online protest studies, which have provided research on issues ranging from whether or not protests are effective, to what extent mass protest movements around the world are organized, and to how well the media portrays these groups."
2943,we go through the above process in the next section one by one.,in the next section we go through the above step one by one.
2944,we can test all these using the postman software very easily.,all of them can be easily tested in the postman software.
2945,if you are not using the index of the elements then you just use an underscore in its place.,"when one does not wish to use the element index, one just uses an underscore in its place."
2946,"like in c, these resemble objects in javascript and in a sense classes with only fields in python.","similarly, this is the style of objects in javascript, while in python classes are fields only, as in c."
2947,pandas is an amazing library for data analysis and data science.,pandas is an awesome library from the viewpoint of data analysis and data science.
2948,"when repeating the same selection of parameters, the songs may be quite repetitive but by design.","songs may seem repetitive by design, but it can be reasonably predictable when the same choice of parameters is repeatedly played."
2949,responsible ai is making sure that we align with societal values.,a responsible ai ensures that we are guided by societal values.
2950,features that have a high frequency of usage are clearly valuable to the folks who use them.,features which are highly desirable to the users are clearly valuable.
2951,"however, we are convinced that this is still the right path to follow.","however, we remain convinced that this is still a fair way to go."
2952,"since marketplaces are highly dynamic platforms where a lot of new ads are added by users daily, there are also many fresh or new ads posted on the platform which have not been viewed at all yet.","platforms such as ebay or the eb are highly dynamic platforms with thousands or millions of new ads posted by users on a daily basis, there may be a lot of fresh or new ads, that are not yet seen by any users."
2953,how would you go about doing that if the code was not well-documented?,"what steps might one take to accomplish this, if the code is not well documented?"
2954,the implicit assumption is that not all the information stored in the model is relevant for a particular input.,the implicit assumption is that not all the information stored in the model is relevant for one input.
2955,both figures are exported as html files with the variable education level included in the tooltips.,the tooltips include variable learning levels and are exported as html files for the two plots.
2956,these meetings allow data scientists to agree on code changes and quickly move pull requests through the process.,these meetings enable data scientists to agree on code modifications and to rapidly move pull requests through the pipeline.
2957,"though not perfect, this is a conventional representation of bias-variance calculations.","but the convention is sound for computing the bias-variance function, while it is far from perfect."
2958,there are some datasets no one can escape when starting to read about data science.,"firstly, when starting to read about data science, there are a few datasets from which no one escapes."
2959,data augmentation helps in preventing overfitting and helps the neural network model to generalize better on unseen variations of test images.,data augmentation assists with preventing overfitting and helps with better generalisation of neural network models to unseen alterations of test images.
2960,"plus, fine-tuning on one dataset may not provide good generalization over others for the same task.",we further note that fine-tuning on one dataset may not offer a good generalization over others that have the same task.
2961,"all things considered, i decided i would purchase a new card and install that in my existing system.","after assessing these effects, i decided to purchase a new sdn card and install it on my existing sdn."
2962,"so now, we have all we need when it comes to the python environment, but we still need to expose it outside of the notebook.","we have now all the tools we need for our implementation in the python environment, but we still need to expose it to the outside world."
2963,language modeling is the task of predicting the best word to follow or continue a sentence given all the words already in the sentence.,language modeling is the task of making sense of all already in the sentence and of predicting which of the words in the sentence should be followed or continued.
2964,these are obvious examples of anomalous transactions that seem identifiable by the naked eye.,these are obvious examples of irregular transactions which seem to be visible to the naked eye.
2965,"this feature is available in other data visualization tools like tableau and power bi, with just a few clicks or hovering the pointer over the datapoints.","you can access this feature by simply clicking or hovering the pointer over any of the datapoints in the dashboard, as in other visualization tools like tableau and power bi."
2966,"this make the problem seems extremely complex, so we need to first define the following settings of typical reinforcement learning problems:","this makes the problem appear difficult, and we first define the following setting for standard reinforcement learning problems:."
2967,these three well structured and generally clean data types can offer a wealth of insights when properly analyzed.,these three well structured and largely clean data types have the potential to offer a wealth of insights if properly analyzed.
2968,"thus, calling for help or trying to get up can be critical.","thus, it might be vital to contact the emergency services or make an effort to get up."
2969,"this is similar to what we did for multinomialnb, here",this is analogous to what we have done here for multinomialnb
2970,it might first predict the popularity of a given product or item.,it may first predict the popularity of a given product or item.
2971,last year i began to mentor younger individuals interested in data science or software engineering.,i have just launched a mentoring program for young individuals who are interested in data science and software engineering.
2972,"i added more characters, and it seems that each character adds one byte to the size of my string object.",i have added a few more characters and it seems to be that every character adds one bytes to the size of my string object.
2973,we then compare the observed partial dependence function to the partial dependence function under the assumption that there are no interactions.,we next compare the observed partial dependence function against the partial dependence function by assuming that no interactions exist.
2974,"i set the index as an integer datatype equal to zero, names as an empty array that we intend to populate with symbols, and lastly lookup which has the corresponding enumerated count and is a dict datatype.","first i define the set of indexes as integer datatypes equal to zero, which names we want to fill with symbols, and lastly, which lookups have an enumeration count and are dict datatypes."
2975,create a folder for the project and download the code files for this article from the repository here.,we upload the project files to our repository and download the code files for the article.
2976,"doing so may introduce wrong standard error estimates as residuals (i.e., observations in the same group) tend to be correlated.","this implies that the residuals (i.e. the observations in the same cluster) tend to be correlated, which is a possible reason why the standard error estimates are incorrect."
2977,"as a result, it is highly unlikely that we will be able to achieve the target throughput we calculated above.","hence, the target throughput we have computed above is highly unlikely to be achievable."
2978,"the main idea of original design sprints is to validate ideas rapidly: understanding market needs, brainstorm new ways to solve the problem, prototype first digital solutions, and test them with customers.","original design sprints aim at validate quickly ideas: we gain insights from the market, brainstorm new ways to solve a problem, develop first-in-class digital solutions, and then perform tests with customers."
2979,"the brain does not only process and weight evidence, but it actively explores.",the brain not only processes and weights evidence but also actively explores it.
2980,we know we can use neural networks for the formulation of the function of the transformation.,we know that this model can be used in neural network setting to formulate transformation functions.
2981,"as always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion.","as usual, if you have a question or suggestion related to a topic covered in this article, add it as a comment so that other readers may benefit from our discussion."
2982,"we have derived an algorithm on how to implement gradient descent here, but there are a lot of nuances when implementing this algorithm in code.","based on this algorithm we developed the gradient descent implementation, but there are many details to consider as we implement the algorithm in code."
2983,"there is still a solid camp of data scientists who use r, however, the fraction of data scientists who are using r in the field is dropping rapidly.","but while there is still a solid camp of data scientists using r, the fraction of data scientists employing r in the field decreases rapidly."
2984,"of course, it was when we had a course on all of these more advanced topics that we were assigned an instructor who was more interested in running his startup than actually teaching the class and giving us feedback.","of course, when we taught all these more advanced topics, we had an instructor with much more interest in running his startup rather than actually teaching the class or giving feedback to us."
2985,"if we rotate and scale the image with higher resolution, we can determine translation with another step of phase correlation.",one important benefit of translating using phase correlation is that it allows us to perform rotation and scalability on images with higher resolution.
2986,"i really want to focus on the second one here, because as simple as it sounds, it is another story in real life.","here i really want to focus on the second one, as it is as simple as it sounds but turns out to be an additional story in real-world situations."
2987,"in the case of system design concepts, caching as a concept is also a bit similar.",caching as a design concept is also somewhat similar to the above.
2988,"to do that you are going to repeat the processes that you did to add the text to the other keys: edit the default attribute on the command key and fill the value data field, but instead of plain text, you will write the actual command.","thus one must again follow the processes of adding text to other keys as follows: modify the attributes on the command key, fill the value field but in the text field instead of the plain text."
2989,the users of a social network and who each user is connected to (i.e.,the number of a social network is the number of users and the number of persons with whom each user is a part of it (cf.
2990,"to use this dataset to build a generalized model that can predict air quality in other neighborhoods in oakland, i first trained a machine learning model to predict air pollutant concentrations in the same locations as measured in the edf dataset by creating a set of generalizable features that describe pollutant concentrations.",we first trained a machine learning model to predict the air pollutant concentration at the same locations measured in the edf dataset and constructed a generalizable feature set describing the pollutant concentration in the other neighborhoods in oakland.
2991,"if you cannot show that you possess those skills in the coding interview, you will not get the job.","if there is no effort to prove that you possess such qualities in a coders interview, you will be rejected."
2992,"similarityfinder strings together two models, a classifier that predicts the breed of a pet and a comparison (siamese) model that determines whether two images are similar.","the similarityfinder strings two models together, one for predicting a dog s breed, and one for comparison (or siamese) classifiers determining how similar two images are to each other."
2993,using the output track data we were able to quickly identify the deviant tracks.,"we were able to identify deviant tracks via the output track data, within an order of magnitude."
2994,the goal of this article is to introduce the idea behind the group by operation and cover the basic syntax for each tool.,the aim of this paper is to introduce the concept of group-by-operations and to cover the most basic syntax of each tool.
2995,"it refers to the new, best-of-breed modern data architecture for dealing with massive amounts of data.",it refers to a new best-of-breed modern data architecture handling massive amount of data.
2996,you then realize that you might not be interested in the data work itself and only see the industry prospect.,one might then realize that one might not be interested in a data work per se and only see one s potential in industry.
2997,"in a rather meta turn of events, apple has actually developed an app called the swift playground, created to help beginner coders learn the basics of swift, along with several other resources to help users learn.","some rather meta-occurrences have led apple to develop a simple new app called swift playground, which aims to help beginning coding with swift, and also to provide some learning resources to interested developers."
2998,"if we apply the k-means algorithm to this graph, the manner by which it segments the image becomes strikingly clear.",the mode by which the image is filtered becomes strikingly clear as we apply the k-means algorithm to this graph.
2999,"however, there is another scenario that you may want to consider, imagine a team of experts, each with his own view on the domain in question.","let us consider the other scenario, imagine a team of experts, each with their own take on the domain under consideration."
